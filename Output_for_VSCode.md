root@masternode:~# # get last kubelet journal lines
sudo journalctl -u kubelet -n 400 --no-pager

# container runtime logs (containerd)
sudo journalctl -u containerd -n 400 --no-pager

# kube-proxy pod logs (use actual pod name if different)
kubectl -n kube-system logs kube-proxy-4g9mt --tail=500

# if kube-proxy repeatedly sees "sandbox changed" or CNI errors, capture kubelet events too:
kubectl describe node homelab | sed -n '1,200p'
Sep 13 12:40:06 masternode kubelet[1795473]: I0913 12:40:06.351084 1795473 topology_manager.go:215] "Topology Admit Handler" podUID="bc73f6e29284e18ef1a5976a5c72479c" podNamespace="kube-system" podName="kube-apiserver-masternode"
Sep 13 12:40:06 masternode kubelet[1795473]: I0913 12:40:06.351822 1795473 topology_manager.go:215] "Topology Admit Handler" podUID="310b6c94507e75997ff41605f87056ba" podNamespace="kube-system" podName="kube-controller-manager-masternode"
Sep 13 12:40:06 masternode kubelet[1795473]: I0913 12:40:06.355404 1795473 topology_manager.go:215] "Topology Admit Handler" podUID="14dedf7322adec20b2d7fe90ea829fab" podNamespace="kube-system" podName="kube-scheduler-masternode"
Sep 13 12:40:06 masternode kubelet[1795473]: E0913 12:40:06.368080 1795473 kubelet.go:1929] "Failed creating a mirror pod for" err="pods \"kube-apiserver-masternode\" already exists" pod="kube-system/kube-apiserver-masternode"
Sep 13 12:40:06 masternode kubelet[1795473]: E0913 12:40:06.368739 1795473 kubelet.go:1929] "Failed creating a mirror pod for" err="pods \"kube-scheduler-masternode\" already exists" pod="kube-system/kube-scheduler-masternode"
Sep 13 12:40:06 masternode kubelet[1795473]: E0913 12:40:06.368741 1795473 kubelet.go:1929] "Failed creating a mirror pod for" err="pods \"kube-controller-manager-masternode\" already exists" pod="kube-system/kube-controller-manager-masternode"
Sep 13 12:40:06 masternode kubelet[1795473]: I0913 12:40:06.503398 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/14dedf7322adec20b2d7fe90ea829fab-kubeconfig\") pod \"kube-scheduler-masternode\" (UID: \"14dedf7322adec20b2d7fe90ea829fab\") " pod="kube-system/kube-scheduler-masternode"
Sep 13 12:40:06 masternode kubelet[1795473]: I0913 12:40:06.503457 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-data\" (UniqueName: \"kubernetes.io/host-path/ae85cbac0ec6e7c5250eb914c4a530aa-etcd-data\") pod \"etcd-masternode\" (UID: \"ae85cbac0ec6e7c5250eb914c4a530aa\") " pod="kube-system/etcd-masternode"
Sep 13 12:40:06 masternode kubelet[1795473]: I0913 12:40:06.503498 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/310b6c94507e75997ff41605f87056ba-k8s-certs\") pod \"kube-controller-manager-masternode\" (UID: \"310b6c94507e75997ff41605f87056ba\") " pod="kube-system/kube-controller-manager-masternode"
Sep 13 12:40:06 masternode kubelet[1795473]: I0913 12:40:06.503534 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/bc73f6e29284e18ef1a5976a5c72479c-k8s-certs\") pod \"kube-apiserver-masternode\" (UID: \"bc73f6e29284e18ef1a5976a5c72479c\") " pod="kube-system/kube-apiserver-masternode"
Sep 13 12:40:06 masternode kubelet[1795473]: I0913 12:40:06.503575 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bc73f6e29284e18ef1a5976a5c72479c-usr-local-share-ca-certificates\") pod \"kube-apiserver-masternode\" (UID: \"bc73f6e29284e18ef1a5976a5c72479c\") " pod="kube-system/kube-apiserver-masternode"
Sep 13 12:40:06 masternode kubelet[1795473]: I0913 12:40:06.503605 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/310b6c94507e75997ff41605f87056ba-ca-certs\") pod \"kube-controller-manager-masternode\" (UID: \"310b6c94507e75997ff41605f87056ba\") " pod="kube-system/kube-controller-manager-masternode"
Sep 13 12:40:06 masternode kubelet[1795473]: I0913 12:40:06.503637 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/310b6c94507e75997ff41605f87056ba-usr-share-ca-certificates\") pod \"kube-controller-manager-masternode\" (UID: \"310b6c94507e75997ff41605f87056ba\") " pod="kube-system/kube-controller-manager-masternode"
Sep 13 12:40:06 masternode kubelet[1795473]: I0913 12:40:06.503671 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/bc73f6e29284e18ef1a5976a5c72479c-ca-certs\") pod \"kube-apiserver-masternode\" (UID: \"bc73f6e29284e18ef1a5976a5c72479c\") " pod="kube-system/kube-apiserver-masternode"
Sep 13 12:40:06 masternode kubelet[1795473]: I0913 12:40:06.503707 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/310b6c94507e75997ff41605f87056ba-etc-ca-certificates\") pod \"kube-controller-manager-masternode\" (UID: \"310b6c94507e75997ff41605f87056ba\") " pod="kube-system/kube-controller-manager-masternode"
Sep 13 12:40:06 masternode kubelet[1795473]: I0913 12:40:06.503744 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"flexvolume-dir\" (UniqueName: \"kubernetes.io/host-path/310b6c94507e75997ff41605f87056ba-flexvolume-dir\") pod \"kube-controller-manager-masternode\" (UID: \"310b6c94507e75997ff41605f87056ba\") " pod="kube-system/kube-controller-manager-masternode"
Sep 13 12:40:06 masternode kubelet[1795473]: I0913 12:40:06.503778 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-certs\" (UniqueName: \"kubernetes.io/host-path/ae85cbac0ec6e7c5250eb914c4a530aa-etcd-certs\") pod \"etcd-masternode\" (UID: \"ae85cbac0ec6e7c5250eb914c4a530aa\") " pod="kube-system/etcd-masternode"
Sep 13 12:40:06 masternode kubelet[1795473]: I0913 12:40:06.503810 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bc73f6e29284e18ef1a5976a5c72479c-etc-ca-certificates\") pod \"kube-apiserver-masternode\" (UID: \"bc73f6e29284e18ef1a5976a5c72479c\") " pod="kube-system/kube-apiserver-masternode"
Sep 13 12:40:06 masternode kubelet[1795473]: I0913 12:40:06.503840 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/310b6c94507e75997ff41605f87056ba-kubeconfig\") pod \"kube-controller-manager-masternode\" (UID: \"310b6c94507e75997ff41605f87056ba\") " pod="kube-system/kube-controller-manager-masternode"
Sep 13 12:40:06 masternode kubelet[1795473]: I0913 12:40:06.503881 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/310b6c94507e75997ff41605f87056ba-usr-local-share-ca-certificates\") pod \"kube-controller-manager-masternode\" (UID: \"310b6c94507e75997ff41605f87056ba\") " pod="kube-system/kube-controller-manager-masternode"
Sep 13 12:40:06 masternode kubelet[1795473]: I0913 12:40:06.503915 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/bc73f6e29284e18ef1a5976a5c72479c-usr-share-ca-certificates\") pod \"kube-apiserver-masternode\" (UID: \"bc73f6e29284e18ef1a5976a5c72479c\") " pod="kube-system/kube-apiserver-masternode"
Sep 13 12:40:07 masternode kubelet[1795473]: I0913 12:40:07.188759 1795473 apiserver.go:52] "Watching apiserver"
Sep 13 12:40:07 masternode kubelet[1795473]: I0913 12:40:07.203718 1795473 desired_state_of_world_populator.go:159] "Finished populating initial desired state of world"
Sep 13 12:40:07 masternode kubelet[1795473]: E0913 12:40:07.281501 1795473 kubelet.go:1929] "Failed creating a mirror pod for" err="pods \"kube-scheduler-masternode\" already exists" pod="kube-system/kube-scheduler-masternode"
Sep 13 12:40:07 masternode kubelet[1795473]: E0913 12:40:07.283609 1795473 kubelet.go:1929] "Failed creating a mirror pod for" err="pods \"kube-controller-manager-masternode\" already exists" pod="kube-system/kube-controller-manager-masternode"
Sep 13 12:40:07 masternode kubelet[1795473]: E0913 12:40:07.284788 1795473 kubelet.go:1929] "Failed creating a mirror pod for" err="pods \"kube-apiserver-masternode\" already exists" pod="kube-system/kube-apiserver-masternode"
Sep 13 12:40:07 masternode kubelet[1795473]: E0913 12:40:07.285381 1795473 kubelet.go:1929] "Failed creating a mirror pod for" err="pods \"etcd-masternode\" already exists" pod="kube-system/etcd-masternode"
Sep 13 12:40:07 masternode kubelet[1795473]: I0913 12:40:07.313537 1795473 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/etcd-masternode" podStartSLOduration=1.313466713 podStartE2EDuration="1.313466713s" podCreationTimestamp="2025-09-13 12:40:06 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-09-13 12:40:07.30230102 -0400 EDT m=+1.179840926" watchObservedRunningTime="2025-09-13 12:40:07.313466713 -0400 EDT m=+1.191006611"
Sep 13 12:40:07 masternode kubelet[1795473]: I0913 12:40:07.313668 1795473 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-apiserver-masternode" podStartSLOduration=3.313635886 podStartE2EDuration="3.313635886s" podCreationTimestamp="2025-09-13 12:40:04 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-09-13 12:40:07.313056167 -0400 EDT m=+1.190596074" watchObservedRunningTime="2025-09-13 12:40:07.313635886 -0400 EDT m=+1.191175788"
Sep 13 12:40:07 masternode kubelet[1795473]: I0913 12:40:07.327103 1795473 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-controller-manager-masternode" podStartSLOduration=2.327044125 podStartE2EDuration="2.327044125s" podCreationTimestamp="2025-09-13 12:40:05 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-09-13 12:40:07.326657547 -0400 EDT m=+1.204197454" watchObservedRunningTime="2025-09-13 12:40:07.327044125 -0400 EDT m=+1.204584039"
Sep 13 12:40:07 masternode kubelet[1795473]: I0913 12:40:07.350131 1795473 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-scheduler-masternode" podStartSLOduration=3.3500784550000002 podStartE2EDuration="3.350078455s" podCreationTimestamp="2025-09-13 12:40:04 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-09-13 12:40:07.339730422 -0400 EDT m=+1.217270327" watchObservedRunningTime="2025-09-13 12:40:07.350078455 -0400 EDT m=+1.227618356"
Sep 13 12:40:20 masternode kubelet[1795473]: I0913 12:40:20.807723 1795473 topology_manager.go:215] "Topology Admit Handler" podUID="22ac925e-0fd7-46eb-a7dc-c33a6e626bef" podNamespace="kube-system" podName="kube-proxy-m99cv"
Sep 13 12:40:20 masternode kubelet[1795473]: I0913 12:40:20.814600 1795473 topology_manager.go:215] "Topology Admit Handler" podUID="3735d286-9507-4d83-8eef-3612f89371a6" podNamespace="kube-flannel" podName="kube-flannel-ds-gcw9s"
Sep 13 12:40:20 masternode kubelet[1795473]: I0913 12:40:20.905038 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/22ac925e-0fd7-46eb-a7dc-c33a6e626bef-kube-proxy\") pod \"kube-proxy-m99cv\" (UID: \"22ac925e-0fd7-46eb-a7dc-c33a6e626bef\") " pod="kube-system/kube-proxy-m99cv"
Sep 13 12:40:20 masternode kubelet[1795473]: I0913 12:40:20.905097 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/22ac925e-0fd7-46eb-a7dc-c33a6e626bef-lib-modules\") pod \"kube-proxy-m99cv\" (UID: \"22ac925e-0fd7-46eb-a7dc-c33a6e626bef\") " pod="kube-system/kube-proxy-m99cv"
Sep 13 12:40:20 masternode kubelet[1795473]: I0913 12:40:20.905137 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-8625s\" (UniqueName: \"kubernetes.io/projected/22ac925e-0fd7-46eb-a7dc-c33a6e626bef-kube-api-access-8625s\") pod \"kube-proxy-m99cv\" (UID: \"22ac925e-0fd7-46eb-a7dc-c33a6e626bef\") " pod="kube-system/kube-proxy-m99cv"
Sep 13 12:40:20 masternode kubelet[1795473]: I0913 12:40:20.905181 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"run\" (UniqueName: \"kubernetes.io/host-path/3735d286-9507-4d83-8eef-3612f89371a6-run\") pod \"kube-flannel-ds-gcw9s\" (UID: \"3735d286-9507-4d83-8eef-3612f89371a6\") " pod="kube-flannel/kube-flannel-ds-gcw9s"
Sep 13 12:40:20 masternode kubelet[1795473]: I0913 12:40:20.905218 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-vg4vk\" (UniqueName: \"kubernetes.io/projected/3735d286-9507-4d83-8eef-3612f89371a6-kube-api-access-vg4vk\") pod \"kube-flannel-ds-gcw9s\" (UID: \"3735d286-9507-4d83-8eef-3612f89371a6\") " pod="kube-flannel/kube-flannel-ds-gcw9s"
Sep 13 12:40:20 masternode kubelet[1795473]: I0913 12:40:20.905258 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/22ac925e-0fd7-46eb-a7dc-c33a6e626bef-xtables-lock\") pod \"kube-proxy-m99cv\" (UID: \"22ac925e-0fd7-46eb-a7dc-c33a6e626bef\") " pod="kube-system/kube-proxy-m99cv"
Sep 13 12:40:20 masternode kubelet[1795473]: I0913 12:40:20.905283 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cni\" (UniqueName: \"kubernetes.io/host-path/3735d286-9507-4d83-8eef-3612f89371a6-cni\") pod \"kube-flannel-ds-gcw9s\" (UID: \"3735d286-9507-4d83-8eef-3612f89371a6\") " pod="kube-flannel/kube-flannel-ds-gcw9s"
Sep 13 12:40:20 masternode kubelet[1795473]: I0913 12:40:20.905313 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"flannel-cfg\" (UniqueName: \"kubernetes.io/configmap/3735d286-9507-4d83-8eef-3612f89371a6-flannel-cfg\") pod \"kube-flannel-ds-gcw9s\" (UID: \"3735d286-9507-4d83-8eef-3612f89371a6\") " pod="kube-flannel/kube-flannel-ds-gcw9s"
Sep 13 12:40:20 masternode kubelet[1795473]: I0913 12:40:20.905376 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cni-plugin\" (UniqueName: \"kubernetes.io/host-path/3735d286-9507-4d83-8eef-3612f89371a6-cni-plugin\") pod \"kube-flannel-ds-gcw9s\" (UID: \"3735d286-9507-4d83-8eef-3612f89371a6\") " pod="kube-flannel/kube-flannel-ds-gcw9s"
Sep 13 12:40:20 masternode kubelet[1795473]: I0913 12:40:20.905411 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/3735d286-9507-4d83-8eef-3612f89371a6-xtables-lock\") pod \"kube-flannel-ds-gcw9s\" (UID: \"3735d286-9507-4d83-8eef-3612f89371a6\") " pod="kube-flannel/kube-flannel-ds-gcw9s"
Sep 13 12:40:21 masternode kubelet[1795473]: I0913 12:40:21.050772 1795473 topology_manager.go:215] "Topology Admit Handler" podUID="fab2956a-e71d-4751-b624-e2dea4e72bde" podNamespace="kube-system" podName="coredns-76f75df574-c6djd"
Sep 13 12:40:21 masternode kubelet[1795473]: I0913 12:40:21.062598 1795473 topology_manager.go:215] "Topology Admit Handler" podUID="a1d2f391-8fb9-4982-8de5-d45f9005e2d1" podNamespace="kube-system" podName="coredns-76f75df574-bnql5"
Sep 13 12:40:21 masternode kubelet[1795473]: I0913 12:40:21.107020 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/fab2956a-e71d-4751-b624-e2dea4e72bde-config-volume\") pod \"coredns-76f75df574-c6djd\" (UID: \"fab2956a-e71d-4751-b624-e2dea4e72bde\") " pod="kube-system/coredns-76f75df574-c6djd"
Sep 13 12:40:21 masternode kubelet[1795473]: I0913 12:40:21.107075 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/a1d2f391-8fb9-4982-8de5-d45f9005e2d1-config-volume\") pod \"coredns-76f75df574-bnql5\" (UID: \"a1d2f391-8fb9-4982-8de5-d45f9005e2d1\") " pod="kube-system/coredns-76f75df574-bnql5"
Sep 13 12:40:21 masternode kubelet[1795473]: I0913 12:40:21.107187 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-h9qg2\" (UniqueName: \"kubernetes.io/projected/a1d2f391-8fb9-4982-8de5-d45f9005e2d1-kube-api-access-h9qg2\") pod \"coredns-76f75df574-bnql5\" (UID: \"a1d2f391-8fb9-4982-8de5-d45f9005e2d1\") " pod="kube-system/coredns-76f75df574-bnql5"
Sep 13 12:40:21 masternode kubelet[1795473]: I0913 12:40:21.107237 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-vgrg6\" (UniqueName: \"kubernetes.io/projected/fab2956a-e71d-4751-b624-e2dea4e72bde-kube-api-access-vgrg6\") pod \"coredns-76f75df574-c6djd\" (UID: \"fab2956a-e71d-4751-b624-e2dea4e72bde\") " pod="kube-system/coredns-76f75df574-c6djd"
Sep 13 12:40:22 masternode kubelet[1795473]: I0913 12:40:22.342602 1795473 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/coredns-76f75df574-bnql5" podStartSLOduration=1.342543431 podStartE2EDuration="1.342543431s" podCreationTimestamp="2025-09-13 12:40:21 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-09-13 12:40:22.32505733 -0400 EDT m=+16.202597238" watchObservedRunningTime="2025-09-13 12:40:22.342543431 -0400 EDT m=+16.220083340"
Sep 13 12:40:22 masternode kubelet[1795473]: I0913 12:40:22.369587 1795473 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/coredns-76f75df574-c6djd" podStartSLOduration=1.369530899 podStartE2EDuration="1.369530899s" podCreationTimestamp="2025-09-13 12:40:21 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-09-13 12:40:22.343280662 -0400 EDT m=+16.220820568" watchObservedRunningTime="2025-09-13 12:40:22.369530899 -0400 EDT m=+16.247070796"
Sep 13 12:40:22 masternode kubelet[1795473]: I0913 12:40:22.420868 1795473 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-proxy-m99cv" podStartSLOduration=2.420813912 podStartE2EDuration="2.420813912s" podCreationTimestamp="2025-09-13 12:40:20 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-09-13 12:40:22.404425412 -0400 EDT m=+16.281965336" watchObservedRunningTime="2025-09-13 12:40:22.420813912 -0400 EDT m=+16.298353817"
Sep 13 12:40:24 masternode kubelet[1795473]: I0913 12:40:24.342878 1795473 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-flannel/kube-flannel-ds-gcw9s" podStartSLOduration=4.342820835 podStartE2EDuration="4.342820835s" podCreationTimestamp="2025-09-13 12:40:20 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-09-13 12:40:24.342486269 -0400 EDT m=+18.220026189" watchObservedRunningTime="2025-09-13 12:40:24.342820835 -0400 EDT m=+18.220360729"
Sep 13 12:40:25 masternode kubelet[1795473]: I0913 12:40:25.214771 1795473 topology_manager.go:215] "Topology Admit Handler" podUID="c0086d83-f0d2-400d-bee8-01d9807210fe" podNamespace="kube-system" podName="coredns-68444cf7cd-dwrkx"
Sep 13 12:40:25 masternode kubelet[1795473]: I0913 12:40:25.232800 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-q982r\" (UniqueName: \"kubernetes.io/projected/c0086d83-f0d2-400d-bee8-01d9807210fe-kube-api-access-q982r\") pod \"coredns-68444cf7cd-dwrkx\" (UID: \"c0086d83-f0d2-400d-bee8-01d9807210fe\") " pod="kube-system/coredns-68444cf7cd-dwrkx"
Sep 13 12:40:25 masternode kubelet[1795473]: I0913 12:40:25.232882 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/c0086d83-f0d2-400d-bee8-01d9807210fe-config-volume\") pod \"coredns-68444cf7cd-dwrkx\" (UID: \"c0086d83-f0d2-400d-bee8-01d9807210fe\") " pod="kube-system/coredns-68444cf7cd-dwrkx"
Sep 13 12:40:26 masternode kubelet[1795473]: I0913 12:40:26.372342 1795473 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/coredns-68444cf7cd-dwrkx" podStartSLOduration=1.372302231 podStartE2EDuration="1.372302231s" podCreationTimestamp="2025-09-13 12:40:25 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-09-13 12:40:26.353423063 -0400 EDT m=+20.230962960" watchObservedRunningTime="2025-09-13 12:40:26.372302231 -0400 EDT m=+20.249842135"
Sep 13 12:40:26 masternode kubelet[1795473]: I0913 12:40:26.707442 1795473 kuberuntime_manager.go:1541] "Updating runtime config through cri with podcidr" CIDR="10.244.0.0/24"
Sep 13 12:40:26 masternode kubelet[1795473]: I0913 12:40:26.707970 1795473 kubelet_network.go:61] "Updating Pod CIDR" originalPodCIDR="" newPodCIDR="10.244.0.0/24"
Sep 13 12:40:30 masternode kubelet[1795473]: I0913 12:40:30.767611 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/fab2956a-e71d-4751-b624-e2dea4e72bde-config-volume\") pod \"fab2956a-e71d-4751-b624-e2dea4e72bde\" (UID: \"fab2956a-e71d-4751-b624-e2dea4e72bde\") "
Sep 13 12:40:30 masternode kubelet[1795473]: I0913 12:40:30.767677 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"kube-api-access-h9qg2\" (UniqueName: \"kubernetes.io/projected/a1d2f391-8fb9-4982-8de5-d45f9005e2d1-kube-api-access-h9qg2\") pod \"a1d2f391-8fb9-4982-8de5-d45f9005e2d1\" (UID: \"a1d2f391-8fb9-4982-8de5-d45f9005e2d1\") "
Sep 13 12:40:30 masternode kubelet[1795473]: I0913 12:40:30.767722 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/a1d2f391-8fb9-4982-8de5-d45f9005e2d1-config-volume\") pod \"a1d2f391-8fb9-4982-8de5-d45f9005e2d1\" (UID: \"a1d2f391-8fb9-4982-8de5-d45f9005e2d1\") "
Sep 13 12:40:30 masternode kubelet[1795473]: I0913 12:40:30.767772 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"kube-api-access-vgrg6\" (UniqueName: \"kubernetes.io/projected/fab2956a-e71d-4751-b624-e2dea4e72bde-kube-api-access-vgrg6\") pod \"fab2956a-e71d-4751-b624-e2dea4e72bde\" (UID: \"fab2956a-e71d-4751-b624-e2dea4e72bde\") "
Sep 13 12:40:30 masternode kubelet[1795473]: I0913 12:40:30.768299 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/configmap/fab2956a-e71d-4751-b624-e2dea4e72bde-config-volume" (OuterVolumeSpecName: "config-volume") pod "fab2956a-e71d-4751-b624-e2dea4e72bde" (UID: "fab2956a-e71d-4751-b624-e2dea4e72bde"). InnerVolumeSpecName "config-volume". PluginName "kubernetes.io/configmap", VolumeGidValue ""
Sep 13 12:40:30 masternode kubelet[1795473]: I0913 12:40:30.768328 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/configmap/a1d2f391-8fb9-4982-8de5-d45f9005e2d1-config-volume" (OuterVolumeSpecName: "config-volume") pod "a1d2f391-8fb9-4982-8de5-d45f9005e2d1" (UID: "a1d2f391-8fb9-4982-8de5-d45f9005e2d1"). InnerVolumeSpecName "config-volume". PluginName "kubernetes.io/configmap", VolumeGidValue ""
Sep 13 12:40:30 masternode kubelet[1795473]: I0913 12:40:30.770556 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/fab2956a-e71d-4751-b624-e2dea4e72bde-kube-api-access-vgrg6" (OuterVolumeSpecName: "kube-api-access-vgrg6") pod "fab2956a-e71d-4751-b624-e2dea4e72bde" (UID: "fab2956a-e71d-4751-b624-e2dea4e72bde"). InnerVolumeSpecName "kube-api-access-vgrg6". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 13 12:40:30 masternode kubelet[1795473]: I0913 12:40:30.770586 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/a1d2f391-8fb9-4982-8de5-d45f9005e2d1-kube-api-access-h9qg2" (OuterVolumeSpecName: "kube-api-access-h9qg2") pod "a1d2f391-8fb9-4982-8de5-d45f9005e2d1" (UID: "a1d2f391-8fb9-4982-8de5-d45f9005e2d1"). InnerVolumeSpecName "kube-api-access-h9qg2". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 13 12:40:30 masternode kubelet[1795473]: I0913 12:40:30.868134 1795473 reconciler_common.go:305] "Volume detached for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/a1d2f391-8fb9-4982-8de5-d45f9005e2d1-config-volume\") on node \"masternode\" DevicePath \"\""
Sep 13 12:40:30 masternode kubelet[1795473]: I0913 12:40:30.868175 1795473 reconciler_common.go:305] "Volume detached for volume \"kube-api-access-vgrg6\" (UniqueName: \"kubernetes.io/projected/fab2956a-e71d-4751-b624-e2dea4e72bde-kube-api-access-vgrg6\") on node \"masternode\" DevicePath \"\""
Sep 13 12:40:30 masternode kubelet[1795473]: I0913 12:40:30.868190 1795473 reconciler_common.go:305] "Volume detached for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/fab2956a-e71d-4751-b624-e2dea4e72bde-config-volume\") on node \"masternode\" DevicePath \"\""
Sep 13 12:40:30 masternode kubelet[1795473]: I0913 12:40:30.868203 1795473 reconciler_common.go:305] "Volume detached for volume \"kube-api-access-h9qg2\" (UniqueName: \"kubernetes.io/projected/a1d2f391-8fb9-4982-8de5-d45f9005e2d1-kube-api-access-h9qg2\") on node \"masternode\" DevicePath \"\""
Sep 13 12:40:31 masternode kubelet[1795473]: I0913 12:40:31.350613 1795473 scope.go:117] "RemoveContainer" containerID="a58302f6fdb3adb089557175b68996d4e3f45f7c7aac030c60d7210f602492e4"
Sep 13 12:40:31 masternode kubelet[1795473]: I0913 12:40:31.379168 1795473 scope.go:117] "RemoveContainer" containerID="a58302f6fdb3adb089557175b68996d4e3f45f7c7aac030c60d7210f602492e4"
Sep 13 12:40:31 masternode kubelet[1795473]: E0913 12:40:31.380059 1795473 remote_runtime.go:432] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"a58302f6fdb3adb089557175b68996d4e3f45f7c7aac030c60d7210f602492e4\": not found" containerID="a58302f6fdb3adb089557175b68996d4e3f45f7c7aac030c60d7210f602492e4"
Sep 13 12:40:31 masternode kubelet[1795473]: I0913 12:40:31.380258 1795473 pod_container_deletor.go:53] "DeleteContainer returned error" containerID={"Type":"containerd","ID":"a58302f6fdb3adb089557175b68996d4e3f45f7c7aac030c60d7210f602492e4"} err="failed to get container status \"a58302f6fdb3adb089557175b68996d4e3f45f7c7aac030c60d7210f602492e4\": rpc error: code = NotFound desc = an error occurred when try to find container \"a58302f6fdb3adb089557175b68996d4e3f45f7c7aac030c60d7210f602492e4\": not found"
Sep 13 12:40:31 masternode kubelet[1795473]: I0913 12:40:31.380298 1795473 scope.go:117] "RemoveContainer" containerID="9d2dfa66d087d1960ee5c0c39317248d73c7d604a3355d053fa251886a88721b"
Sep 13 12:40:31 masternode kubelet[1795473]: I0913 12:40:31.390252 1795473 scope.go:117] "RemoveContainer" containerID="9d2dfa66d087d1960ee5c0c39317248d73c7d604a3355d053fa251886a88721b"
Sep 13 12:40:31 masternode kubelet[1795473]: E0913 12:40:31.390626 1795473 remote_runtime.go:432] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"9d2dfa66d087d1960ee5c0c39317248d73c7d604a3355d053fa251886a88721b\": not found" containerID="9d2dfa66d087d1960ee5c0c39317248d73c7d604a3355d053fa251886a88721b"
Sep 13 12:40:31 masternode kubelet[1795473]: I0913 12:40:31.390677 1795473 pod_container_deletor.go:53] "DeleteContainer returned error" containerID={"Type":"containerd","ID":"9d2dfa66d087d1960ee5c0c39317248d73c7d604a3355d053fa251886a88721b"} err="failed to get container status \"9d2dfa66d087d1960ee5c0c39317248d73c7d604a3355d053fa251886a88721b\": rpc error: code = NotFound desc = an error occurred when try to find container \"9d2dfa66d087d1960ee5c0c39317248d73c7d604a3355d053fa251886a88721b\": not found"
Sep 13 12:40:32 masternode kubelet[1795473]: I0913 12:40:32.259081 1795473 kubelet_volumes.go:163] "Cleaned up orphaned pod volumes dir" podUID="a1d2f391-8fb9-4982-8de5-d45f9005e2d1" path="/var/lib/kubelet/pods/a1d2f391-8fb9-4982-8de5-d45f9005e2d1/volumes"
Sep 13 12:40:32 masternode kubelet[1795473]: I0913 12:40:32.260592 1795473 kubelet_volumes.go:163] "Cleaned up orphaned pod volumes dir" podUID="fab2956a-e71d-4751-b624-e2dea4e72bde" path="/var/lib/kubelet/pods/fab2956a-e71d-4751-b624-e2dea4e72bde/volumes"
Sep 13 12:41:06 masternode kubelet[1795473]: E0913 12:41:06.283929 1795473 remote_runtime.go:432] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"7a0b17219668d887831eb36bc8279814d9d3b503838364bb904c4c6c3afcca6b\": not found" containerID="7a0b17219668d887831eb36bc8279814d9d3b503838364bb904c4c6c3afcca6b"
Sep 13 12:41:06 masternode kubelet[1795473]: I0913 12:41:06.283968 1795473 kuberuntime_gc.go:360] "Error getting ContainerStatus for containerID" containerID="7a0b17219668d887831eb36bc8279814d9d3b503838364bb904c4c6c3afcca6b" err="rpc error: code = NotFound desc = an error occurred when try to find container \"7a0b17219668d887831eb36bc8279814d9d3b503838364bb904c4c6c3afcca6b\": not found"
Sep 13 12:41:06 masternode kubelet[1795473]: E0913 12:41:06.284436 1795473 remote_runtime.go:432] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"95dd5e72825506dbda7306615397d5feed9d03bef6512f4f6acb26b1abc66d4e\": not found" containerID="95dd5e72825506dbda7306615397d5feed9d03bef6512f4f6acb26b1abc66d4e"
Sep 13 12:41:06 masternode kubelet[1795473]: I0913 12:41:06.284462 1795473 kuberuntime_gc.go:360] "Error getting ContainerStatus for containerID" containerID="95dd5e72825506dbda7306615397d5feed9d03bef6512f4f6acb26b1abc66d4e" err="rpc error: code = NotFound desc = an error occurred when try to find container \"95dd5e72825506dbda7306615397d5feed9d03bef6512f4f6acb26b1abc66d4e\": not found"
Sep 13 12:41:06 masternode kubelet[1795473]: E0913 12:41:06.284950 1795473 remote_runtime.go:432] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"4e752d73eb9e45201413fbe648fb346bf93182ff7d92597182bc5b31ebd18f93\": not found" containerID="4e752d73eb9e45201413fbe648fb346bf93182ff7d92597182bc5b31ebd18f93"
Sep 13 12:41:06 masternode kubelet[1795473]: I0913 12:41:06.284978 1795473 kuberuntime_gc.go:360] "Error getting ContainerStatus for containerID" containerID="4e752d73eb9e45201413fbe648fb346bf93182ff7d92597182bc5b31ebd18f93" err="rpc error: code = NotFound desc = an error occurred when try to find container \"4e752d73eb9e45201413fbe648fb346bf93182ff7d92597182bc5b31ebd18f93\": not found"
Sep 13 12:41:06 masternode kubelet[1795473]: E0913 12:41:06.285272 1795473 remote_runtime.go:432] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"9450b9f0f00902b0e1dd3d9662846d129ede6c883e6d669624ddf101990b570e\": not found" containerID="9450b9f0f00902b0e1dd3d9662846d129ede6c883e6d669624ddf101990b570e"
Sep 13 12:41:06 masternode kubelet[1795473]: I0913 12:41:06.285298 1795473 kuberuntime_gc.go:360] "Error getting ContainerStatus for containerID" containerID="9450b9f0f00902b0e1dd3d9662846d129ede6c883e6d669624ddf101990b570e" err="rpc error: code = NotFound desc = an error occurred when try to find container \"9450b9f0f00902b0e1dd3d9662846d129ede6c883e6d669624ddf101990b570e\": not found"
Sep 13 12:41:06 masternode kubelet[1795473]: E0913 12:41:06.285579 1795473 remote_runtime.go:432] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"967bf1270f5dda4d9e4a5a755e529fe87ae9e6dac8316ad178bc6d8f8f06607a\": not found" containerID="967bf1270f5dda4d9e4a5a755e529fe87ae9e6dac8316ad178bc6d8f8f06607a"
Sep 13 12:41:06 masternode kubelet[1795473]: I0913 12:41:06.285607 1795473 kuberuntime_gc.go:360] "Error getting ContainerStatus for containerID" containerID="967bf1270f5dda4d9e4a5a755e529fe87ae9e6dac8316ad178bc6d8f8f06607a" err="rpc error: code = NotFound desc = an error occurred when try to find container \"967bf1270f5dda4d9e4a5a755e529fe87ae9e6dac8316ad178bc6d8f8f06607a\": not found"
Sep 13 12:41:06 masternode kubelet[1795473]: E0913 12:41:06.285883 1795473 remote_runtime.go:432] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"5db69079541748797059ea4cbad7aae67d90884ea756df78171198a65da4cbbc\": not found" containerID="5db69079541748797059ea4cbad7aae67d90884ea756df78171198a65da4cbbc"
Sep 13 12:41:06 masternode kubelet[1795473]: I0913 12:41:06.285908 1795473 kuberuntime_gc.go:360] "Error getting ContainerStatus for containerID" containerID="5db69079541748797059ea4cbad7aae67d90884ea756df78171198a65da4cbbc" err="rpc error: code = NotFound desc = an error occurred when try to find container \"5db69079541748797059ea4cbad7aae67d90884ea756df78171198a65da4cbbc\": not found"
Sep 13 12:41:06 masternode kubelet[1795473]: E0913 12:41:06.286268 1795473 remote_runtime.go:432] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"d95e4959058061eb8d047fe0f1f866fb2545a24cec2fb376c6399e5ddceb6221\": not found" containerID="d95e4959058061eb8d047fe0f1f866fb2545a24cec2fb376c6399e5ddceb6221"
Sep 13 12:41:06 masternode kubelet[1795473]: I0913 12:41:06.286292 1795473 kuberuntime_gc.go:360] "Error getting ContainerStatus for containerID" containerID="d95e4959058061eb8d047fe0f1f866fb2545a24cec2fb376c6399e5ddceb6221" err="rpc error: code = NotFound desc = an error occurred when try to find container \"d95e4959058061eb8d047fe0f1f866fb2545a24cec2fb376c6399e5ddceb6221\": not found"
Sep 13 12:42:28 masternode kubelet[1795473]: E0913 12:42:28.811864 1795473 controller.go:195] "Failed to update lease" err="Put \"https://192.168.4.63:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:28 masternode kubelet[1795473]: E0913 12:42:28.812615 1795473 controller.go:195] "Failed to update lease" err="Put \"https://192.168.4.63:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:28 masternode kubelet[1795473]: E0913 12:42:28.813282 1795473 controller.go:195] "Failed to update lease" err="Put \"https://192.168.4.63:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:28 masternode kubelet[1795473]: E0913 12:42:28.813978 1795473 controller.go:195] "Failed to update lease" err="Put \"https://192.168.4.63:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:28 masternode kubelet[1795473]: E0913 12:42:28.814593 1795473 controller.go:195] "Failed to update lease" err="Put \"https://192.168.4.63:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:28 masternode kubelet[1795473]: I0913 12:42:28.814664 1795473 controller.go:115] "failed to update lease using latest lease, fallback to ensure lease" err="failed 5 attempts to update lease"
Sep 13 12:42:28 masternode kubelet[1795473]: E0913 12:42:28.815395 1795473 controller.go:145] "Failed to ensure lease exists, will retry" err="Get \"https://192.168.4.63:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused" interval="200ms"
Sep 13 12:42:29 masternode kubelet[1795473]: E0913 12:42:29.017428 1795473 controller.go:145] "Failed to ensure lease exists, will retry" err="Get \"https://192.168.4.63:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused" interval="400ms"
Sep 13 12:42:29 masternode kubelet[1795473]: E0913 12:42:29.350734 1795473 kubelet_node_status.go:544] "Error updating node status, will retry" err="error getting node \"masternode\": Get \"https://192.168.4.63:6443/api/v1/nodes/masternode?resourceVersion=0&timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:29 masternode kubelet[1795473]: E0913 12:42:29.351412 1795473 kubelet_node_status.go:544] "Error updating node status, will retry" err="error getting node \"masternode\": Get \"https://192.168.4.63:6443/api/v1/nodes/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:29 masternode kubelet[1795473]: E0913 12:42:29.352118 1795473 kubelet_node_status.go:544] "Error updating node status, will retry" err="error getting node \"masternode\": Get \"https://192.168.4.63:6443/api/v1/nodes/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:29 masternode kubelet[1795473]: E0913 12:42:29.352856 1795473 kubelet_node_status.go:544] "Error updating node status, will retry" err="error getting node \"masternode\": Get \"https://192.168.4.63:6443/api/v1/nodes/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:29 masternode kubelet[1795473]: E0913 12:42:29.353530 1795473 kubelet_node_status.go:544] "Error updating node status, will retry" err="error getting node \"masternode\": Get \"https://192.168.4.63:6443/api/v1/nodes/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:29 masternode kubelet[1795473]: E0913 12:42:29.353582 1795473 kubelet_node_status.go:531] "Unable to update node status" err="update node status exceeds retry count"
Sep 13 12:42:29 masternode kubelet[1795473]: E0913 12:42:29.418880 1795473 controller.go:145] "Failed to ensure lease exists, will retry" err="Get \"https://192.168.4.63:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused" interval="800ms"
Sep 13 12:42:30 masternode kubelet[1795473]: E0913 12:42:30.219642 1795473 controller.go:145] "Failed to ensure lease exists, will retry" err="Get \"https://192.168.4.63:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused" interval="1.6s"
Sep 13 12:42:31 masternode kubelet[1795473]: E0913 12:42:31.820848 1795473 controller.go:145] "Failed to ensure lease exists, will retry" err="Get \"https://192.168.4.63:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused" interval="3.2s"
Sep 13 12:42:35 masternode kubelet[1795473]: E0913 12:42:35.021594 1795473 controller.go:145] "Failed to ensure lease exists, will retry" err="Get \"https://192.168.4.63:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused" interval="6.4s"
Sep 13 12:42:38 masternode kubelet[1795473]: E0913 12:42:38.219992 1795473 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://192.168.4.63:6443/api/v1/namespaces/kube-system/events\": dial tcp 192.168.4.63:6443: connect: connection refused" event="&Event{ObjectMeta:{kube-scheduler-masternode.1864e5322b4d2fb9  kube-system    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Pod,Namespace:kube-system,Name:kube-scheduler-masternode,UID:14dedf7322adec20b2d7fe90ea829fab,APIVersion:v1,ResourceVersion:,FieldPath:spec.containers{kube-scheduler},},Reason:Unhealthy,Message:Liveness probe failed: Get \"https://127.0.0.1:10259/healthz\": dial tcp 127.0.0.1:10259: connect: connection refused,Source:EventSource{Component:kubelet,Host:masternode,},FirstTimestamp:2025-09-13 12:42:38.218940345 -0400 EDT m=+152.096480298,LastTimestamp:2025-09-13 12:42:38.218940345 -0400 EDT m=+152.096480298,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kubelet,ReportingInstance:masternode,}"
Sep 13 12:42:38 masternode kubelet[1795473]: I0913 12:42:38.677257 1795473 scope.go:117] "RemoveContainer" containerID="4b5b7af4997d52d6f371b690a2ede750edf82fbe4098947b619bb43f1c56abe3"
Sep 13 12:42:38 masternode kubelet[1795473]: I0913 12:42:38.677744 1795473 status_manager.go:853] "Failed to get status for pod" podUID="14dedf7322adec20b2d7fe90ea829fab" pod="kube-system/kube-scheduler-masternode" err="Get \"https://192.168.4.63:6443/api/v1/namespaces/kube-system/pods/kube-scheduler-masternode\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:38 masternode kubelet[1795473]: I0913 12:42:38.681807 1795473 scope.go:117] "RemoveContainer" containerID="0b83583226cc8dff891d962abcc1a0354de91bd9bb8b9f1af73e469d9496635e"
Sep 13 12:42:38 masternode kubelet[1795473]: I0913 12:42:38.682390 1795473 status_manager.go:853] "Failed to get status for pod" podUID="310b6c94507e75997ff41605f87056ba" pod="kube-system/kube-controller-manager-masternode" err="Get \"https://192.168.4.63:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-masternode\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:38 masternode kubelet[1795473]: I0913 12:42:38.683640 1795473 status_manager.go:853] "Failed to get status for pod" podUID="14dedf7322adec20b2d7fe90ea829fab" pod="kube-system/kube-scheduler-masternode" err="Get \"https://192.168.4.63:6443/api/v1/namespaces/kube-system/pods/kube-scheduler-masternode\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:39 masternode kubelet[1795473]: E0913 12:42:39.640499 1795473 kubelet_node_status.go:544] "Error updating node status, will retry" err="error getting node \"masternode\": Get \"https://192.168.4.63:6443/api/v1/nodes/masternode?resourceVersion=0&timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:39 masternode kubelet[1795473]: E0913 12:42:39.640733 1795473 kubelet_node_status.go:544] "Error updating node status, will retry" err="error getting node \"masternode\": Get \"https://192.168.4.63:6443/api/v1/nodes/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:39 masternode kubelet[1795473]: E0913 12:42:39.640932 1795473 kubelet_node_status.go:544] "Error updating node status, will retry" err="error getting node \"masternode\": Get \"https://192.168.4.63:6443/api/v1/nodes/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:39 masternode kubelet[1795473]: E0913 12:42:39.641138 1795473 kubelet_node_status.go:544] "Error updating node status, will retry" err="error getting node \"masternode\": Get \"https://192.168.4.63:6443/api/v1/nodes/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:39 masternode kubelet[1795473]: E0913 12:42:39.641328 1795473 kubelet_node_status.go:544] "Error updating node status, will retry" err="error getting node \"masternode\": Get \"https://192.168.4.63:6443/api/v1/nodes/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:39 masternode kubelet[1795473]: E0913 12:42:39.641346 1795473 kubelet_node_status.go:531] "Unable to update node status" err="update node status exceeds retry count"
Sep 13 12:42:39 masternode kubelet[1795473]: I0913 12:42:39.685013 1795473 status_manager.go:853] "Failed to get status for pod" podUID="310b6c94507e75997ff41605f87056ba" pod="kube-system/kube-controller-manager-masternode" err="Get \"https://192.168.4.63:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-masternode\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:39 masternode kubelet[1795473]: I0913 12:42:39.685335 1795473 status_manager.go:853] "Failed to get status for pod" podUID="14dedf7322adec20b2d7fe90ea829fab" pod="kube-system/kube-scheduler-masternode" err="Get \"https://192.168.4.63:6443/api/v1/namespaces/kube-system/pods/kube-scheduler-masternode\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:39 masternode kubelet[1795473]: I0913 12:42:39.686760 1795473 status_manager.go:853] "Failed to get status for pod" podUID="310b6c94507e75997ff41605f87056ba" pod="kube-system/kube-controller-manager-masternode" err="Get \"https://192.168.4.63:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-masternode\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:39 masternode kubelet[1795473]: I0913 12:42:39.686995 1795473 status_manager.go:853] "Failed to get status for pod" podUID="14dedf7322adec20b2d7fe90ea829fab" pod="kube-system/kube-scheduler-masternode" err="Get \"https://192.168.4.63:6443/api/v1/namespaces/kube-system/pods/kube-scheduler-masternode\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:41 masternode kubelet[1795473]: E0913 12:42:41.422961 1795473 controller.go:145] "Failed to ensure lease exists, will retry" err="Get \"https://192.168.4.63:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused" interval="7s"
Sep 13 12:42:46 masternode kubelet[1795473]: I0913 12:42:46.252560 1795473 status_manager.go:853] "Failed to get status for pod" podUID="310b6c94507e75997ff41605f87056ba" pod="kube-system/kube-controller-manager-masternode" err="Get \"https://192.168.4.63:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-masternode\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:46 masternode kubelet[1795473]: I0913 12:42:46.254294 1795473 status_manager.go:853] "Failed to get status for pod" podUID="14dedf7322adec20b2d7fe90ea829fab" pod="kube-system/kube-scheduler-masternode" err="Get \"https://192.168.4.63:6443/api/v1/namespaces/kube-system/pods/kube-scheduler-masternode\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:47 masternode kubelet[1795473]: E0913 12:42:47.091323 1795473 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://192.168.4.63:6443/api/v1/namespaces/kube-system/events\": dial tcp 192.168.4.63:6443: connect: connection refused" event="&Event{ObjectMeta:{kube-scheduler-masternode.1864e5322b4d2fb9  kube-system    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Pod,Namespace:kube-system,Name:kube-scheduler-masternode,UID:14dedf7322adec20b2d7fe90ea829fab,APIVersion:v1,ResourceVersion:,FieldPath:spec.containers{kube-scheduler},},Reason:Unhealthy,Message:Liveness probe failed: Get \"https://127.0.0.1:10259/healthz\": dial tcp 127.0.0.1:10259: connect: connection refused,Source:EventSource{Component:kubelet,Host:masternode,},FirstTimestamp:2025-09-13 12:42:38.218940345 -0400 EDT m=+152.096480298,LastTimestamp:2025-09-13 12:42:38.218940345 -0400 EDT m=+152.096480298,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kubelet,ReportingInstance:masternode,}"
Sep 13 12:42:48 masternode kubelet[1795473]: E0913 12:42:48.424401 1795473 controller.go:145] "Failed to ensure lease exists, will retry" err="Get \"https://192.168.4.63:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused" interval="7s"
Sep 13 12:42:49 masternode kubelet[1795473]: I0913 12:42:49.388170 1795473 status_manager.go:853] "Failed to get status for pod" podUID="310b6c94507e75997ff41605f87056ba" pod="kube-system/kube-controller-manager-masternode" err="Get \"https://192.168.4.63:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-masternode\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:49 masternode kubelet[1795473]: I0913 12:42:49.388994 1795473 status_manager.go:853] "Failed to get status for pod" podUID="14dedf7322adec20b2d7fe90ea829fab" pod="kube-system/kube-scheduler-masternode" err="Get \"https://192.168.4.63:6443/api/v1/namespaces/kube-system/pods/kube-scheduler-masternode\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:49 masternode kubelet[1795473]: I0913 12:42:49.715173 1795473 status_manager.go:853] "Failed to get status for pod" podUID="310b6c94507e75997ff41605f87056ba" pod="kube-system/kube-controller-manager-masternode" err="Get \"https://192.168.4.63:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-masternode\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:49 masternode kubelet[1795473]: I0913 12:42:49.715929 1795473 status_manager.go:853] "Failed to get status for pod" podUID="14dedf7322adec20b2d7fe90ea829fab" pod="kube-system/kube-scheduler-masternode" err="Get \"https://192.168.4.63:6443/api/v1/namespaces/kube-system/pods/kube-scheduler-masternode\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:49 masternode kubelet[1795473]: E0913 12:42:49.973468 1795473 kubelet_node_status.go:544] "Error updating node status, will retry" err="error getting node \"masternode\": Get \"https://192.168.4.63:6443/api/v1/nodes/masternode?resourceVersion=0&timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:49 masternode kubelet[1795473]: E0913 12:42:49.974264 1795473 kubelet_node_status.go:544] "Error updating node status, will retry" err="error getting node \"masternode\": Get \"https://192.168.4.63:6443/api/v1/nodes/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:49 masternode kubelet[1795473]: E0913 12:42:49.974994 1795473 kubelet_node_status.go:544] "Error updating node status, will retry" err="error getting node \"masternode\": Get \"https://192.168.4.63:6443/api/v1/nodes/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:49 masternode kubelet[1795473]: E0913 12:42:49.975696 1795473 kubelet_node_status.go:544] "Error updating node status, will retry" err="error getting node \"masternode\": Get \"https://192.168.4.63:6443/api/v1/nodes/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:49 masternode kubelet[1795473]: E0913 12:42:49.976455 1795473 kubelet_node_status.go:544] "Error updating node status, will retry" err="error getting node \"masternode\": Get \"https://192.168.4.63:6443/api/v1/nodes/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:49 masternode kubelet[1795473]: E0913 12:42:49.976501 1795473 kubelet_node_status.go:531] "Unable to update node status" err="update node status exceeds retry count"
Sep 13 12:42:54 masternode kubelet[1795473]: I0913 12:42:54.690242 1795473 status_manager.go:853] "Failed to get status for pod" podUID="310b6c94507e75997ff41605f87056ba" pod="kube-system/kube-controller-manager-masternode" err="Get \"https://192.168.4.63:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-masternode\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:54 masternode kubelet[1795473]: I0913 12:42:54.690943 1795473 status_manager.go:853] "Failed to get status for pod" podUID="14dedf7322adec20b2d7fe90ea829fab" pod="kube-system/kube-scheduler-masternode" err="Get \"https://192.168.4.63:6443/api/v1/namespaces/kube-system/pods/kube-scheduler-masternode\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:54 masternode kubelet[1795473]: I0913 12:42:54.691628 1795473 status_manager.go:853] "Failed to get status for pod" podUID="310b6c94507e75997ff41605f87056ba" pod="kube-system/kube-controller-manager-masternode" err="Get \"https://192.168.4.63:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-masternode\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:54 masternode kubelet[1795473]: I0913 12:42:54.692347 1795473 status_manager.go:853] "Failed to get status for pod" podUID="14dedf7322adec20b2d7fe90ea829fab" pod="kube-system/kube-scheduler-masternode" err="Get \"https://192.168.4.63:6443/api/v1/namespaces/kube-system/pods/kube-scheduler-masternode\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:55 masternode kubelet[1795473]: E0913 12:42:55.426012 1795473 controller.go:145] "Failed to ensure lease exists, will retry" err="Get \"https://192.168.4.63:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/masternode?timeout=10s\": dial tcp 192.168.4.63:6443: connect: connection refused" interval="7s"
Sep 13 12:42:56 masternode kubelet[1795473]: I0913 12:42:56.253244 1795473 status_manager.go:853] "Failed to get status for pod" podUID="310b6c94507e75997ff41605f87056ba" pod="kube-system/kube-controller-manager-masternode" err="Get \"https://192.168.4.63:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-masternode\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:56 masternode kubelet[1795473]: I0913 12:42:56.254031 1795473 status_manager.go:853] "Failed to get status for pod" podUID="14dedf7322adec20b2d7fe90ea829fab" pod="kube-system/kube-scheduler-masternode" err="Get \"https://192.168.4.63:6443/api/v1/namespaces/kube-system/pods/kube-scheduler-masternode\": dial tcp 192.168.4.63:6443: connect: connection refused"
Sep 13 12:42:57 masternode kubelet[1795473]: E0913 12:42:57.092313 1795473 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://192.168.4.63:6443/api/v1/namespaces/kube-system/events\": dial tcp 192.168.4.63:6443: connect: connection refused" event="&Event{ObjectMeta:{kube-scheduler-masternode.1864e5322b4d2fb9  kube-system    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Pod,Namespace:kube-system,Name:kube-scheduler-masternode,UID:14dedf7322adec20b2d7fe90ea829fab,APIVersion:v1,ResourceVersion:,FieldPath:spec.containers{kube-scheduler},},Reason:Unhealthy,Message:Liveness probe failed: Get \"https://127.0.0.1:10259/healthz\": dial tcp 127.0.0.1:10259: connect: connection refused,Source:EventSource{Component:kubelet,Host:masternode,},FirstTimestamp:2025-09-13 12:42:38.218940345 -0400 EDT m=+152.096480298,LastTimestamp:2025-09-13 12:42:38.218940345 -0400 EDT m=+152.096480298,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kubelet,ReportingInstance:masternode,}"
Sep 13 12:42:58 masternode kubelet[1795473]: E0913 12:42:58.802551 1795473 reflector.go:147] object-"kube-system"/"coredns": Failed to watch *v1.ConfigMap: unknown (get configmaps)
Sep 13 12:42:58 masternode kubelet[1795473]: E0913 12:42:58.805833 1795473 reflector.go:147] object-"kube-flannel"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: unknown (get configmaps)
Sep 13 12:42:58 masternode kubelet[1795473]: E0913 12:42:58.805967 1795473 reflector.go:147] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: unknown (get configmaps)
Sep 13 12:42:58 masternode kubelet[1795473]: E0913 12:42:58.805999 1795473 reflector.go:147] object-"kube-system"/"kube-proxy": Failed to watch *v1.ConfigMap: unknown (get configmaps)
Sep 13 12:42:58 masternode kubelet[1795473]: E0913 12:42:58.806070 1795473 reflector.go:147] object-"kube-flannel"/"kube-flannel-cfg": Failed to watch *v1.ConfigMap: unknown (get configmaps)
Sep 13 13:00:17 masternode kubelet[1795473]: E0913 13:00:17.115536 1795473 remote_runtime.go:407] "ListContainers with filter from runtime service failed" err="rpc error: code = Unknown desc = server is not initialized yet" filter="&ContainerFilter{Id:,State:nil,PodSandboxId:,LabelSelector:map[string]string{},}"
Sep 13 13:00:17 masternode kubelet[1795473]: E0913 13:00:17.115571 1795473 container_log_manager.go:185] "Failed to rotate container logs" err="failed to list containers: rpc error: code = Unknown desc = server is not initialized yet"
Sep 13 13:18:04 masternode kubelet[1795473]: E0913 13:18:04.253696 1795473 remote_runtime.go:294] "ListPodSandbox with filter from runtime service failed" err="rpc error: code = Unknown desc = server is not initialized yet" filter="&PodSandboxFilter{Id:,State:&PodSandboxStateValue{State:SANDBOX_READY,},LabelSelector:map[string]string{},}"
Sep 13 13:18:04 masternode kubelet[1795473]: E0913 13:18:04.253731 1795473 kuberuntime_sandbox.go:297] "Failed to list pod sandboxes" err="rpc error: code = Unknown desc = server is not initialized yet"
Sep 13 13:18:04 masternode kubelet[1795473]: E0913 13:18:04.253750 1795473 kubelet_pods.go:1090] "Error listing containers" err="rpc error: code = Unknown desc = server is not initialized yet"
Sep 13 13:18:04 masternode kubelet[1795473]: E0913 13:18:04.253769 1795473 kubelet.go:2517] "Failed cleaning pods" err="rpc error: code = Unknown desc = server is not initialized yet"
Sep 13 13:19:39 masternode kubelet[1795473]: I0913 13:19:39.988046 1795473 topology_manager.go:215] "Topology Admit Handler" podUID="49db131f-35a7-4620-98d1-0ee4383c0180" podNamespace="kube-flannel" podName="kube-flannel-ds-mj8rt"
Sep 13 13:19:39 masternode kubelet[1795473]: E0913 13:19:39.988753 1795473 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="a1d2f391-8fb9-4982-8de5-d45f9005e2d1" containerName="coredns"
Sep 13 13:19:39 masternode kubelet[1795473]: E0913 13:19:39.988865 1795473 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="3735d286-9507-4d83-8eef-3612f89371a6" containerName="install-cni"
Sep 13 13:19:39 masternode kubelet[1795473]: E0913 13:19:39.988952 1795473 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="3735d286-9507-4d83-8eef-3612f89371a6" containerName="install-cni-plugin"
Sep 13 13:19:39 masternode kubelet[1795473]: E0913 13:19:39.989041 1795473 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="3735d286-9507-4d83-8eef-3612f89371a6" containerName="kube-flannel"
Sep 13 13:19:39 masternode kubelet[1795473]: E0913 13:19:39.989060 1795473 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="fab2956a-e71d-4751-b624-e2dea4e72bde" containerName="coredns"
Sep 13 13:19:39 masternode kubelet[1795473]: I0913 13:19:39.989098 1795473 memory_manager.go:354] "RemoveStaleState removing state" podUID="a1d2f391-8fb9-4982-8de5-d45f9005e2d1" containerName="coredns"
Sep 13 13:19:39 masternode kubelet[1795473]: I0913 13:19:39.989111 1795473 memory_manager.go:354] "RemoveStaleState removing state" podUID="3735d286-9507-4d83-8eef-3612f89371a6" containerName="kube-flannel"
Sep 13 13:19:39 masternode kubelet[1795473]: I0913 13:19:39.989120 1795473 memory_manager.go:354] "RemoveStaleState removing state" podUID="fab2956a-e71d-4751-b624-e2dea4e72bde" containerName="coredns"
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.068986 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/3735d286-9507-4d83-8eef-3612f89371a6-run" (OuterVolumeSpecName: "run") pod "3735d286-9507-4d83-8eef-3612f89371a6" (UID: "3735d286-9507-4d83-8eef-3612f89371a6"). InnerVolumeSpecName "run". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.069005 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"run\" (UniqueName: \"kubernetes.io/host-path/3735d286-9507-4d83-8eef-3612f89371a6-run\") pod \"3735d286-9507-4d83-8eef-3612f89371a6\" (UID: \"3735d286-9507-4d83-8eef-3612f89371a6\") "
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.069079 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"kube-api-access-vg4vk\" (UniqueName: \"kubernetes.io/projected/3735d286-9507-4d83-8eef-3612f89371a6-kube-api-access-vg4vk\") pod \"3735d286-9507-4d83-8eef-3612f89371a6\" (UID: \"3735d286-9507-4d83-8eef-3612f89371a6\") "
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.069101 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"cni\" (UniqueName: \"kubernetes.io/host-path/3735d286-9507-4d83-8eef-3612f89371a6-cni\") pod \"3735d286-9507-4d83-8eef-3612f89371a6\" (UID: \"3735d286-9507-4d83-8eef-3612f89371a6\") "
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.069123 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"flannel-cfg\" (UniqueName: \"kubernetes.io/configmap/3735d286-9507-4d83-8eef-3612f89371a6-flannel-cfg\") pod \"3735d286-9507-4d83-8eef-3612f89371a6\" (UID: \"3735d286-9507-4d83-8eef-3612f89371a6\") "
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.069140 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"cni-plugin\" (UniqueName: \"kubernetes.io/host-path/3735d286-9507-4d83-8eef-3612f89371a6-cni-plugin\") pod \"3735d286-9507-4d83-8eef-3612f89371a6\" (UID: \"3735d286-9507-4d83-8eef-3612f89371a6\") "
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.069166 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/3735d286-9507-4d83-8eef-3612f89371a6-xtables-lock\") pod \"3735d286-9507-4d83-8eef-3612f89371a6\" (UID: \"3735d286-9507-4d83-8eef-3612f89371a6\") "
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.069226 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"run\" (UniqueName: \"kubernetes.io/host-path/49db131f-35a7-4620-98d1-0ee4383c0180-run\") pod \"kube-flannel-ds-mj8rt\" (UID: \"49db131f-35a7-4620-98d1-0ee4383c0180\") " pod="kube-flannel/kube-flannel-ds-mj8rt"
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.069252 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cni-plugin\" (UniqueName: \"kubernetes.io/host-path/49db131f-35a7-4620-98d1-0ee4383c0180-cni-plugin\") pod \"kube-flannel-ds-mj8rt\" (UID: \"49db131f-35a7-4620-98d1-0ee4383c0180\") " pod="kube-flannel/kube-flannel-ds-mj8rt"
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.069273 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/49db131f-35a7-4620-98d1-0ee4383c0180-xtables-lock\") pod \"kube-flannel-ds-mj8rt\" (UID: \"49db131f-35a7-4620-98d1-0ee4383c0180\") " pod="kube-flannel/kube-flannel-ds-mj8rt"
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.069290 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"flannel-cfg\" (UniqueName: \"kubernetes.io/configmap/49db131f-35a7-4620-98d1-0ee4383c0180-flannel-cfg\") pod \"kube-flannel-ds-mj8rt\" (UID: \"49db131f-35a7-4620-98d1-0ee4383c0180\") " pod="kube-flannel/kube-flannel-ds-mj8rt"
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.069310 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cni\" (UniqueName: \"kubernetes.io/host-path/49db131f-35a7-4620-98d1-0ee4383c0180-cni\") pod \"kube-flannel-ds-mj8rt\" (UID: \"49db131f-35a7-4620-98d1-0ee4383c0180\") " pod="kube-flannel/kube-flannel-ds-mj8rt"
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.069334 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-xwt6v\" (UniqueName: \"kubernetes.io/projected/49db131f-35a7-4620-98d1-0ee4383c0180-kube-api-access-xwt6v\") pod \"kube-flannel-ds-mj8rt\" (UID: \"49db131f-35a7-4620-98d1-0ee4383c0180\") " pod="kube-flannel/kube-flannel-ds-mj8rt"
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.069353 1795473 reconciler_common.go:305] "Volume detached for volume \"run\" (UniqueName: \"kubernetes.io/host-path/3735d286-9507-4d83-8eef-3612f89371a6-run\") on node \"masternode\" DevicePath \"\""
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.069977 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/3735d286-9507-4d83-8eef-3612f89371a6-cni-plugin" (OuterVolumeSpecName: "cni-plugin") pod "3735d286-9507-4d83-8eef-3612f89371a6" (UID: "3735d286-9507-4d83-8eef-3612f89371a6"). InnerVolumeSpecName "cni-plugin". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.070013 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/configmap/3735d286-9507-4d83-8eef-3612f89371a6-flannel-cfg" (OuterVolumeSpecName: "flannel-cfg") pod "3735d286-9507-4d83-8eef-3612f89371a6" (UID: "3735d286-9507-4d83-8eef-3612f89371a6"). InnerVolumeSpecName "flannel-cfg". PluginName "kubernetes.io/configmap", VolumeGidValue ""
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.070042 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/3735d286-9507-4d83-8eef-3612f89371a6-cni" (OuterVolumeSpecName: "cni") pod "3735d286-9507-4d83-8eef-3612f89371a6" (UID: "3735d286-9507-4d83-8eef-3612f89371a6"). InnerVolumeSpecName "cni". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.070085 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/3735d286-9507-4d83-8eef-3612f89371a6-xtables-lock" (OuterVolumeSpecName: "xtables-lock") pod "3735d286-9507-4d83-8eef-3612f89371a6" (UID: "3735d286-9507-4d83-8eef-3612f89371a6"). InnerVolumeSpecName "xtables-lock". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.071488 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/3735d286-9507-4d83-8eef-3612f89371a6-kube-api-access-vg4vk" (OuterVolumeSpecName: "kube-api-access-vg4vk") pod "3735d286-9507-4d83-8eef-3612f89371a6" (UID: "3735d286-9507-4d83-8eef-3612f89371a6"). InnerVolumeSpecName "kube-api-access-vg4vk". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.170022 1795473 reconciler_common.go:305] "Volume detached for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/3735d286-9507-4d83-8eef-3612f89371a6-xtables-lock\") on node \"masternode\" DevicePath \"\""
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.170258 1795473 reconciler_common.go:305] "Volume detached for volume \"kube-api-access-vg4vk\" (UniqueName: \"kubernetes.io/projected/3735d286-9507-4d83-8eef-3612f89371a6-kube-api-access-vg4vk\") on node \"masternode\" DevicePath \"\""
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.170370 1795473 reconciler_common.go:305] "Volume detached for volume \"cni\" (UniqueName: \"kubernetes.io/host-path/3735d286-9507-4d83-8eef-3612f89371a6-cni\") on node \"masternode\" DevicePath \"\""
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.170480 1795473 reconciler_common.go:305] "Volume detached for volume \"cni-plugin\" (UniqueName: \"kubernetes.io/host-path/3735d286-9507-4d83-8eef-3612f89371a6-cni-plugin\") on node \"masternode\" DevicePath \"\""
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.170597 1795473 reconciler_common.go:305] "Volume detached for volume \"flannel-cfg\" (UniqueName: \"kubernetes.io/configmap/3735d286-9507-4d83-8eef-3612f89371a6-flannel-cfg\") on node \"masternode\" DevicePath \"\""
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.600561 1795473 scope.go:117] "RemoveContainer" containerID="3d7dd05d469e86465c97e2cf9a73968d88fa5bf492736fe4b568a601116e5f29"
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.635286 1795473 scope.go:117] "RemoveContainer" containerID="66a6f28b4a0b5c33ea6b1128e7e4e70ec003f1ca72646012b2fb42754bb2d577"
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.655562 1795473 scope.go:117] "RemoveContainer" containerID="25d7ddeebbb04abe6cc58ee10c79e4953bb0ff1fe5db848d79304f3750d90fa5"
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.667097 1795473 scope.go:117] "RemoveContainer" containerID="3d7dd05d469e86465c97e2cf9a73968d88fa5bf492736fe4b568a601116e5f29"
Sep 13 13:19:40 masternode kubelet[1795473]: E0913 13:19:40.667560 1795473 remote_runtime.go:432] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"3d7dd05d469e86465c97e2cf9a73968d88fa5bf492736fe4b568a601116e5f29\": not found" containerID="3d7dd05d469e86465c97e2cf9a73968d88fa5bf492736fe4b568a601116e5f29"
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.667611 1795473 pod_container_deletor.go:53] "DeleteContainer returned error" containerID={"Type":"containerd","ID":"3d7dd05d469e86465c97e2cf9a73968d88fa5bf492736fe4b568a601116e5f29"} err="failed to get container status \"3d7dd05d469e86465c97e2cf9a73968d88fa5bf492736fe4b568a601116e5f29\": rpc error: code = NotFound desc = an error occurred when try to find container \"3d7dd05d469e86465c97e2cf9a73968d88fa5bf492736fe4b568a601116e5f29\": not found"
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.667636 1795473 scope.go:117] "RemoveContainer" containerID="66a6f28b4a0b5c33ea6b1128e7e4e70ec003f1ca72646012b2fb42754bb2d577"
Sep 13 13:19:40 masternode kubelet[1795473]: E0913 13:19:40.668052 1795473 remote_runtime.go:432] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"66a6f28b4a0b5c33ea6b1128e7e4e70ec003f1ca72646012b2fb42754bb2d577\": not found" containerID="66a6f28b4a0b5c33ea6b1128e7e4e70ec003f1ca72646012b2fb42754bb2d577"
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.668099 1795473 pod_container_deletor.go:53] "DeleteContainer returned error" containerID={"Type":"containerd","ID":"66a6f28b4a0b5c33ea6b1128e7e4e70ec003f1ca72646012b2fb42754bb2d577"} err="failed to get container status \"66a6f28b4a0b5c33ea6b1128e7e4e70ec003f1ca72646012b2fb42754bb2d577\": rpc error: code = NotFound desc = an error occurred when try to find container \"66a6f28b4a0b5c33ea6b1128e7e4e70ec003f1ca72646012b2fb42754bb2d577\": not found"
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.668120 1795473 scope.go:117] "RemoveContainer" containerID="25d7ddeebbb04abe6cc58ee10c79e4953bb0ff1fe5db848d79304f3750d90fa5"
Sep 13 13:19:40 masternode kubelet[1795473]: E0913 13:19:40.668505 1795473 remote_runtime.go:432] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"25d7ddeebbb04abe6cc58ee10c79e4953bb0ff1fe5db848d79304f3750d90fa5\": not found" containerID="25d7ddeebbb04abe6cc58ee10c79e4953bb0ff1fe5db848d79304f3750d90fa5"
Sep 13 13:19:40 masternode kubelet[1795473]: I0913 13:19:40.668547 1795473 pod_container_deletor.go:53] "DeleteContainer returned error" containerID={"Type":"containerd","ID":"25d7ddeebbb04abe6cc58ee10c79e4953bb0ff1fe5db848d79304f3750d90fa5"} err="failed to get container status \"25d7ddeebbb04abe6cc58ee10c79e4953bb0ff1fe5db848d79304f3750d90fa5\": rpc error: code = NotFound desc = an error occurred when try to find container \"25d7ddeebbb04abe6cc58ee10c79e4953bb0ff1fe5db848d79304f3750d90fa5\": not found"
Sep 13 13:19:42 masternode kubelet[1795473]: I0913 13:19:42.258811 1795473 kubelet_volumes.go:163] "Cleaned up orphaned pod volumes dir" podUID="3735d286-9507-4d83-8eef-3612f89371a6" path="/var/lib/kubelet/pods/3735d286-9507-4d83-8eef-3612f89371a6/volumes"
Sep 13 13:19:43 masternode kubelet[1795473]: I0913 13:19:43.627684 1795473 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-flannel/kube-flannel-ds-mj8rt" podStartSLOduration=4.627630418 podStartE2EDuration="4.627630418s" podCreationTimestamp="2025-09-13 13:19:39 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-09-13 13:19:43.627535608 -0400 EDT m=+2377.505075520" watchObservedRunningTime="2025-09-13 13:19:43.627630418 -0400 EDT m=+2377.505170339"
Sep 13 13:20:01 masternode kubelet[1795473]: I0913 13:20:01.587048 1795473 topology_manager.go:215] "Topology Admit Handler" podUID="51613b7c-ed24-4002-b4c2-6777650c54a6" podNamespace="monitoring" podName="prometheus-5bbc459489-lbv2q"
Sep 13 13:20:01 masternode kubelet[1795473]: I0913 13:20:01.698121 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-m2r8r\" (UniqueName: \"kubernetes.io/projected/51613b7c-ed24-4002-b4c2-6777650c54a6-kube-api-access-m2r8r\") pod \"prometheus-5bbc459489-lbv2q\" (UID: \"51613b7c-ed24-4002-b4c2-6777650c54a6\") " pod="monitoring/prometheus-5bbc459489-lbv2q"
Sep 13 13:20:01 masternode kubelet[1795473]: I0913 13:20:01.698185 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"prometheus-storage\" (UniqueName: \"kubernetes.io/empty-dir/51613b7c-ed24-4002-b4c2-6777650c54a6-prometheus-storage\") pod \"prometheus-5bbc459489-lbv2q\" (UID: \"51613b7c-ed24-4002-b4c2-6777650c54a6\") " pod="monitoring/prometheus-5bbc459489-lbv2q"
Sep 13 13:20:01 masternode kubelet[1795473]: I0913 13:20:01.698232 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"prometheus-config\" (UniqueName: \"kubernetes.io/configmap/51613b7c-ed24-4002-b4c2-6777650c54a6-prometheus-config\") pod \"prometheus-5bbc459489-lbv2q\" (UID: \"51613b7c-ed24-4002-b4c2-6777650c54a6\") " pod="monitoring/prometheus-5bbc459489-lbv2q"
Sep 13 13:20:02 masternode kubelet[1795473]: I0913 13:20:02.487544 1795473 topology_manager.go:215] "Topology Admit Handler" podUID="05b7e739-c96a-4a72-a0ae-38430d5079fc" podNamespace="monitoring" podName="grafana-79747fbd7-9jdsf"
Sep 13 13:20:02 masternode kubelet[1795473]: I0913 13:20:02.604459 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"grafana-datasources\" (UniqueName: \"kubernetes.io/configmap/05b7e739-c96a-4a72-a0ae-38430d5079fc-grafana-datasources\") pod \"grafana-79747fbd7-9jdsf\" (UID: \"05b7e739-c96a-4a72-a0ae-38430d5079fc\") " pod="monitoring/grafana-79747fbd7-9jdsf"
Sep 13 13:20:02 masternode kubelet[1795473]: I0913 13:20:02.604509 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"grafana-storage\" (UniqueName: \"kubernetes.io/empty-dir/05b7e739-c96a-4a72-a0ae-38430d5079fc-grafana-storage\") pod \"grafana-79747fbd7-9jdsf\" (UID: \"05b7e739-c96a-4a72-a0ae-38430d5079fc\") " pod="monitoring/grafana-79747fbd7-9jdsf"
Sep 13 13:20:02 masternode kubelet[1795473]: I0913 13:20:02.604542 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"grafana-dashboard-providers\" (UniqueName: \"kubernetes.io/configmap/05b7e739-c96a-4a72-a0ae-38430d5079fc-grafana-dashboard-providers\") pod \"grafana-79747fbd7-9jdsf\" (UID: \"05b7e739-c96a-4a72-a0ae-38430d5079fc\") " pod="monitoring/grafana-79747fbd7-9jdsf"
Sep 13 13:20:02 masternode kubelet[1795473]: I0913 13:20:02.604581 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"grafana-dashboard-kubernetes\" (UniqueName: \"kubernetes.io/configmap/05b7e739-c96a-4a72-a0ae-38430d5079fc-grafana-dashboard-kubernetes\") pod \"grafana-79747fbd7-9jdsf\" (UID: \"05b7e739-c96a-4a72-a0ae-38430d5079fc\") " pod="monitoring/grafana-79747fbd7-9jdsf"
Sep 13 13:20:02 masternode kubelet[1795473]: I0913 13:20:02.604617 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-mpdbn\" (UniqueName: \"kubernetes.io/projected/05b7e739-c96a-4a72-a0ae-38430d5079fc-kube-api-access-mpdbn\") pod \"grafana-79747fbd7-9jdsf\" (UID: \"05b7e739-c96a-4a72-a0ae-38430d5079fc\") " pod="monitoring/grafana-79747fbd7-9jdsf"
Sep 13 13:20:03 masternode kubelet[1795473]: I0913 13:20:03.665847 1795473 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="monitoring/grafana-79747fbd7-9jdsf" podStartSLOduration=1.6657923829999999 podStartE2EDuration="1.665792383s" podCreationTimestamp="2025-09-13 13:20:02 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-09-13 13:20:03.665546066 -0400 EDT m=+2397.543085983" watchObservedRunningTime="2025-09-13 13:20:03.665792383 -0400 EDT m=+2397.543332289"
Sep 13 13:20:03 masternode kubelet[1795473]: I0913 13:20:03.665971 1795473 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="monitoring/prometheus-5bbc459489-lbv2q" podStartSLOduration=2.665942233 podStartE2EDuration="2.665942233s" podCreationTimestamp="2025-09-13 13:20:01 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-09-13 13:20:02.660056521 -0400 EDT m=+2396.537596433" watchObservedRunningTime="2025-09-13 13:20:03.665942233 -0400 EDT m=+2397.543482137"
Sep 13 14:14:58 masternode kubelet[1795473]: I0913 14:14:58.316119 1795473 topology_manager.go:215] "Topology Admit Handler" podUID="420a725e-8ff4-4aa3-8c15-23b64e1a5117" podNamespace="kube-system" podName="kube-proxy-vfhhh"
Sep 13 14:14:58 masternode kubelet[1795473]: E0913 14:14:58.316254 1795473 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="22ac925e-0fd7-46eb-a7dc-c33a6e626bef" containerName="kube-proxy"
Sep 13 14:14:58 masternode kubelet[1795473]: I0913 14:14:58.316302 1795473 memory_manager.go:354] "RemoveStaleState removing state" podUID="22ac925e-0fd7-46eb-a7dc-c33a6e626bef" containerName="kube-proxy"
Sep 13 14:14:58 masternode kubelet[1795473]: I0913 14:14:58.389304 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/22ac925e-0fd7-46eb-a7dc-c33a6e626bef-kube-proxy\") pod \"22ac925e-0fd7-46eb-a7dc-c33a6e626bef\" (UID: \"22ac925e-0fd7-46eb-a7dc-c33a6e626bef\") "
Sep 13 14:14:58 masternode kubelet[1795473]: I0913 14:14:58.389352 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/22ac925e-0fd7-46eb-a7dc-c33a6e626bef-xtables-lock\") pod \"22ac925e-0fd7-46eb-a7dc-c33a6e626bef\" (UID: \"22ac925e-0fd7-46eb-a7dc-c33a6e626bef\") "
Sep 13 14:14:58 masternode kubelet[1795473]: I0913 14:14:58.389398 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/22ac925e-0fd7-46eb-a7dc-c33a6e626bef-lib-modules\") pod \"22ac925e-0fd7-46eb-a7dc-c33a6e626bef\" (UID: \"22ac925e-0fd7-46eb-a7dc-c33a6e626bef\") "
Sep 13 14:14:58 masternode kubelet[1795473]: I0913 14:14:58.389457 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/22ac925e-0fd7-46eb-a7dc-c33a6e626bef-lib-modules" (OuterVolumeSpecName: "lib-modules") pod "22ac925e-0fd7-46eb-a7dc-c33a6e626bef" (UID: "22ac925e-0fd7-46eb-a7dc-c33a6e626bef"). InnerVolumeSpecName "lib-modules". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Sep 13 14:14:58 masternode kubelet[1795473]: I0913 14:14:58.389468 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/22ac925e-0fd7-46eb-a7dc-c33a6e626bef-xtables-lock" (OuterVolumeSpecName: "xtables-lock") pod "22ac925e-0fd7-46eb-a7dc-c33a6e626bef" (UID: "22ac925e-0fd7-46eb-a7dc-c33a6e626bef"). InnerVolumeSpecName "xtables-lock". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Sep 13 14:14:58 masternode kubelet[1795473]: I0913 14:14:58.389521 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"kube-api-access-8625s\" (UniqueName: \"kubernetes.io/projected/22ac925e-0fd7-46eb-a7dc-c33a6e626bef-kube-api-access-8625s\") pod \"22ac925e-0fd7-46eb-a7dc-c33a6e626bef\" (UID: \"22ac925e-0fd7-46eb-a7dc-c33a6e626bef\") "
Sep 13 14:14:58 masternode kubelet[1795473]: I0913 14:14:58.389634 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-vvjsg\" (UniqueName: \"kubernetes.io/projected/420a725e-8ff4-4aa3-8c15-23b64e1a5117-kube-api-access-vvjsg\") pod \"kube-proxy-vfhhh\" (UID: \"420a725e-8ff4-4aa3-8c15-23b64e1a5117\") " pod="kube-system/kube-proxy-vfhhh"
Sep 13 14:14:58 masternode kubelet[1795473]: I0913 14:14:58.389671 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/420a725e-8ff4-4aa3-8c15-23b64e1a5117-lib-modules\") pod \"kube-proxy-vfhhh\" (UID: \"420a725e-8ff4-4aa3-8c15-23b64e1a5117\") " pod="kube-system/kube-proxy-vfhhh"
Sep 13 14:14:58 masternode kubelet[1795473]: I0913 14:14:58.389759 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/420a725e-8ff4-4aa3-8c15-23b64e1a5117-kube-proxy\") pod \"kube-proxy-vfhhh\" (UID: \"420a725e-8ff4-4aa3-8c15-23b64e1a5117\") " pod="kube-system/kube-proxy-vfhhh"
Sep 13 14:14:58 masternode kubelet[1795473]: I0913 14:14:58.389874 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/420a725e-8ff4-4aa3-8c15-23b64e1a5117-xtables-lock\") pod \"kube-proxy-vfhhh\" (UID: \"420a725e-8ff4-4aa3-8c15-23b64e1a5117\") " pod="kube-system/kube-proxy-vfhhh"
Sep 13 14:14:58 masternode kubelet[1795473]: I0913 14:14:58.389957 1795473 reconciler_common.go:305] "Volume detached for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/22ac925e-0fd7-46eb-a7dc-c33a6e626bef-lib-modules\") on node \"masternode\" DevicePath \"\""
Sep 13 14:14:58 masternode kubelet[1795473]: I0913 14:14:58.389993 1795473 reconciler_common.go:305] "Volume detached for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/22ac925e-0fd7-46eb-a7dc-c33a6e626bef-xtables-lock\") on node \"masternode\" DevicePath \"\""
Sep 13 14:14:58 masternode kubelet[1795473]: I0913 14:14:58.390558 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/configmap/22ac925e-0fd7-46eb-a7dc-c33a6e626bef-kube-proxy" (OuterVolumeSpecName: "kube-proxy") pod "22ac925e-0fd7-46eb-a7dc-c33a6e626bef" (UID: "22ac925e-0fd7-46eb-a7dc-c33a6e626bef"). InnerVolumeSpecName "kube-proxy". PluginName "kubernetes.io/configmap", VolumeGidValue ""
Sep 13 14:14:58 masternode kubelet[1795473]: I0913 14:14:58.392428 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/22ac925e-0fd7-46eb-a7dc-c33a6e626bef-kube-api-access-8625s" (OuterVolumeSpecName: "kube-api-access-8625s") pod "22ac925e-0fd7-46eb-a7dc-c33a6e626bef" (UID: "22ac925e-0fd7-46eb-a7dc-c33a6e626bef"). InnerVolumeSpecName "kube-api-access-8625s". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 13 14:14:58 masternode kubelet[1795473]: I0913 14:14:58.490851 1795473 reconciler_common.go:305] "Volume detached for volume \"kube-api-access-8625s\" (UniqueName: \"kubernetes.io/projected/22ac925e-0fd7-46eb-a7dc-c33a6e626bef-kube-api-access-8625s\") on node \"masternode\" DevicePath \"\""
Sep 13 14:14:58 masternode kubelet[1795473]: I0913 14:14:58.490905 1795473 reconciler_common.go:305] "Volume detached for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/22ac925e-0fd7-46eb-a7dc-c33a6e626bef-kube-proxy\") on node \"masternode\" DevicePath \"\""
Sep 13 14:14:58 masternode kubelet[1795473]: I0913 14:14:58.970709 1795473 scope.go:117] "RemoveContainer" containerID="34bf61cfea13b4c38cc7703f63078b32332f76f4813c13118fd8f6fdeb9cb5ce"
Sep 13 14:14:58 masternode kubelet[1795473]: I0913 14:14:58.985078 1795473 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-proxy-vfhhh" podStartSLOduration=0.985024241 podStartE2EDuration="985.024241ms" podCreationTimestamp="2025-09-13 14:14:58 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-09-13 14:14:58.984500064 -0400 EDT m=+5692.862039977" watchObservedRunningTime="2025-09-13 14:14:58.985024241 -0400 EDT m=+5692.862564163"
Sep 13 14:14:58 masternode kubelet[1795473]: I0913 14:14:58.988433 1795473 scope.go:117] "RemoveContainer" containerID="34bf61cfea13b4c38cc7703f63078b32332f76f4813c13118fd8f6fdeb9cb5ce"
Sep 13 14:14:58 masternode kubelet[1795473]: E0913 14:14:58.988930 1795473 remote_runtime.go:432] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"34bf61cfea13b4c38cc7703f63078b32332f76f4813c13118fd8f6fdeb9cb5ce\": not found" containerID="34bf61cfea13b4c38cc7703f63078b32332f76f4813c13118fd8f6fdeb9cb5ce"
Sep 13 14:14:58 masternode kubelet[1795473]: I0913 14:14:58.988985 1795473 pod_container_deletor.go:53] "DeleteContainer returned error" containerID={"Type":"containerd","ID":"34bf61cfea13b4c38cc7703f63078b32332f76f4813c13118fd8f6fdeb9cb5ce"} err="failed to get container status \"34bf61cfea13b4c38cc7703f63078b32332f76f4813c13118fd8f6fdeb9cb5ce\": rpc error: code = NotFound desc = an error occurred when try to find container \"34bf61cfea13b4c38cc7703f63078b32332f76f4813c13118fd8f6fdeb9cb5ce\": not found"
Sep 13 14:15:00 masternode kubelet[1795473]: I0913 14:15:00.254498 1795473 kubelet_volumes.go:163] "Cleaned up orphaned pod volumes dir" podUID="22ac925e-0fd7-46eb-a7dc-c33a6e626bef" path="/var/lib/kubelet/pods/22ac925e-0fd7-46eb-a7dc-c33a6e626bef/volumes"
Sep 13 14:15:15 masternode kubelet[1795473]: I0913 14:15:15.822199 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"kube-api-access-q982r\" (UniqueName: \"kubernetes.io/projected/c0086d83-f0d2-400d-bee8-01d9807210fe-kube-api-access-q982r\") pod \"c0086d83-f0d2-400d-bee8-01d9807210fe\" (UID: \"c0086d83-f0d2-400d-bee8-01d9807210fe\") "
Sep 13 14:15:15 masternode kubelet[1795473]: I0913 14:15:15.822276 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/c0086d83-f0d2-400d-bee8-01d9807210fe-config-volume\") pod \"c0086d83-f0d2-400d-bee8-01d9807210fe\" (UID: \"c0086d83-f0d2-400d-bee8-01d9807210fe\") "
Sep 13 14:15:15 masternode kubelet[1795473]: I0913 14:15:15.823474 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/configmap/c0086d83-f0d2-400d-bee8-01d9807210fe-config-volume" (OuterVolumeSpecName: "config-volume") pod "c0086d83-f0d2-400d-bee8-01d9807210fe" (UID: "c0086d83-f0d2-400d-bee8-01d9807210fe"). InnerVolumeSpecName "config-volume". PluginName "kubernetes.io/configmap", VolumeGidValue ""
Sep 13 14:15:15 masternode kubelet[1795473]: I0913 14:15:15.825309 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/c0086d83-f0d2-400d-bee8-01d9807210fe-kube-api-access-q982r" (OuterVolumeSpecName: "kube-api-access-q982r") pod "c0086d83-f0d2-400d-bee8-01d9807210fe" (UID: "c0086d83-f0d2-400d-bee8-01d9807210fe"). InnerVolumeSpecName "kube-api-access-q982r". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 13 14:15:15 masternode kubelet[1795473]: I0913 14:15:15.922920 1795473 reconciler_common.go:305] "Volume detached for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/c0086d83-f0d2-400d-bee8-01d9807210fe-config-volume\") on node \"masternode\" DevicePath \"\""
Sep 13 14:15:15 masternode kubelet[1795473]: I0913 14:15:15.922962 1795473 reconciler_common.go:305] "Volume detached for volume \"kube-api-access-q982r\" (UniqueName: \"kubernetes.io/projected/c0086d83-f0d2-400d-bee8-01d9807210fe-kube-api-access-q982r\") on node \"masternode\" DevicePath \"\""
Sep 13 14:15:16 masternode kubelet[1795473]: I0913 14:15:16.022182 1795473 scope.go:117] "RemoveContainer" containerID="ddc5e8b4dcd414a990e0ab8bb699ed120a470350c42a711d393c26ee79160c62"
Sep 13 14:15:16 masternode kubelet[1795473]: I0913 14:15:16.036386 1795473 scope.go:117] "RemoveContainer" containerID="ddc5e8b4dcd414a990e0ab8bb699ed120a470350c42a711d393c26ee79160c62"
Sep 13 14:15:16 masternode kubelet[1795473]: E0913 14:15:16.036732 1795473 remote_runtime.go:432] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"ddc5e8b4dcd414a990e0ab8bb699ed120a470350c42a711d393c26ee79160c62\": not found" containerID="ddc5e8b4dcd414a990e0ab8bb699ed120a470350c42a711d393c26ee79160c62"
Sep 13 14:15:16 masternode kubelet[1795473]: I0913 14:15:16.036771 1795473 pod_container_deletor.go:53] "DeleteContainer returned error" containerID={"Type":"containerd","ID":"ddc5e8b4dcd414a990e0ab8bb699ed120a470350c42a711d393c26ee79160c62"} err="failed to get container status \"ddc5e8b4dcd414a990e0ab8bb699ed120a470350c42a711d393c26ee79160c62\": rpc error: code = NotFound desc = an error occurred when try to find container \"ddc5e8b4dcd414a990e0ab8bb699ed120a470350c42a711d393c26ee79160c62\": not found"
Sep 13 14:15:16 masternode kubelet[1795473]: I0913 14:15:16.255157 1795473 kubelet_volumes.go:163] "Cleaned up orphaned pod volumes dir" podUID="c0086d83-f0d2-400d-bee8-01d9807210fe" path="/var/lib/kubelet/pods/c0086d83-f0d2-400d-bee8-01d9807210fe/volumes"
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.310108 1795473 topology_manager.go:215] "Topology Admit Handler" podUID="4cf49b2e-350d-4c47-a7d5-4c1d1649b5af" podNamespace="kube-flannel" podName="kube-flannel-ds-jzh7t"
Sep 13 14:20:43 masternode kubelet[1795473]: E0913 14:20:43.310185 1795473 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="49db131f-35a7-4620-98d1-0ee4383c0180" containerName="kube-flannel"
Sep 13 14:20:43 masternode kubelet[1795473]: E0913 14:20:43.310203 1795473 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="c0086d83-f0d2-400d-bee8-01d9807210fe" containerName="coredns"
Sep 13 14:20:43 masternode kubelet[1795473]: E0913 14:20:43.310218 1795473 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="49db131f-35a7-4620-98d1-0ee4383c0180" containerName="install-cni-plugin"
Sep 13 14:20:43 masternode kubelet[1795473]: E0913 14:20:43.310228 1795473 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="49db131f-35a7-4620-98d1-0ee4383c0180" containerName="install-cni"
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.310261 1795473 memory_manager.go:354] "RemoveStaleState removing state" podUID="49db131f-35a7-4620-98d1-0ee4383c0180" containerName="kube-flannel"
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.310275 1795473 memory_manager.go:354] "RemoveStaleState removing state" podUID="c0086d83-f0d2-400d-bee8-01d9807210fe" containerName="coredns"
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.446589 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-cgd54\" (UniqueName: \"kubernetes.io/projected/4cf49b2e-350d-4c47-a7d5-4c1d1649b5af-kube-api-access-cgd54\") pod \"kube-flannel-ds-jzh7t\" (UID: \"4cf49b2e-350d-4c47-a7d5-4c1d1649b5af\") " pod="kube-flannel/kube-flannel-ds-jzh7t"
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.446646 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"flannel-cfg\" (UniqueName: \"kubernetes.io/configmap/4cf49b2e-350d-4c47-a7d5-4c1d1649b5af-flannel-cfg\") pod \"kube-flannel-ds-jzh7t\" (UID: \"4cf49b2e-350d-4c47-a7d5-4c1d1649b5af\") " pod="kube-flannel/kube-flannel-ds-jzh7t"
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.446689 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"run\" (UniqueName: \"kubernetes.io/host-path/4cf49b2e-350d-4c47-a7d5-4c1d1649b5af-run\") pod \"kube-flannel-ds-jzh7t\" (UID: \"4cf49b2e-350d-4c47-a7d5-4c1d1649b5af\") " pod="kube-flannel/kube-flannel-ds-jzh7t"
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.446719 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cni-plugin\" (UniqueName: \"kubernetes.io/host-path/4cf49b2e-350d-4c47-a7d5-4c1d1649b5af-cni-plugin\") pod \"kube-flannel-ds-jzh7t\" (UID: \"4cf49b2e-350d-4c47-a7d5-4c1d1649b5af\") " pod="kube-flannel/kube-flannel-ds-jzh7t"
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.446762 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cni\" (UniqueName: \"kubernetes.io/host-path/4cf49b2e-350d-4c47-a7d5-4c1d1649b5af-cni\") pod \"kube-flannel-ds-jzh7t\" (UID: \"4cf49b2e-350d-4c47-a7d5-4c1d1649b5af\") " pod="kube-flannel/kube-flannel-ds-jzh7t"
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.446815 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/4cf49b2e-350d-4c47-a7d5-4c1d1649b5af-xtables-lock\") pod \"kube-flannel-ds-jzh7t\" (UID: \"4cf49b2e-350d-4c47-a7d5-4c1d1649b5af\") " pod="kube-flannel/kube-flannel-ds-jzh7t"
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.547941 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"flannel-cfg\" (UniqueName: \"kubernetes.io/configmap/49db131f-35a7-4620-98d1-0ee4383c0180-flannel-cfg\") pod \"49db131f-35a7-4620-98d1-0ee4383c0180\" (UID: \"49db131f-35a7-4620-98d1-0ee4383c0180\") "
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.547990 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"kube-api-access-xwt6v\" (UniqueName: \"kubernetes.io/projected/49db131f-35a7-4620-98d1-0ee4383c0180-kube-api-access-xwt6v\") pod \"49db131f-35a7-4620-98d1-0ee4383c0180\" (UID: \"49db131f-35a7-4620-98d1-0ee4383c0180\") "
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.548031 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"cni-plugin\" (UniqueName: \"kubernetes.io/host-path/49db131f-35a7-4620-98d1-0ee4383c0180-cni-plugin\") pod \"49db131f-35a7-4620-98d1-0ee4383c0180\" (UID: \"49db131f-35a7-4620-98d1-0ee4383c0180\") "
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.548058 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"run\" (UniqueName: \"kubernetes.io/host-path/49db131f-35a7-4620-98d1-0ee4383c0180-run\") pod \"49db131f-35a7-4620-98d1-0ee4383c0180\" (UID: \"49db131f-35a7-4620-98d1-0ee4383c0180\") "
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.548095 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/49db131f-35a7-4620-98d1-0ee4383c0180-xtables-lock\") pod \"49db131f-35a7-4620-98d1-0ee4383c0180\" (UID: \"49db131f-35a7-4620-98d1-0ee4383c0180\") "
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.548134 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"cni\" (UniqueName: \"kubernetes.io/host-path/49db131f-35a7-4620-98d1-0ee4383c0180-cni\") pod \"49db131f-35a7-4620-98d1-0ee4383c0180\" (UID: \"49db131f-35a7-4620-98d1-0ee4383c0180\") "
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.548580 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/49db131f-35a7-4620-98d1-0ee4383c0180-xtables-lock" (OuterVolumeSpecName: "xtables-lock") pod "49db131f-35a7-4620-98d1-0ee4383c0180" (UID: "49db131f-35a7-4620-98d1-0ee4383c0180"). InnerVolumeSpecName "xtables-lock". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.548662 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/49db131f-35a7-4620-98d1-0ee4383c0180-cni" (OuterVolumeSpecName: "cni") pod "49db131f-35a7-4620-98d1-0ee4383c0180" (UID: "49db131f-35a7-4620-98d1-0ee4383c0180"). InnerVolumeSpecName "cni". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.548667 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/49db131f-35a7-4620-98d1-0ee4383c0180-cni-plugin" (OuterVolumeSpecName: "cni-plugin") pod "49db131f-35a7-4620-98d1-0ee4383c0180" (UID: "49db131f-35a7-4620-98d1-0ee4383c0180"). InnerVolumeSpecName "cni-plugin". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.548783 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/49db131f-35a7-4620-98d1-0ee4383c0180-run" (OuterVolumeSpecName: "run") pod "49db131f-35a7-4620-98d1-0ee4383c0180" (UID: "49db131f-35a7-4620-98d1-0ee4383c0180"). InnerVolumeSpecName "run". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.549017 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/configmap/49db131f-35a7-4620-98d1-0ee4383c0180-flannel-cfg" (OuterVolumeSpecName: "flannel-cfg") pod "49db131f-35a7-4620-98d1-0ee4383c0180" (UID: "49db131f-35a7-4620-98d1-0ee4383c0180"). InnerVolumeSpecName "flannel-cfg". PluginName "kubernetes.io/configmap", VolumeGidValue ""
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.551320 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/49db131f-35a7-4620-98d1-0ee4383c0180-kube-api-access-xwt6v" (OuterVolumeSpecName: "kube-api-access-xwt6v") pod "49db131f-35a7-4620-98d1-0ee4383c0180" (UID: "49db131f-35a7-4620-98d1-0ee4383c0180"). InnerVolumeSpecName "kube-api-access-xwt6v". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.648780 1795473 reconciler_common.go:305] "Volume detached for volume \"flannel-cfg\" (UniqueName: \"kubernetes.io/configmap/49db131f-35a7-4620-98d1-0ee4383c0180-flannel-cfg\") on node \"masternode\" DevicePath \"\""
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.648818 1795473 reconciler_common.go:305] "Volume detached for volume \"kube-api-access-xwt6v\" (UniqueName: \"kubernetes.io/projected/49db131f-35a7-4620-98d1-0ee4383c0180-kube-api-access-xwt6v\") on node \"masternode\" DevicePath \"\""
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.648836 1795473 reconciler_common.go:305] "Volume detached for volume \"cni-plugin\" (UniqueName: \"kubernetes.io/host-path/49db131f-35a7-4620-98d1-0ee4383c0180-cni-plugin\") on node \"masternode\" DevicePath \"\""
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.648849 1795473 reconciler_common.go:305] "Volume detached for volume \"run\" (UniqueName: \"kubernetes.io/host-path/49db131f-35a7-4620-98d1-0ee4383c0180-run\") on node \"masternode\" DevicePath \"\""
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.648862 1795473 reconciler_common.go:305] "Volume detached for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/49db131f-35a7-4620-98d1-0ee4383c0180-xtables-lock\") on node \"masternode\" DevicePath \"\""
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.648873 1795473 reconciler_common.go:305] "Volume detached for volume \"cni\" (UniqueName: \"kubernetes.io/host-path/49db131f-35a7-4620-98d1-0ee4383c0180-cni\") on node \"masternode\" DevicePath \"\""
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.925119 1795473 scope.go:117] "RemoveContainer" containerID="90a8645cbf36eb188a3eca75a82a0b27307eb6f4ab175d8598257e8bc9aefd0a"
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.939227 1795473 scope.go:117] "RemoveContainer" containerID="f2f2dc7b4a9432f7fb665ba29aa6fbeb7477adf04e900ec306f583fe8fb9309e"
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.955898 1795473 scope.go:117] "RemoveContainer" containerID="be44b23f3fbb1813f7accc195015482d0159990e76ad649bf6ae220e36c62525"
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.972542 1795473 scope.go:117] "RemoveContainer" containerID="90a8645cbf36eb188a3eca75a82a0b27307eb6f4ab175d8598257e8bc9aefd0a"
Sep 13 14:20:43 masternode kubelet[1795473]: E0913 14:20:43.973001 1795473 remote_runtime.go:432] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"90a8645cbf36eb188a3eca75a82a0b27307eb6f4ab175d8598257e8bc9aefd0a\": not found" containerID="90a8645cbf36eb188a3eca75a82a0b27307eb6f4ab175d8598257e8bc9aefd0a"
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.973048 1795473 pod_container_deletor.go:53] "DeleteContainer returned error" containerID={"Type":"containerd","ID":"90a8645cbf36eb188a3eca75a82a0b27307eb6f4ab175d8598257e8bc9aefd0a"} err="failed to get container status \"90a8645cbf36eb188a3eca75a82a0b27307eb6f4ab175d8598257e8bc9aefd0a\": rpc error: code = NotFound desc = an error occurred when try to find container \"90a8645cbf36eb188a3eca75a82a0b27307eb6f4ab175d8598257e8bc9aefd0a\": not found"
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.973066 1795473 scope.go:117] "RemoveContainer" containerID="f2f2dc7b4a9432f7fb665ba29aa6fbeb7477adf04e900ec306f583fe8fb9309e"
Sep 13 14:20:43 masternode kubelet[1795473]: E0913 14:20:43.973441 1795473 remote_runtime.go:432] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"f2f2dc7b4a9432f7fb665ba29aa6fbeb7477adf04e900ec306f583fe8fb9309e\": not found" containerID="f2f2dc7b4a9432f7fb665ba29aa6fbeb7477adf04e900ec306f583fe8fb9309e"
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.973480 1795473 pod_container_deletor.go:53] "DeleteContainer returned error" containerID={"Type":"containerd","ID":"f2f2dc7b4a9432f7fb665ba29aa6fbeb7477adf04e900ec306f583fe8fb9309e"} err="failed to get container status \"f2f2dc7b4a9432f7fb665ba29aa6fbeb7477adf04e900ec306f583fe8fb9309e\": rpc error: code = NotFound desc = an error occurred when try to find container \"f2f2dc7b4a9432f7fb665ba29aa6fbeb7477adf04e900ec306f583fe8fb9309e\": not found"
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.973499 1795473 scope.go:117] "RemoveContainer" containerID="be44b23f3fbb1813f7accc195015482d0159990e76ad649bf6ae220e36c62525"
Sep 13 14:20:43 masternode kubelet[1795473]: E0913 14:20:43.973817 1795473 remote_runtime.go:432] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"be44b23f3fbb1813f7accc195015482d0159990e76ad649bf6ae220e36c62525\": not found" containerID="be44b23f3fbb1813f7accc195015482d0159990e76ad649bf6ae220e36c62525"
Sep 13 14:20:43 masternode kubelet[1795473]: I0913 14:20:43.973844 1795473 pod_container_deletor.go:53] "DeleteContainer returned error" containerID={"Type":"containerd","ID":"be44b23f3fbb1813f7accc195015482d0159990e76ad649bf6ae220e36c62525"} err="failed to get container status \"be44b23f3fbb1813f7accc195015482d0159990e76ad649bf6ae220e36c62525\": rpc error: code = NotFound desc = an error occurred when try to find container \"be44b23f3fbb1813f7accc195015482d0159990e76ad649bf6ae220e36c62525\": not found"
Sep 13 14:20:44 masternode kubelet[1795473]: I0913 14:20:44.254012 1795473 kubelet_volumes.go:163] "Cleaned up orphaned pod volumes dir" podUID="49db131f-35a7-4620-98d1-0ee4383c0180" path="/var/lib/kubelet/pods/49db131f-35a7-4620-98d1-0ee4383c0180/volumes"
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.289207 1795473 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-flannel/kube-flannel-ds-jzh7t" podStartSLOduration=499.289075112 podStartE2EDuration="8m19.289075112s" podCreationTimestamp="2025-09-13 14:20:43 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-09-13 14:20:46.958606216 -0400 EDT m=+6040.836146118" watchObservedRunningTime="2025-09-13 14:29:02.289075112 -0400 EDT m=+6536.166615080"
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.478768 1795473 topology_manager.go:215] "Topology Admit Handler" podUID="6880a041-6398-401b-8525-c37d46489b70" podNamespace="kube-flannel" podName="kube-flannel-ds-vk9mg"
Sep 13 14:29:02 masternode kubelet[1795473]: E0913 14:29:02.478845 1795473 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="4cf49b2e-350d-4c47-a7d5-4c1d1649b5af" containerName="install-cni"
Sep 13 14:29:02 masternode kubelet[1795473]: E0913 14:29:02.478865 1795473 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="4cf49b2e-350d-4c47-a7d5-4c1d1649b5af" containerName="kube-flannel"
Sep 13 14:29:02 masternode kubelet[1795473]: E0913 14:29:02.478878 1795473 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="4cf49b2e-350d-4c47-a7d5-4c1d1649b5af" containerName="install-cni-plugin"
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.478911 1795473 memory_manager.go:354] "RemoveStaleState removing state" podUID="4cf49b2e-350d-4c47-a7d5-4c1d1649b5af" containerName="kube-flannel"
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.487734 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"kube-api-access-cgd54\" (UniqueName: \"kubernetes.io/projected/4cf49b2e-350d-4c47-a7d5-4c1d1649b5af-kube-api-access-cgd54\") pod \"4cf49b2e-350d-4c47-a7d5-4c1d1649b5af\" (UID: \"4cf49b2e-350d-4c47-a7d5-4c1d1649b5af\") "
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.487784 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"cni-plugin\" (UniqueName: \"kubernetes.io/host-path/4cf49b2e-350d-4c47-a7d5-4c1d1649b5af-cni-plugin\") pod \"4cf49b2e-350d-4c47-a7d5-4c1d1649b5af\" (UID: \"4cf49b2e-350d-4c47-a7d5-4c1d1649b5af\") "
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.488468 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"flannel-cfg\" (UniqueName: \"kubernetes.io/configmap/4cf49b2e-350d-4c47-a7d5-4c1d1649b5af-flannel-cfg\") pod \"4cf49b2e-350d-4c47-a7d5-4c1d1649b5af\" (UID: \"4cf49b2e-350d-4c47-a7d5-4c1d1649b5af\") "
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.488515 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"cni\" (UniqueName: \"kubernetes.io/host-path/4cf49b2e-350d-4c47-a7d5-4c1d1649b5af-cni\") pod \"4cf49b2e-350d-4c47-a7d5-4c1d1649b5af\" (UID: \"4cf49b2e-350d-4c47-a7d5-4c1d1649b5af\") "
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.488551 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/4cf49b2e-350d-4c47-a7d5-4c1d1649b5af-xtables-lock\") pod \"4cf49b2e-350d-4c47-a7d5-4c1d1649b5af\" (UID: \"4cf49b2e-350d-4c47-a7d5-4c1d1649b5af\") "
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.488582 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"run\" (UniqueName: \"kubernetes.io/host-path/4cf49b2e-350d-4c47-a7d5-4c1d1649b5af-run\") pod \"4cf49b2e-350d-4c47-a7d5-4c1d1649b5af\" (UID: \"4cf49b2e-350d-4c47-a7d5-4c1d1649b5af\") "
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.488662 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/4cf49b2e-350d-4c47-a7d5-4c1d1649b5af-run" (OuterVolumeSpecName: "run") pod "4cf49b2e-350d-4c47-a7d5-4c1d1649b5af" (UID: "4cf49b2e-350d-4c47-a7d5-4c1d1649b5af"). InnerVolumeSpecName "run". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.488703 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/4cf49b2e-350d-4c47-a7d5-4c1d1649b5af-cni-plugin" (OuterVolumeSpecName: "cni-plugin") pod "4cf49b2e-350d-4c47-a7d5-4c1d1649b5af" (UID: "4cf49b2e-350d-4c47-a7d5-4c1d1649b5af"). InnerVolumeSpecName "cni-plugin". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.489147 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/configmap/4cf49b2e-350d-4c47-a7d5-4c1d1649b5af-flannel-cfg" (OuterVolumeSpecName: "flannel-cfg") pod "4cf49b2e-350d-4c47-a7d5-4c1d1649b5af" (UID: "4cf49b2e-350d-4c47-a7d5-4c1d1649b5af"). InnerVolumeSpecName "flannel-cfg". PluginName "kubernetes.io/configmap", VolumeGidValue ""
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.489194 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/4cf49b2e-350d-4c47-a7d5-4c1d1649b5af-cni" (OuterVolumeSpecName: "cni") pod "4cf49b2e-350d-4c47-a7d5-4c1d1649b5af" (UID: "4cf49b2e-350d-4c47-a7d5-4c1d1649b5af"). InnerVolumeSpecName "cni". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.489223 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/4cf49b2e-350d-4c47-a7d5-4c1d1649b5af-xtables-lock" (OuterVolumeSpecName: "xtables-lock") pod "4cf49b2e-350d-4c47-a7d5-4c1d1649b5af" (UID: "4cf49b2e-350d-4c47-a7d5-4c1d1649b5af"). InnerVolumeSpecName "xtables-lock". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.495329 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/4cf49b2e-350d-4c47-a7d5-4c1d1649b5af-kube-api-access-cgd54" (OuterVolumeSpecName: "kube-api-access-cgd54") pod "4cf49b2e-350d-4c47-a7d5-4c1d1649b5af" (UID: "4cf49b2e-350d-4c47-a7d5-4c1d1649b5af"). InnerVolumeSpecName "kube-api-access-cgd54". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.589516 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-dbvjk\" (UniqueName: \"kubernetes.io/projected/6880a041-6398-401b-8525-c37d46489b70-kube-api-access-dbvjk\") pod \"kube-flannel-ds-vk9mg\" (UID: \"6880a041-6398-401b-8525-c37d46489b70\") " pod="kube-flannel/kube-flannel-ds-vk9mg"
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.589609 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cni\" (UniqueName: \"kubernetes.io/host-path/6880a041-6398-401b-8525-c37d46489b70-cni\") pod \"kube-flannel-ds-vk9mg\" (UID: \"6880a041-6398-401b-8525-c37d46489b70\") " pod="kube-flannel/kube-flannel-ds-vk9mg"
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.589650 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"flannel-cfg\" (UniqueName: \"kubernetes.io/configmap/6880a041-6398-401b-8525-c37d46489b70-flannel-cfg\") pod \"kube-flannel-ds-vk9mg\" (UID: \"6880a041-6398-401b-8525-c37d46489b70\") " pod="kube-flannel/kube-flannel-ds-vk9mg"
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.589678 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"run\" (UniqueName: \"kubernetes.io/host-path/6880a041-6398-401b-8525-c37d46489b70-run\") pod \"kube-flannel-ds-vk9mg\" (UID: \"6880a041-6398-401b-8525-c37d46489b70\") " pod="kube-flannel/kube-flannel-ds-vk9mg"
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.589715 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cni-plugin\" (UniqueName: \"kubernetes.io/host-path/6880a041-6398-401b-8525-c37d46489b70-cni-plugin\") pod \"kube-flannel-ds-vk9mg\" (UID: \"6880a041-6398-401b-8525-c37d46489b70\") " pod="kube-flannel/kube-flannel-ds-vk9mg"
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.589804 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/6880a041-6398-401b-8525-c37d46489b70-xtables-lock\") pod \"kube-flannel-ds-vk9mg\" (UID: \"6880a041-6398-401b-8525-c37d46489b70\") " pod="kube-flannel/kube-flannel-ds-vk9mg"
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.589865 1795473 reconciler_common.go:305] "Volume detached for volume \"kube-api-access-cgd54\" (UniqueName: \"kubernetes.io/projected/4cf49b2e-350d-4c47-a7d5-4c1d1649b5af-kube-api-access-cgd54\") on node \"masternode\" DevicePath \"\""
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.589897 1795473 reconciler_common.go:305] "Volume detached for volume \"cni-plugin\" (UniqueName: \"kubernetes.io/host-path/4cf49b2e-350d-4c47-a7d5-4c1d1649b5af-cni-plugin\") on node \"masternode\" DevicePath \"\""
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.589925 1795473 reconciler_common.go:305] "Volume detached for volume \"flannel-cfg\" (UniqueName: \"kubernetes.io/configmap/4cf49b2e-350d-4c47-a7d5-4c1d1649b5af-flannel-cfg\") on node \"masternode\" DevicePath \"\""
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.589949 1795473 reconciler_common.go:305] "Volume detached for volume \"cni\" (UniqueName: \"kubernetes.io/host-path/4cf49b2e-350d-4c47-a7d5-4c1d1649b5af-cni\") on node \"masternode\" DevicePath \"\""
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.589971 1795473 reconciler_common.go:305] "Volume detached for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/4cf49b2e-350d-4c47-a7d5-4c1d1649b5af-xtables-lock\") on node \"masternode\" DevicePath \"\""
Sep 13 14:29:02 masternode kubelet[1795473]: I0913 14:29:02.589993 1795473 reconciler_common.go:305] "Volume detached for volume \"run\" (UniqueName: \"kubernetes.io/host-path/4cf49b2e-350d-4c47-a7d5-4c1d1649b5af-run\") on node \"masternode\" DevicePath \"\""
Sep 13 14:29:03 masternode kubelet[1795473]: I0913 14:29:03.248877 1795473 scope.go:117] "RemoveContainer" containerID="50352268387147cb336c0b330648f2d44835ffd29ebc8391237c987ef287150f"
Sep 13 14:29:03 masternode kubelet[1795473]: I0913 14:29:03.273817 1795473 scope.go:117] "RemoveContainer" containerID="efdbada3baa46f8ce24f2e9494c7e4e6104544a1e7ab754895175be75e61401a"
Sep 13 14:29:03 masternode kubelet[1795473]: I0913 14:29:03.292433 1795473 scope.go:117] "RemoveContainer" containerID="1880c8975d68414cc88269a6c75ecd9cc67b0170c8d1b7f24fc1fe2200a55da7"
Sep 13 14:29:03 masternode kubelet[1795473]: I0913 14:29:03.305221 1795473 scope.go:117] "RemoveContainer" containerID="50352268387147cb336c0b330648f2d44835ffd29ebc8391237c987ef287150f"
Sep 13 14:29:03 masternode kubelet[1795473]: E0913 14:29:03.305617 1795473 remote_runtime.go:432] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"50352268387147cb336c0b330648f2d44835ffd29ebc8391237c987ef287150f\": not found" containerID="50352268387147cb336c0b330648f2d44835ffd29ebc8391237c987ef287150f"
Sep 13 14:29:03 masternode kubelet[1795473]: I0913 14:29:03.305647 1795473 pod_container_deletor.go:53] "DeleteContainer returned error" containerID={"Type":"containerd","ID":"50352268387147cb336c0b330648f2d44835ffd29ebc8391237c987ef287150f"} err="failed to get container status \"50352268387147cb336c0b330648f2d44835ffd29ebc8391237c987ef287150f\": rpc error: code = NotFound desc = an error occurred when try to find container \"50352268387147cb336c0b330648f2d44835ffd29ebc8391237c987ef287150f\": not found"
Sep 13 14:29:03 masternode kubelet[1795473]: I0913 14:29:03.305657 1795473 scope.go:117] "RemoveContainer" containerID="efdbada3baa46f8ce24f2e9494c7e4e6104544a1e7ab754895175be75e61401a"
Sep 13 14:29:03 masternode kubelet[1795473]: E0913 14:29:03.306385 1795473 remote_runtime.go:432] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"efdbada3baa46f8ce24f2e9494c7e4e6104544a1e7ab754895175be75e61401a\": not found" containerID="efdbada3baa46f8ce24f2e9494c7e4e6104544a1e7ab754895175be75e61401a"
Sep 13 14:29:03 masternode kubelet[1795473]: I0913 14:29:03.310749 1795473 pod_container_deletor.go:53] "DeleteContainer returned error" containerID={"Type":"containerd","ID":"efdbada3baa46f8ce24f2e9494c7e4e6104544a1e7ab754895175be75e61401a"} err="failed to get container status \"efdbada3baa46f8ce24f2e9494c7e4e6104544a1e7ab754895175be75e61401a\": rpc error: code = NotFound desc = an error occurred when try to find container \"efdbada3baa46f8ce24f2e9494c7e4e6104544a1e7ab754895175be75e61401a\": not found"
Sep 13 14:29:03 masternode kubelet[1795473]: I0913 14:29:03.310801 1795473 scope.go:117] "RemoveContainer" containerID="1880c8975d68414cc88269a6c75ecd9cc67b0170c8d1b7f24fc1fe2200a55da7"
Sep 13 14:29:03 masternode kubelet[1795473]: E0913 14:29:03.311339 1795473 remote_runtime.go:432] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"1880c8975d68414cc88269a6c75ecd9cc67b0170c8d1b7f24fc1fe2200a55da7\": not found" containerID="1880c8975d68414cc88269a6c75ecd9cc67b0170c8d1b7f24fc1fe2200a55da7"
Sep 13 14:29:03 masternode kubelet[1795473]: I0913 14:29:03.311372 1795473 pod_container_deletor.go:53] "DeleteContainer returned error" containerID={"Type":"containerd","ID":"1880c8975d68414cc88269a6c75ecd9cc67b0170c8d1b7f24fc1fe2200a55da7"} err="failed to get container status \"1880c8975d68414cc88269a6c75ecd9cc67b0170c8d1b7f24fc1fe2200a55da7\": rpc error: code = NotFound desc = an error occurred when try to find container \"1880c8975d68414cc88269a6c75ecd9cc67b0170c8d1b7f24fc1fe2200a55da7\": not found"
Sep 13 14:29:04 masternode kubelet[1795473]: I0913 14:29:04.261308 1795473 kubelet_volumes.go:163] "Cleaned up orphaned pod volumes dir" podUID="4cf49b2e-350d-4c47-a7d5-4c1d1649b5af" path="/var/lib/kubelet/pods/4cf49b2e-350d-4c47-a7d5-4c1d1649b5af/volumes"
Sep 13 14:45:25 masternode kubelet[1795473]: I0913 14:45:25.783422 1795473 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-flannel/kube-flannel-ds-vk9mg" podStartSLOduration=983.783365946 podStartE2EDuration="16m23.783365946s" podCreationTimestamp="2025-09-13 14:29:02 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-09-13 14:29:05.296955268 -0400 EDT m=+6539.174495266" watchObservedRunningTime="2025-09-13 14:45:25.783365946 -0400 EDT m=+7519.660905863"
Sep 13 14:45:25 masternode kubelet[1795473]: I0913 14:45:25.974185 1795473 topology_manager.go:215] "Topology Admit Handler" podUID="042b0a43-8184-493f-b4a1-0309e75f2ab3" podNamespace="kube-system" podName="kube-proxy-hw8p6"
Sep 13 14:45:25 masternode kubelet[1795473]: E0913 14:45:25.974261 1795473 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="420a725e-8ff4-4aa3-8c15-23b64e1a5117" containerName="kube-proxy"
Sep 13 14:45:25 masternode kubelet[1795473]: I0913 14:45:25.974303 1795473 memory_manager.go:354] "RemoveStaleState removing state" podUID="420a725e-8ff4-4aa3-8c15-23b64e1a5117" containerName="kube-proxy"
Sep 13 14:45:26 masternode kubelet[1795473]: I0913 14:45:26.062989 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/420a725e-8ff4-4aa3-8c15-23b64e1a5117-kube-proxy\") pod \"420a725e-8ff4-4aa3-8c15-23b64e1a5117\" (UID: \"420a725e-8ff4-4aa3-8c15-23b64e1a5117\") "
Sep 13 14:45:26 masternode kubelet[1795473]: I0913 14:45:26.063046 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/420a725e-8ff4-4aa3-8c15-23b64e1a5117-lib-modules\") pod \"420a725e-8ff4-4aa3-8c15-23b64e1a5117\" (UID: \"420a725e-8ff4-4aa3-8c15-23b64e1a5117\") "
Sep 13 14:45:26 masternode kubelet[1795473]: I0913 14:45:26.063095 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"kube-api-access-vvjsg\" (UniqueName: \"kubernetes.io/projected/420a725e-8ff4-4aa3-8c15-23b64e1a5117-kube-api-access-vvjsg\") pod \"420a725e-8ff4-4aa3-8c15-23b64e1a5117\" (UID: \"420a725e-8ff4-4aa3-8c15-23b64e1a5117\") "
Sep 13 14:45:26 masternode kubelet[1795473]: I0913 14:45:26.063135 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/420a725e-8ff4-4aa3-8c15-23b64e1a5117-xtables-lock\") pod \"420a725e-8ff4-4aa3-8c15-23b64e1a5117\" (UID: \"420a725e-8ff4-4aa3-8c15-23b64e1a5117\") "
Sep 13 14:45:26 masternode kubelet[1795473]: I0913 14:45:26.063252 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-mq4z9\" (UniqueName: \"kubernetes.io/projected/042b0a43-8184-493f-b4a1-0309e75f2ab3-kube-api-access-mq4z9\") pod \"kube-proxy-hw8p6\" (UID: \"042b0a43-8184-493f-b4a1-0309e75f2ab3\") " pod="kube-system/kube-proxy-hw8p6"
Sep 13 14:45:26 masternode kubelet[1795473]: I0913 14:45:26.063308 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/042b0a43-8184-493f-b4a1-0309e75f2ab3-lib-modules\") pod \"kube-proxy-hw8p6\" (UID: \"042b0a43-8184-493f-b4a1-0309e75f2ab3\") " pod="kube-system/kube-proxy-hw8p6"
Sep 13 14:45:26 masternode kubelet[1795473]: I0913 14:45:26.063362 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/042b0a43-8184-493f-b4a1-0309e75f2ab3-xtables-lock\") pod \"kube-proxy-hw8p6\" (UID: \"042b0a43-8184-493f-b4a1-0309e75f2ab3\") " pod="kube-system/kube-proxy-hw8p6"
Sep 13 14:45:26 masternode kubelet[1795473]: I0913 14:45:26.063409 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/042b0a43-8184-493f-b4a1-0309e75f2ab3-kube-proxy\") pod \"kube-proxy-hw8p6\" (UID: \"042b0a43-8184-493f-b4a1-0309e75f2ab3\") " pod="kube-system/kube-proxy-hw8p6"
Sep 13 14:45:26 masternode kubelet[1795473]: I0913 14:45:26.063490 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/420a725e-8ff4-4aa3-8c15-23b64e1a5117-xtables-lock" (OuterVolumeSpecName: "xtables-lock") pod "420a725e-8ff4-4aa3-8c15-23b64e1a5117" (UID: "420a725e-8ff4-4aa3-8c15-23b64e1a5117"). InnerVolumeSpecName "xtables-lock". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Sep 13 14:45:26 masternode kubelet[1795473]: I0913 14:45:26.063124 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/420a725e-8ff4-4aa3-8c15-23b64e1a5117-lib-modules" (OuterVolumeSpecName: "lib-modules") pod "420a725e-8ff4-4aa3-8c15-23b64e1a5117" (UID: "420a725e-8ff4-4aa3-8c15-23b64e1a5117"). InnerVolumeSpecName "lib-modules". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Sep 13 14:45:26 masternode kubelet[1795473]: I0913 14:45:26.063613 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/configmap/420a725e-8ff4-4aa3-8c15-23b64e1a5117-kube-proxy" (OuterVolumeSpecName: "kube-proxy") pod "420a725e-8ff4-4aa3-8c15-23b64e1a5117" (UID: "420a725e-8ff4-4aa3-8c15-23b64e1a5117"). InnerVolumeSpecName "kube-proxy". PluginName "kubernetes.io/configmap", VolumeGidValue ""
Sep 13 14:45:26 masternode kubelet[1795473]: I0913 14:45:26.065398 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/420a725e-8ff4-4aa3-8c15-23b64e1a5117-kube-api-access-vvjsg" (OuterVolumeSpecName: "kube-api-access-vvjsg") pod "420a725e-8ff4-4aa3-8c15-23b64e1a5117" (UID: "420a725e-8ff4-4aa3-8c15-23b64e1a5117"). InnerVolumeSpecName "kube-api-access-vvjsg". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 13 14:45:26 masternode kubelet[1795473]: I0913 14:45:26.081864 1795473 scope.go:117] "RemoveContainer" containerID="e08f780b197441d2c0f99fb4cfa238cdde9cabeb4ee699c099a1700416e73106"
Sep 13 14:45:26 masternode kubelet[1795473]: I0913 14:45:26.092861 1795473 scope.go:117] "RemoveContainer" containerID="e08f780b197441d2c0f99fb4cfa238cdde9cabeb4ee699c099a1700416e73106"
Sep 13 14:45:26 masternode kubelet[1795473]: E0913 14:45:26.093370 1795473 remote_runtime.go:432] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"e08f780b197441d2c0f99fb4cfa238cdde9cabeb4ee699c099a1700416e73106\": not found" containerID="e08f780b197441d2c0f99fb4cfa238cdde9cabeb4ee699c099a1700416e73106"
Sep 13 14:45:26 masternode kubelet[1795473]: I0913 14:45:26.093409 1795473 pod_container_deletor.go:53] "DeleteContainer returned error" containerID={"Type":"containerd","ID":"e08f780b197441d2c0f99fb4cfa238cdde9cabeb4ee699c099a1700416e73106"} err="failed to get container status \"e08f780b197441d2c0f99fb4cfa238cdde9cabeb4ee699c099a1700416e73106\": rpc error: code = NotFound desc = an error occurred when try to find container \"e08f780b197441d2c0f99fb4cfa238cdde9cabeb4ee699c099a1700416e73106\": not found"
Sep 13 14:45:26 masternode kubelet[1795473]: I0913 14:45:26.164706 1795473 reconciler_common.go:305] "Volume detached for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/420a725e-8ff4-4aa3-8c15-23b64e1a5117-lib-modules\") on node \"masternode\" DevicePath \"\""
Sep 13 14:45:26 masternode kubelet[1795473]: I0913 14:45:26.164985 1795473 reconciler_common.go:305] "Volume detached for volume \"kube-api-access-vvjsg\" (UniqueName: \"kubernetes.io/projected/420a725e-8ff4-4aa3-8c15-23b64e1a5117-kube-api-access-vvjsg\") on node \"masternode\" DevicePath \"\""
Sep 13 14:45:26 masternode kubelet[1795473]: I0913 14:45:26.165145 1795473 reconciler_common.go:305] "Volume detached for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/420a725e-8ff4-4aa3-8c15-23b64e1a5117-xtables-lock\") on node \"masternode\" DevicePath \"\""
Sep 13 14:45:26 masternode kubelet[1795473]: I0913 14:45:26.165180 1795473 reconciler_common.go:305] "Volume detached for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/420a725e-8ff4-4aa3-8c15-23b64e1a5117-kube-proxy\") on node \"masternode\" DevicePath \"\""
Sep 13 14:45:26 masternode kubelet[1795473]: I0913 14:45:26.254081 1795473 kubelet_volumes.go:163] "Cleaned up orphaned pod volumes dir" podUID="420a725e-8ff4-4aa3-8c15-23b64e1a5117" path="/var/lib/kubelet/pods/420a725e-8ff4-4aa3-8c15-23b64e1a5117/volumes"
Sep 13 14:48:42 masternode kubelet[1795473]: I0913 14:48:42.957325 1795473 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-proxy-hw8p6" podStartSLOduration=197.957252043 podStartE2EDuration="3m17.957252043s" podCreationTimestamp="2025-09-13 14:45:25 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-09-13 14:45:27.115855626 -0400 EDT m=+7520.993395535" watchObservedRunningTime="2025-09-13 14:48:42.957252043 -0400 EDT m=+7716.834791941"
Sep 13 14:48:43 masternode kubelet[1795473]: I0913 14:48:43.135085 1795473 topology_manager.go:215] "Topology Admit Handler" podUID="6a77170e-42e3-4a2f-bb7b-7983c83e7290" podNamespace="kube-system" podName="kube-proxy-2z4dg"
Sep 13 14:48:43 masternode kubelet[1795473]: E0913 14:48:43.135171 1795473 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="042b0a43-8184-493f-b4a1-0309e75f2ab3" containerName="kube-proxy"
Sep 13 14:48:43 masternode kubelet[1795473]: I0913 14:48:43.135224 1795473 memory_manager.go:354] "RemoveStaleState removing state" podUID="042b0a43-8184-493f-b4a1-0309e75f2ab3" containerName="kube-proxy"
Sep 13 14:48:43 masternode kubelet[1795473]: I0913 14:48:43.154878 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/042b0a43-8184-493f-b4a1-0309e75f2ab3-kube-proxy\") pod \"042b0a43-8184-493f-b4a1-0309e75f2ab3\" (UID: \"042b0a43-8184-493f-b4a1-0309e75f2ab3\") "
Sep 13 14:48:43 masternode kubelet[1795473]: I0913 14:48:43.154916 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/042b0a43-8184-493f-b4a1-0309e75f2ab3-lib-modules\") pod \"042b0a43-8184-493f-b4a1-0309e75f2ab3\" (UID: \"042b0a43-8184-493f-b4a1-0309e75f2ab3\") "
Sep 13 14:48:43 masternode kubelet[1795473]: I0913 14:48:43.154954 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"kube-api-access-mq4z9\" (UniqueName: \"kubernetes.io/projected/042b0a43-8184-493f-b4a1-0309e75f2ab3-kube-api-access-mq4z9\") pod \"042b0a43-8184-493f-b4a1-0309e75f2ab3\" (UID: \"042b0a43-8184-493f-b4a1-0309e75f2ab3\") "
Sep 13 14:48:43 masternode kubelet[1795473]: I0913 14:48:43.154977 1795473 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/042b0a43-8184-493f-b4a1-0309e75f2ab3-xtables-lock\") pod \"042b0a43-8184-493f-b4a1-0309e75f2ab3\" (UID: \"042b0a43-8184-493f-b4a1-0309e75f2ab3\") "
Sep 13 14:48:43 masternode kubelet[1795473]: I0913 14:48:43.155033 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/042b0a43-8184-493f-b4a1-0309e75f2ab3-lib-modules" (OuterVolumeSpecName: "lib-modules") pod "042b0a43-8184-493f-b4a1-0309e75f2ab3" (UID: "042b0a43-8184-493f-b4a1-0309e75f2ab3"). InnerVolumeSpecName "lib-modules". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Sep 13 14:48:43 masternode kubelet[1795473]: I0913 14:48:43.155043 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/042b0a43-8184-493f-b4a1-0309e75f2ab3-xtables-lock" (OuterVolumeSpecName: "xtables-lock") pod "042b0a43-8184-493f-b4a1-0309e75f2ab3" (UID: "042b0a43-8184-493f-b4a1-0309e75f2ab3"). InnerVolumeSpecName "xtables-lock". PluginName "kubernetes.io/host-path", VolumeGidValue ""
Sep 13 14:48:43 masternode kubelet[1795473]: I0913 14:48:43.155440 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/configmap/042b0a43-8184-493f-b4a1-0309e75f2ab3-kube-proxy" (OuterVolumeSpecName: "kube-proxy") pod "042b0a43-8184-493f-b4a1-0309e75f2ab3" (UID: "042b0a43-8184-493f-b4a1-0309e75f2ab3"). InnerVolumeSpecName "kube-proxy". PluginName "kubernetes.io/configmap", VolumeGidValue ""
Sep 13 14:48:43 masternode kubelet[1795473]: I0913 14:48:43.157237 1795473 operation_generator.go:887] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/042b0a43-8184-493f-b4a1-0309e75f2ab3-kube-api-access-mq4z9" (OuterVolumeSpecName: "kube-api-access-mq4z9") pod "042b0a43-8184-493f-b4a1-0309e75f2ab3" (UID: "042b0a43-8184-493f-b4a1-0309e75f2ab3"). InnerVolumeSpecName "kube-api-access-mq4z9". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 13 14:48:43 masternode kubelet[1795473]: I0913 14:48:43.255398 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/6a77170e-42e3-4a2f-bb7b-7983c83e7290-xtables-lock\") pod \"kube-proxy-2z4dg\" (UID: \"6a77170e-42e3-4a2f-bb7b-7983c83e7290\") " pod="kube-system/kube-proxy-2z4dg"
Sep 13 14:48:43 masternode kubelet[1795473]: I0913 14:48:43.255459 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-jmllk\" (UniqueName: \"kubernetes.io/projected/6a77170e-42e3-4a2f-bb7b-7983c83e7290-kube-api-access-jmllk\") pod \"kube-proxy-2z4dg\" (UID: \"6a77170e-42e3-4a2f-bb7b-7983c83e7290\") " pod="kube-system/kube-proxy-2z4dg"
Sep 13 14:48:43 masternode kubelet[1795473]: I0913 14:48:43.255499 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/6a77170e-42e3-4a2f-bb7b-7983c83e7290-lib-modules\") pod \"kube-proxy-2z4dg\" (UID: \"6a77170e-42e3-4a2f-bb7b-7983c83e7290\") " pod="kube-system/kube-proxy-2z4dg"
Sep 13 14:48:43 masternode kubelet[1795473]: I0913 14:48:43.255524 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/6a77170e-42e3-4a2f-bb7b-7983c83e7290-kube-proxy\") pod \"kube-proxy-2z4dg\" (UID: \"6a77170e-42e3-4a2f-bb7b-7983c83e7290\") " pod="kube-system/kube-proxy-2z4dg"
Sep 13 14:48:43 masternode kubelet[1795473]: I0913 14:48:43.255574 1795473 reconciler_common.go:305] "Volume detached for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/042b0a43-8184-493f-b4a1-0309e75f2ab3-kube-proxy\") on node \"masternode\" DevicePath \"\""
Sep 13 14:48:43 masternode kubelet[1795473]: I0913 14:48:43.255593 1795473 reconciler_common.go:305] "Volume detached for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/042b0a43-8184-493f-b4a1-0309e75f2ab3-lib-modules\") on node \"masternode\" DevicePath \"\""
Sep 13 14:48:43 masternode kubelet[1795473]: I0913 14:48:43.255618 1795473 reconciler_common.go:305] "Volume detached for volume \"kube-api-access-mq4z9\" (UniqueName: \"kubernetes.io/projected/042b0a43-8184-493f-b4a1-0309e75f2ab3-kube-api-access-mq4z9\") on node \"masternode\" DevicePath \"\""
Sep 13 14:48:43 masternode kubelet[1795473]: I0913 14:48:43.255645 1795473 reconciler_common.go:305] "Volume detached for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/042b0a43-8184-493f-b4a1-0309e75f2ab3-xtables-lock\") on node \"masternode\" DevicePath \"\""
Sep 13 14:48:43 masternode kubelet[1795473]: I0913 14:48:43.671171 1795473 scope.go:117] "RemoveContainer" containerID="671037d2d133ff9019a44facb1f3d6f20a93096220298e73ec0946374ea4d46d"
Sep 13 14:48:43 masternode kubelet[1795473]: I0913 14:48:43.692423 1795473 scope.go:117] "RemoveContainer" containerID="671037d2d133ff9019a44facb1f3d6f20a93096220298e73ec0946374ea4d46d"
Sep 13 14:48:43 masternode kubelet[1795473]: E0913 14:48:43.693013 1795473 remote_runtime.go:432] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"671037d2d133ff9019a44facb1f3d6f20a93096220298e73ec0946374ea4d46d\": not found" containerID="671037d2d133ff9019a44facb1f3d6f20a93096220298e73ec0946374ea4d46d"
Sep 13 14:48:43 masternode kubelet[1795473]: I0913 14:48:43.693066 1795473 pod_container_deletor.go:53] "DeleteContainer returned error" containerID={"Type":"containerd","ID":"671037d2d133ff9019a44facb1f3d6f20a93096220298e73ec0946374ea4d46d"} err="failed to get container status \"671037d2d133ff9019a44facb1f3d6f20a93096220298e73ec0946374ea4d46d\": rpc error: code = NotFound desc = an error occurred when try to find container \"671037d2d133ff9019a44facb1f3d6f20a93096220298e73ec0946374ea4d46d\": not found"
Sep 13 14:48:43 masternode kubelet[1795473]: I0913 14:48:43.706976 1795473 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-proxy-2z4dg" podStartSLOduration=0.706920646 podStartE2EDuration="706.920646ms" podCreationTimestamp="2025-09-13 14:48:43 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-09-13 14:48:43.689033872 -0400 EDT m=+7717.566573783" watchObservedRunningTime="2025-09-13 14:48:43.706920646 -0400 EDT m=+7717.584460560"
Sep 13 14:48:44 masternode kubelet[1795473]: I0913 14:48:44.254434 1795473 kubelet_volumes.go:163] "Cleaned up orphaned pod volumes dir" podUID="042b0a43-8184-493f-b4a1-0309e75f2ab3" path="/var/lib/kubelet/pods/042b0a43-8184-493f-b4a1-0309e75f2ab3/volumes"
Sep 13 14:49:39 masternode kubelet[1795473]: I0913 14:49:39.471158 1795473 topology_manager.go:215] "Topology Admit Handler" podUID="a0e0124b-7bf2-4bbd-b18c-bb4cce91e249" podNamespace="kube-system" podName="coredns-784db4cdd8-gszlz"
Sep 13 14:49:39 masternode kubelet[1795473]: I0913 14:49:39.578863 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-dgjrs\" (UniqueName: \"kubernetes.io/projected/a0e0124b-7bf2-4bbd-b18c-bb4cce91e249-kube-api-access-dgjrs\") pod \"coredns-784db4cdd8-gszlz\" (UID: \"a0e0124b-7bf2-4bbd-b18c-bb4cce91e249\") " pod="kube-system/coredns-784db4cdd8-gszlz"
Sep 13 14:49:39 masternode kubelet[1795473]: I0913 14:49:39.578944 1795473 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/a0e0124b-7bf2-4bbd-b18c-bb4cce91e249-config-volume\") pod \"coredns-784db4cdd8-gszlz\" (UID: \"a0e0124b-7bf2-4bbd-b18c-bb4cce91e249\") " pod="kube-system/coredns-784db4cdd8-gszlz"
Sep 13 14:49:40 masternode kubelet[1795473]: I0913 14:49:40.873972 1795473 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/coredns-784db4cdd8-gszlz" podStartSLOduration=1.8738654559999999 podStartE2EDuration="1.873865456s" podCreationTimestamp="2025-09-13 14:49:39 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-09-13 14:49:40.872662549 -0400 EDT m=+7774.750202516" watchObservedRunningTime="2025-09-13 14:49:40.873865456 -0400 EDT m=+7774.751405392"
Sep 13 13:19:42 masternode containerd[1820030]: time="2025-09-13T13:19:42.667974384-04:00" level=info msg="StartContainer for \"90a8645cbf36eb188a3eca75a82a0b27307eb6f4ab175d8598257e8bc9aefd0a\""
Sep 13 13:19:42 masternode containerd[1820030]: time="2025-09-13T13:19:42.740259990-04:00" level=info msg="StartContainer for \"90a8645cbf36eb188a3eca75a82a0b27307eb6f4ab175d8598257e8bc9aefd0a\" returns successfully"
Sep 13 13:20:01 masternode containerd[1820030]: time="2025-09-13T13:20:01.903252430-04:00" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:prometheus-5bbc459489-lbv2q,Uid:51613b7c-ed24-4002-b4c2-6777650c54a6,Namespace:monitoring,Attempt:0,}"
Sep 13 13:20:01 masternode containerd[1820030]: time="2025-09-13T13:20:01.994538311-04:00" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Sep 13 13:20:01 masternode containerd[1820030]: time="2025-09-13T13:20:01.994734342-04:00" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Sep 13 13:20:01 masternode containerd[1820030]: time="2025-09-13T13:20:01.994748806-04:00" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Sep 13 13:20:01 masternode containerd[1820030]: time="2025-09-13T13:20:01.994966604-04:00" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/a1e8acf2ad023e0eb664ce613306bfe4f7092a2e50d6bdb797a5ce1da1ab5a5c pid=1825000 runtime=io.containerd.runc.v2
Sep 13 13:20:02 masternode containerd[1820030]: time="2025-09-13T13:20:02.091166845-04:00" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:prometheus-5bbc459489-lbv2q,Uid:51613b7c-ed24-4002-b4c2-6777650c54a6,Namespace:monitoring,Attempt:0,} returns sandbox id \"a1e8acf2ad023e0eb664ce613306bfe4f7092a2e50d6bdb797a5ce1da1ab5a5c\""
Sep 13 13:20:02 masternode containerd[1820030]: time="2025-09-13T13:20:02.094898912-04:00" level=info msg="CreateContainer within sandbox \"a1e8acf2ad023e0eb664ce613306bfe4f7092a2e50d6bdb797a5ce1da1ab5a5c\" for container &ContainerMetadata{Name:prometheus,Attempt:0,}"
Sep 13 13:20:02 masternode containerd[1820030]: time="2025-09-13T13:20:02.129438697-04:00" level=info msg="CreateContainer within sandbox \"a1e8acf2ad023e0eb664ce613306bfe4f7092a2e50d6bdb797a5ce1da1ab5a5c\" for &ContainerMetadata{Name:prometheus,Attempt:0,} returns container id \"1b7b761efe9221e543da4f64a27b6dc5e505ba3ed30a29b53c26b64fb4603e0e\""
Sep 13 13:20:02 masternode containerd[1820030]: time="2025-09-13T13:20:02.130016866-04:00" level=info msg="StartContainer for \"1b7b761efe9221e543da4f64a27b6dc5e505ba3ed30a29b53c26b64fb4603e0e\""
Sep 13 13:20:02 masternode containerd[1820030]: time="2025-09-13T13:20:02.215215625-04:00" level=info msg="StartContainer for \"1b7b761efe9221e543da4f64a27b6dc5e505ba3ed30a29b53c26b64fb4603e0e\" returns successfully"
Sep 13 13:20:02 masternode containerd[1820030]: time="2025-09-13T13:20:02.802001049-04:00" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:grafana-79747fbd7-9jdsf,Uid:05b7e739-c96a-4a72-a0ae-38430d5079fc,Namespace:monitoring,Attempt:0,}"
Sep 13 13:20:02 masternode containerd[1820030]: time="2025-09-13T13:20:02.892074734-04:00" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Sep 13 13:20:02 masternode containerd[1820030]: time="2025-09-13T13:20:02.892197461-04:00" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Sep 13 13:20:02 masternode containerd[1820030]: time="2025-09-13T13:20:02.892364254-04:00" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Sep 13 13:20:02 masternode containerd[1820030]: time="2025-09-13T13:20:02.892723954-04:00" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/89c7937e87fb59155330caf57366a1792c3a671406ca0e8c6fcc02c5cb41eb8b pid=1825139 runtime=io.containerd.runc.v2
Sep 13 13:20:03 masternode containerd[1820030]: time="2025-09-13T13:20:03.036127751-04:00" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:grafana-79747fbd7-9jdsf,Uid:05b7e739-c96a-4a72-a0ae-38430d5079fc,Namespace:monitoring,Attempt:0,} returns sandbox id \"89c7937e87fb59155330caf57366a1792c3a671406ca0e8c6fcc02c5cb41eb8b\""
Sep 13 13:20:03 masternode containerd[1820030]: time="2025-09-13T13:20:03.039601818-04:00" level=info msg="CreateContainer within sandbox \"89c7937e87fb59155330caf57366a1792c3a671406ca0e8c6fcc02c5cb41eb8b\" for container &ContainerMetadata{Name:grafana,Attempt:0,}"
Sep 13 13:20:03 masternode containerd[1820030]: time="2025-09-13T13:20:03.080763604-04:00" level=info msg="CreateContainer within sandbox \"89c7937e87fb59155330caf57366a1792c3a671406ca0e8c6fcc02c5cb41eb8b\" for &ContainerMetadata{Name:grafana,Attempt:0,} returns container id \"544e7908786533fe3c54ba92635f604d75476d6a68b896b9f4ea5be03c7ff14b\""
Sep 13 13:20:03 masternode containerd[1820030]: time="2025-09-13T13:20:03.081226121-04:00" level=info msg="StartContainer for \"544e7908786533fe3c54ba92635f604d75476d6a68b896b9f4ea5be03c7ff14b\""
Sep 13 13:20:03 masternode containerd[1820030]: time="2025-09-13T13:20:03.148942757-04:00" level=info msg="StartContainer for \"544e7908786533fe3c54ba92635f604d75476d6a68b896b9f4ea5be03c7ff14b\" returns successfully"
Sep 13 13:20:06 masternode containerd[1820030]: time="2025-09-13T13:20:06.393495418-04:00" level=info msg="StopPodSandbox for \"316454b08e96e3202b0285f56213a0baf44be6c581f30f6499276ecf52fd512a\""
Sep 13 13:20:06 masternode containerd[1820030]: time="2025-09-13T13:20:06.393644890-04:00" level=info msg="TearDown network for sandbox \"316454b08e96e3202b0285f56213a0baf44be6c581f30f6499276ecf52fd512a\" successfully"
Sep 13 13:20:06 masternode containerd[1820030]: time="2025-09-13T13:20:06.393665460-04:00" level=info msg="StopPodSandbox for \"316454b08e96e3202b0285f56213a0baf44be6c581f30f6499276ecf52fd512a\" returns successfully"
Sep 13 13:20:06 masternode containerd[1820030]: time="2025-09-13T13:20:06.393948977-04:00" level=info msg="RemovePodSandbox for \"316454b08e96e3202b0285f56213a0baf44be6c581f30f6499276ecf52fd512a\""
Sep 13 13:20:06 masternode containerd[1820030]: time="2025-09-13T13:20:06.394013706-04:00" level=info msg="Forcibly stopping sandbox \"316454b08e96e3202b0285f56213a0baf44be6c581f30f6499276ecf52fd512a\""
Sep 13 13:20:06 masternode containerd[1820030]: time="2025-09-13T13:20:06.394099923-04:00" level=info msg="TearDown network for sandbox \"316454b08e96e3202b0285f56213a0baf44be6c581f30f6499276ecf52fd512a\" successfully"
Sep 13 13:20:06 masternode containerd[1820030]: time="2025-09-13T13:20:06.402551376-04:00" level=info msg="RemovePodSandbox \"316454b08e96e3202b0285f56213a0baf44be6c581f30f6499276ecf52fd512a\" returns successfully"
Sep 13 13:26:28 masternode containerd[1820030]: time="2025-09-13T13:26:28.944129244-04:00" level=error msg="ContainerStatus for \"kube-proxy-m99cv\" failed" error="rpc error: code = NotFound desc = an error occurred when try to find container \"kube-proxy-m99cv\": not found"
Sep 13 13:38:01 masternode systemd[1]: Stopping containerd.service - containerd container runtime...
Sep 13 13:38:01 masternode containerd[1820030]: time="2025-09-13T13:38:01.039573392-04:00" level=info msg="Stop CRI service"
Sep 13 13:38:01 masternode containerd[1820030]: time="2025-09-13T13:38:01.059710271-04:00" level=info msg="Stop CRI service"
Sep 13 13:38:01 masternode containerd[1820030]: time="2025-09-13T13:38:01.059756253-04:00" level=info msg="Event monitor stopped"
Sep 13 13:38:01 masternode containerd[1820030]: time="2025-09-13T13:38:01.059775323-04:00" level=info msg="Stream server stopped"
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Deactivated successfully.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Unit process 1795126 (containerd-shim) remains running after unit stopped.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Unit process 1795158 (containerd-shim) remains running after unit stopped.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Unit process 1795168 (containerd-shim) remains running after unit stopped.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Unit process 1795170 (containerd-shim) remains running after unit stopped.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Unit process 1795719 (containerd-shim) remains running after unit stopped.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Unit process 1796602 (containerd-shim) remains running after unit stopped.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Unit process 1823439 (containerd-shim) remains running after unit stopped.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Unit process 1825000 (containerd-shim) remains running after unit stopped.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Unit process 1825139 (containerd-shim) remains running after unit stopped.
Sep 13 13:38:01 masternode systemd[1]: Stopped containerd.service - containerd container runtime.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Consumed 15.427s CPU time.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Found left-over process 1795126 (containerd-shim) in control group while starting unit. Ignoring.
Sep 13 13:38:01 masternode systemd[1]: This usually indicates unclean termination of a previous run, or service implementation deficiencies.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Found left-over process 1795158 (containerd-shim) in control group while starting unit. Ignoring.
Sep 13 13:38:01 masternode systemd[1]: This usually indicates unclean termination of a previous run, or service implementation deficiencies.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Found left-over process 1795168 (containerd-shim) in control group while starting unit. Ignoring.
Sep 13 13:38:01 masternode systemd[1]: This usually indicates unclean termination of a previous run, or service implementation deficiencies.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Found left-over process 1795170 (containerd-shim) in control group while starting unit. Ignoring.
Sep 13 13:38:01 masternode systemd[1]: This usually indicates unclean termination of a previous run, or service implementation deficiencies.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Found left-over process 1795719 (containerd-shim) in control group while starting unit. Ignoring.
Sep 13 13:38:01 masternode systemd[1]: This usually indicates unclean termination of a previous run, or service implementation deficiencies.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Found left-over process 1796602 (containerd-shim) in control group while starting unit. Ignoring.
Sep 13 13:38:01 masternode systemd[1]: This usually indicates unclean termination of a previous run, or service implementation deficiencies.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Found left-over process 1823439 (containerd-shim) in control group while starting unit. Ignoring.
Sep 13 13:38:01 masternode systemd[1]: This usually indicates unclean termination of a previous run, or service implementation deficiencies.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Found left-over process 1825000 (containerd-shim) in control group while starting unit. Ignoring.
Sep 13 13:38:01 masternode systemd[1]: This usually indicates unclean termination of a previous run, or service implementation deficiencies.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Found left-over process 1825139 (containerd-shim) in control group while starting unit. Ignoring.
Sep 13 13:38:01 masternode systemd[1]: This usually indicates unclean termination of a previous run, or service implementation deficiencies.
Sep 13 13:38:01 masternode systemd[1]: Starting containerd.service - containerd container runtime...
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Found left-over process 1795126 (containerd-shim) in control group while starting unit. Ignoring.
Sep 13 13:38:01 masternode systemd[1]: This usually indicates unclean termination of a previous run, or service implementation deficiencies.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Found left-over process 1795158 (containerd-shim) in control group while starting unit. Ignoring.
Sep 13 13:38:01 masternode systemd[1]: This usually indicates unclean termination of a previous run, or service implementation deficiencies.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Found left-over process 1795168 (containerd-shim) in control group while starting unit. Ignoring.
Sep 13 13:38:01 masternode systemd[1]: This usually indicates unclean termination of a previous run, or service implementation deficiencies.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Found left-over process 1795170 (containerd-shim) in control group while starting unit. Ignoring.
Sep 13 13:38:01 masternode systemd[1]: This usually indicates unclean termination of a previous run, or service implementation deficiencies.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Found left-over process 1795719 (containerd-shim) in control group while starting unit. Ignoring.
Sep 13 13:38:01 masternode systemd[1]: This usually indicates unclean termination of a previous run, or service implementation deficiencies.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Found left-over process 1796602 (containerd-shim) in control group while starting unit. Ignoring.
Sep 13 13:38:01 masternode systemd[1]: This usually indicates unclean termination of a previous run, or service implementation deficiencies.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Found left-over process 1823439 (containerd-shim) in control group while starting unit. Ignoring.
Sep 13 13:38:01 masternode systemd[1]: This usually indicates unclean termination of a previous run, or service implementation deficiencies.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Found left-over process 1825000 (containerd-shim) in control group while starting unit. Ignoring.
Sep 13 13:38:01 masternode systemd[1]: This usually indicates unclean termination of a previous run, or service implementation deficiencies.
Sep 13 13:38:01 masternode systemd[1]: containerd.service: Found left-over process 1825139 (containerd-shim) in control group while starting unit. Ignoring.
Sep 13 13:38:01 masternode systemd[1]: This usually indicates unclean termination of a previous run, or service implementation deficiencies.
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.111035708-04:00" level=info msg="starting containerd" revision="1.6.20~ds1-1+deb12u1" version="1.6.20~ds1"
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.127295041-04:00" level=info msg="loading plugin \"io.containerd.content.v1.content\"..." type=io.containerd.content.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.127363239-04:00" level=info msg="loading plugin \"io.containerd.snapshotter.v1.aufs\"..." type=io.containerd.snapshotter.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.129780358-04:00" level=info msg="skip loading plugin \"io.containerd.snapshotter.v1.aufs\"..." error="aufs is not supported (modprobe aufs failed: exit status 1 \"modprobe: FATAL: Module aufs not found in directory /lib/modules/6.1.0-32-amd64\\n\"): skip plugin" type=io.containerd.snapshotter.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.129872395-04:00" level=info msg="loading plugin \"io.containerd.snapshotter.v1.btrfs\"..." type=io.containerd.snapshotter.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.131018111-04:00" level=info msg="skip loading plugin \"io.containerd.snapshotter.v1.btrfs\"..." error="path /var/lib/containerd/io.containerd.snapshotter.v1.btrfs (ext4) must be a btrfs filesystem to be used with the btrfs snapshotter: skip plugin" type=io.containerd.snapshotter.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.131221351-04:00" level=info msg="loading plugin \"io.containerd.snapshotter.v1.devmapper\"..." type=io.containerd.snapshotter.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.131283735-04:00" level=warning msg="failed to load plugin io.containerd.snapshotter.v1.devmapper" error="devmapper not configured"
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.131304486-04:00" level=info msg="loading plugin \"io.containerd.snapshotter.v1.native\"..." type=io.containerd.snapshotter.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.131353484-04:00" level=info msg="loading plugin \"io.containerd.snapshotter.v1.overlayfs\"..." type=io.containerd.snapshotter.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.131526662-04:00" level=info msg="loading plugin \"io.containerd.snapshotter.v1.zfs\"..." type=io.containerd.snapshotter.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.132130981-04:00" level=info msg="skip loading plugin \"io.containerd.snapshotter.v1.zfs\"..." error="path /var/lib/containerd/io.containerd.snapshotter.v1.zfs must be a zfs filesystem to be used with the zfs snapshotter: skip plugin" type=io.containerd.snapshotter.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.132161992-04:00" level=info msg="loading plugin \"io.containerd.metadata.v1.bolt\"..." type=io.containerd.metadata.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.132190005-04:00" level=warning msg="could not use snapshotter devmapper in metadata plugin" error="devmapper not configured"
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.132201376-04:00" level=info msg="metadata content store policy set" policy=shared
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.132361299-04:00" level=info msg="loading plugin \"io.containerd.differ.v1.walking\"..." type=io.containerd.differ.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.132393155-04:00" level=info msg="loading plugin \"io.containerd.event.v1.exchange\"..." type=io.containerd.event.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.132417277-04:00" level=info msg="loading plugin \"io.containerd.gc.v1.scheduler\"..." type=io.containerd.gc.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.132463918-04:00" level=info msg="loading plugin \"io.containerd.service.v1.introspection-service\"..." type=io.containerd.service.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.132482944-04:00" level=info msg="loading plugin \"io.containerd.service.v1.containers-service\"..." type=io.containerd.service.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.132497272-04:00" level=info msg="loading plugin \"io.containerd.service.v1.content-service\"..." type=io.containerd.service.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.132510086-04:00" level=info msg="loading plugin \"io.containerd.service.v1.diff-service\"..." type=io.containerd.service.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.132540166-04:00" level=info msg="loading plugin \"io.containerd.service.v1.images-service\"..." type=io.containerd.service.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.132565268-04:00" level=info msg="loading plugin \"io.containerd.service.v1.leases-service\"..." type=io.containerd.service.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.132580136-04:00" level=info msg="loading plugin \"io.containerd.service.v1.namespaces-service\"..." type=io.containerd.service.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.132594202-04:00" level=info msg="loading plugin \"io.containerd.service.v1.snapshots-service\"..." type=io.containerd.service.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.132607422-04:00" level=info msg="loading plugin \"io.containerd.runtime.v1.linux\"..." type=io.containerd.runtime.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.132657083-04:00" level=info msg="loading plugin \"io.containerd.runtime.v2.task\"..." type=io.containerd.runtime.v2
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.138540724-04:00" level=info msg="loading plugin \"io.containerd.monitor.v1.cgroups\"..." type=io.containerd.monitor.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.139244322-04:00" level=info msg="loading plugin \"io.containerd.service.v1.tasks-service\"..." type=io.containerd.service.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.139376085-04:00" level=info msg="loading plugin \"io.containerd.grpc.v1.introspection\"..." type=io.containerd.grpc.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.139414473-04:00" level=info msg="loading plugin \"io.containerd.internal.v1.restart\"..." type=io.containerd.internal.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.139510162-04:00" level=info msg="loading plugin \"io.containerd.grpc.v1.containers\"..." type=io.containerd.grpc.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.139550015-04:00" level=info msg="loading plugin \"io.containerd.grpc.v1.content\"..." type=io.containerd.grpc.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.139583286-04:00" level=info msg="loading plugin \"io.containerd.grpc.v1.diff\"..." type=io.containerd.grpc.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.139613109-04:00" level=info msg="loading plugin \"io.containerd.grpc.v1.events\"..." type=io.containerd.grpc.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.139643676-04:00" level=info msg="loading plugin \"io.containerd.grpc.v1.healthcheck\"..." type=io.containerd.grpc.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.139673404-04:00" level=info msg="loading plugin \"io.containerd.grpc.v1.images\"..." type=io.containerd.grpc.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.139703872-04:00" level=info msg="loading plugin \"io.containerd.grpc.v1.leases\"..." type=io.containerd.grpc.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.139737050-04:00" level=info msg="loading plugin \"io.containerd.grpc.v1.namespaces\"..." type=io.containerd.grpc.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.139777729-04:00" level=info msg="loading plugin \"io.containerd.internal.v1.opt\"..." type=io.containerd.internal.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.139881791-04:00" level=info msg="loading plugin \"io.containerd.grpc.v1.snapshots\"..." type=io.containerd.grpc.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.139917402-04:00" level=info msg="loading plugin \"io.containerd.grpc.v1.tasks\"..." type=io.containerd.grpc.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.139950729-04:00" level=info msg="loading plugin \"io.containerd.grpc.v1.version\"..." type=io.containerd.grpc.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.139983851-04:00" level=info msg="loading plugin \"io.containerd.grpc.v1.cri\"..." type=io.containerd.grpc.v1
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.140770565-04:00" level=info msg="Start cri plugin with config {PluginConfig:{ContainerdConfig:{Snapshotter:overlayfs DefaultRuntimeName:runc DefaultRuntime:{Type: Path: Engine: PodAnnotations:[] ContainerAnnotations:[] Root: Options:map[] PrivilegedWithoutHostDevices:false BaseRuntimeSpec: NetworkPluginConfDir: NetworkPluginMaxConfNum:0} UntrustedWorkloadRuntime:{Type: Path: Engine: PodAnnotations:[] ContainerAnnotations:[] Root: Options:map[] PrivilegedWithoutHostDevices:false BaseRuntimeSpec: NetworkPluginConfDir: NetworkPluginMaxConfNum:0} Runtimes:map[runc:{Type:io.containerd.runc.v2 Path: Engine: PodAnnotations:[] ContainerAnnotations:[] Root: Options:map[BinaryName: CriuImagePath: CriuPath: CriuWorkPath: IoGid:0 IoUid:0 NoNewKeyring:false NoPivotRoot:false Root: ShimCgroup: SystemdCgroup:true] PrivilegedWithoutHostDevices:false BaseRuntimeSpec: NetworkPluginConfDir: NetworkPluginMaxConfNum:0}] NoPivot:false DisableSnapshotAnnotations:true DiscardUnpackedLayers:false IgnoreRdtNotEnabledErrors:false} CniConfig:{NetworkPluginBinDir:/opt/cni/bin NetworkPluginConfDir:/etc/cni/net.d NetworkPluginMaxConfNum:1 NetworkPluginConfTemplate: IPPreference:} Registry:{ConfigPath: Mirrors:map[] Configs:map[] Auths:map[] Headers:map[]} ImageDecryption:{KeyModel:node} DisableTCPService:true StreamServerAddress:127.0.0.1 StreamServerPort:0 StreamIdleTimeout:4h0m0s EnableSelinux:false SelinuxCategoryRange:1024 SandboxImage:registry.k8s.io/pause:3.6 StatsCollectPeriod:10 SystemdCgroup:false EnableTLSStreaming:false X509KeyPairStreaming:{TLSCertFile: TLSKeyFile:} MaxContainerLogLineSize:16384 DisableCgroup:false DisableApparmor:false RestrictOOMScoreAdj:false MaxConcurrentDownloads:3 DisableProcMount:false UnsetSeccompProfile: TolerateMissingHugetlbController:true DisableHugetlbController:true DeviceOwnershipFromSecurityContext:false IgnoreImageDefinedVolumes:false NetNSMountsUnderStateDir:false EnableUnprivilegedPorts:false EnableUnprivilegedICMP:false} ContainerdRootDir:/var/lib/containerd ContainerdEndpoint:/run/containerd/containerd.sock RootDir:/var/lib/containerd/io.containerd.grpc.v1.cri StateDir:/run/containerd/io.containerd.grpc.v1.cri}"
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.140881009-04:00" level=info msg="Connect containerd service"
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.140956411-04:00" level=info msg="Get image filesystem path \"/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs\""
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.141607816-04:00" level=info msg="Start subscribing containerd event"
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.141692875-04:00" level=info msg="Start recovering state"
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.141823920-04:00" level=info msg=serving... address=/run/containerd/containerd.sock.ttrpc
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.141897962-04:00" level=info msg=serving... address=/run/containerd/containerd.sock
Sep 13 13:38:01 masternode systemd[1]: Started containerd.service - containerd container runtime.
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.143658744-04:00" level=info msg="containerd successfully booted in 0.034855s"
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.324691661-04:00" level=info msg="Start event monitor"
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.324731444-04:00" level=info msg="Start snapshots syncer"
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.324752906-04:00" level=info msg="Start cni network conf syncer for default"
Sep 13 13:38:01 masternode containerd[1833980]: time="2025-09-13T13:38:01.324768947-04:00" level=info msg="Start streaming server"
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.113066306-04:00" level=info msg="StopContainer for \"34bf61cfea13b4c38cc7703f63078b32332f76f4813c13118fd8f6fdeb9cb5ce\" with timeout 30 (s)"
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.114348691-04:00" level=info msg="Stop container \"34bf61cfea13b4c38cc7703f63078b32332f76f4813c13118fd8f6fdeb9cb5ce\" with signal terminated"
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.176830872-04:00" level=info msg="shim disconnected" id=34bf61cfea13b4c38cc7703f63078b32332f76f4813c13118fd8f6fdeb9cb5ce
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.176893828-04:00" level=warning msg="cleaning up after shim disconnected" id=34bf61cfea13b4c38cc7703f63078b32332f76f4813c13118fd8f6fdeb9cb5ce namespace=k8s.io
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.176910829-04:00" level=info msg="cleaning up dead shim"
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.185570785-04:00" level=warning msg="cleanup warnings time=\"2025-09-13T14:14:58-04:00\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=1849440 runtime=io.containerd.runc.v2\n"
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.191476495-04:00" level=info msg="StopContainer for \"34bf61cfea13b4c38cc7703f63078b32332f76f4813c13118fd8f6fdeb9cb5ce\" returns successfully"
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.191913087-04:00" level=info msg="StopPodSandbox for \"dadf6373e555d240ad5f761ba8dd646eee0751240f4c95163269e7a6532c4d59\""
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.191996030-04:00" level=info msg="Container to stop \"34bf61cfea13b4c38cc7703f63078b32332f76f4813c13118fd8f6fdeb9cb5ce\" must be in running or unknown state, current state \"CONTAINER_EXITED\""
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.276795729-04:00" level=info msg="shim disconnected" id=dadf6373e555d240ad5f761ba8dd646eee0751240f4c95163269e7a6532c4d59
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.276874902-04:00" level=warning msg="cleaning up after shim disconnected" id=dadf6373e555d240ad5f761ba8dd646eee0751240f4c95163269e7a6532c4d59 namespace=k8s.io
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.276901468-04:00" level=info msg="cleaning up dead shim"
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.285040730-04:00" level=warning msg="cleanup warnings time=\"2025-09-13T14:14:58-04:00\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=1849471 runtime=io.containerd.runc.v2\n"
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.285398537-04:00" level=info msg="TearDown network for sandbox \"dadf6373e555d240ad5f761ba8dd646eee0751240f4c95163269e7a6532c4d59\" successfully"
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.285427116-04:00" level=info msg="StopPodSandbox for \"dadf6373e555d240ad5f761ba8dd646eee0751240f4c95163269e7a6532c4d59\" returns successfully"
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.628088418-04:00" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kube-proxy-vfhhh,Uid:420a725e-8ff4-4aa3-8c15-23b64e1a5117,Namespace:kube-system,Attempt:0,}"
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.665977918-04:00" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.666206514-04:00" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.666248701-04:00" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.666535041-04:00" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/6198a9b50d0dd012d2ec3f380f0aaa788cdea5e2920a6d7592c67e8fbca2aa46 pid=1849491 runtime=io.containerd.runc.v2
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.712246366-04:00" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kube-proxy-vfhhh,Uid:420a725e-8ff4-4aa3-8c15-23b64e1a5117,Namespace:kube-system,Attempt:0,} returns sandbox id \"6198a9b50d0dd012d2ec3f380f0aaa788cdea5e2920a6d7592c67e8fbca2aa46\""
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.714473977-04:00" level=info msg="CreateContainer within sandbox \"6198a9b50d0dd012d2ec3f380f0aaa788cdea5e2920a6d7592c67e8fbca2aa46\" for container &ContainerMetadata{Name:kube-proxy,Attempt:0,}"
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.757419087-04:00" level=info msg="CreateContainer within sandbox \"6198a9b50d0dd012d2ec3f380f0aaa788cdea5e2920a6d7592c67e8fbca2aa46\" for &ContainerMetadata{Name:kube-proxy,Attempt:0,} returns container id \"e08f780b197441d2c0f99fb4cfa238cdde9cabeb4ee699c099a1700416e73106\""
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.757908236-04:00" level=info msg="StartContainer for \"e08f780b197441d2c0f99fb4cfa238cdde9cabeb4ee699c099a1700416e73106\""
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.844074103-04:00" level=info msg="StartContainer for \"e08f780b197441d2c0f99fb4cfa238cdde9cabeb4ee699c099a1700416e73106\" returns successfully"
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.971970550-04:00" level=info msg="RemoveContainer for \"34bf61cfea13b4c38cc7703f63078b32332f76f4813c13118fd8f6fdeb9cb5ce\""
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.988085957-04:00" level=info msg="RemoveContainer for \"34bf61cfea13b4c38cc7703f63078b32332f76f4813c13118fd8f6fdeb9cb5ce\" returns successfully"
Sep 13 14:14:58 masternode containerd[1833980]: time="2025-09-13T14:14:58.988712062-04:00" level=error msg="ContainerStatus for \"34bf61cfea13b4c38cc7703f63078b32332f76f4813c13118fd8f6fdeb9cb5ce\" failed" error="rpc error: code = NotFound desc = an error occurred when try to find container \"34bf61cfea13b4c38cc7703f63078b32332f76f4813c13118fd8f6fdeb9cb5ce\": not found"
Sep 13 14:15:06 masternode containerd[1833980]: time="2025-09-13T14:15:06.645982462-04:00" level=info msg="StopPodSandbox for \"dadf6373e555d240ad5f761ba8dd646eee0751240f4c95163269e7a6532c4d59\""
Sep 13 14:15:06 masternode containerd[1833980]: time="2025-09-13T14:15:06.646357903-04:00" level=info msg="TearDown network for sandbox \"dadf6373e555d240ad5f761ba8dd646eee0751240f4c95163269e7a6532c4d59\" successfully"
Sep 13 14:15:06 masternode containerd[1833980]: time="2025-09-13T14:15:06.646413546-04:00" level=info msg="StopPodSandbox for \"dadf6373e555d240ad5f761ba8dd646eee0751240f4c95163269e7a6532c4d59\" returns successfully"
Sep 13 14:15:06 masternode containerd[1833980]: time="2025-09-13T14:15:06.647165850-04:00" level=info msg="RemovePodSandbox for \"dadf6373e555d240ad5f761ba8dd646eee0751240f4c95163269e7a6532c4d59\""
Sep 13 14:15:06 masternode containerd[1833980]: time="2025-09-13T14:15:06.647378759-04:00" level=info msg="Forcibly stopping sandbox \"dadf6373e555d240ad5f761ba8dd646eee0751240f4c95163269e7a6532c4d59\""
Sep 13 14:15:06 masternode containerd[1833980]: time="2025-09-13T14:15:06.647625153-04:00" level=info msg="TearDown network for sandbox \"dadf6373e555d240ad5f761ba8dd646eee0751240f4c95163269e7a6532c4d59\" successfully"
Sep 13 14:15:06 masternode containerd[1833980]: time="2025-09-13T14:15:06.661744339-04:00" level=info msg="RemovePodSandbox \"dadf6373e555d240ad5f761ba8dd646eee0751240f4c95163269e7a6532c4d59\" returns successfully"
Sep 13 14:15:10 masternode containerd[1833980]: time="2025-09-13T14:15:10.461334131-04:00" level=info msg="StopContainer for \"ddc5e8b4dcd414a990e0ab8bb699ed120a470350c42a711d393c26ee79160c62\" with timeout 30 (s)"
Sep 13 14:15:10 masternode containerd[1833980]: time="2025-09-13T14:15:10.462177521-04:00" level=info msg="Stop container \"ddc5e8b4dcd414a990e0ab8bb699ed120a470350c42a711d393c26ee79160c62\" with signal terminated"
Sep 13 14:15:15 masternode containerd[1833980]: time="2025-09-13T14:15:15.525958087-04:00" level=info msg="shim disconnected" id=ddc5e8b4dcd414a990e0ab8bb699ed120a470350c42a711d393c26ee79160c62
Sep 13 14:15:15 masternode containerd[1833980]: time="2025-09-13T14:15:15.526027113-04:00" level=warning msg="cleaning up after shim disconnected" id=ddc5e8b4dcd414a990e0ab8bb699ed120a470350c42a711d393c26ee79160c62 namespace=k8s.io
Sep 13 14:15:15 masternode containerd[1833980]: time="2025-09-13T14:15:15.526048715-04:00" level=info msg="cleaning up dead shim"
Sep 13 14:15:15 masternode containerd[1833980]: time="2025-09-13T14:15:15.534377022-04:00" level=warning msg="cleanup warnings time=\"2025-09-13T14:15:15-04:00\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=1849780 runtime=io.containerd.runc.v2\n"
Sep 13 14:15:15 masternode containerd[1833980]: time="2025-09-13T14:15:15.539985016-04:00" level=info msg="StopContainer for \"ddc5e8b4dcd414a990e0ab8bb699ed120a470350c42a711d393c26ee79160c62\" returns successfully"
Sep 13 14:15:15 masternode containerd[1833980]: time="2025-09-13T14:15:15.540422043-04:00" level=info msg="StopPodSandbox for \"49b4a2300d73a6b574f2251759f7a76f1549775a07353778a2fc31d35ca0f6fc\""
Sep 13 14:15:15 masternode containerd[1833980]: time="2025-09-13T14:15:15.540509883-04:00" level=info msg="Container to stop \"ddc5e8b4dcd414a990e0ab8bb699ed120a470350c42a711d393c26ee79160c62\" must be in running or unknown state, current state \"CONTAINER_EXITED\""
Sep 13 14:15:15 masternode containerd[1833980]: time="2025-09-13T14:15:15.592961856-04:00" level=info msg="shim disconnected" id=49b4a2300d73a6b574f2251759f7a76f1549775a07353778a2fc31d35ca0f6fc
Sep 13 14:15:15 masternode containerd[1833980]: time="2025-09-13T14:15:15.593043187-04:00" level=warning msg="cleaning up after shim disconnected" id=49b4a2300d73a6b574f2251759f7a76f1549775a07353778a2fc31d35ca0f6fc namespace=k8s.io
Sep 13 14:15:15 masternode containerd[1833980]: time="2025-09-13T14:15:15.593068130-04:00" level=info msg="cleaning up dead shim"
Sep 13 14:15:15 masternode containerd[1833980]: time="2025-09-13T14:15:15.600893937-04:00" level=warning msg="cleanup warnings time=\"2025-09-13T14:15:15-04:00\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=1849810 runtime=io.containerd.runc.v2\n"
Sep 13 14:15:15 masternode containerd[1833980]: time="2025-09-13T14:15:15.733128435-04:00" level=info msg="TearDown network for sandbox \"49b4a2300d73a6b574f2251759f7a76f1549775a07353778a2fc31d35ca0f6fc\" successfully"
Sep 13 14:15:15 masternode containerd[1833980]: time="2025-09-13T14:15:15.733181755-04:00" level=info msg="StopPodSandbox for \"49b4a2300d73a6b574f2251759f7a76f1549775a07353778a2fc31d35ca0f6fc\" returns successfully"
Sep 13 14:15:16 masternode containerd[1833980]: time="2025-09-13T14:15:16.023684550-04:00" level=info msg="RemoveContainer for \"ddc5e8b4dcd414a990e0ab8bb699ed120a470350c42a711d393c26ee79160c62\""
Sep 13 14:15:16 masternode containerd[1833980]: time="2025-09-13T14:15:16.036124296-04:00" level=info msg="RemoveContainer for \"ddc5e8b4dcd414a990e0ab8bb699ed120a470350c42a711d393c26ee79160c62\" returns successfully"
Sep 13 14:15:16 masternode containerd[1833980]: time="2025-09-13T14:15:16.036608949-04:00" level=error msg="ContainerStatus for \"ddc5e8b4dcd414a990e0ab8bb699ed120a470350c42a711d393c26ee79160c62\" failed" error="rpc error: code = NotFound desc = an error occurred when try to find container \"ddc5e8b4dcd414a990e0ab8bb699ed120a470350c42a711d393c26ee79160c62\": not found"
Sep 13 14:16:06 masternode containerd[1833980]: time="2025-09-13T14:16:06.667326258-04:00" level=info msg="StopPodSandbox for \"49b4a2300d73a6b574f2251759f7a76f1549775a07353778a2fc31d35ca0f6fc\""
Sep 13 14:16:06 masternode containerd[1833980]: time="2025-09-13T14:16:06.674622843-04:00" level=info msg="TearDown network for sandbox \"49b4a2300d73a6b574f2251759f7a76f1549775a07353778a2fc31d35ca0f6fc\" successfully"
Sep 13 14:16:06 masternode containerd[1833980]: time="2025-09-13T14:16:06.674661629-04:00" level=info msg="StopPodSandbox for \"49b4a2300d73a6b574f2251759f7a76f1549775a07353778a2fc31d35ca0f6fc\" returns successfully"
Sep 13 14:16:06 masternode containerd[1833980]: time="2025-09-13T14:16:06.675027353-04:00" level=info msg="RemovePodSandbox for \"49b4a2300d73a6b574f2251759f7a76f1549775a07353778a2fc31d35ca0f6fc\""
Sep 13 14:16:06 masternode containerd[1833980]: time="2025-09-13T14:16:06.675117470-04:00" level=info msg="Forcibly stopping sandbox \"49b4a2300d73a6b574f2251759f7a76f1549775a07353778a2fc31d35ca0f6fc\""
Sep 13 14:16:06 masternode containerd[1833980]: time="2025-09-13T14:16:06.681091677-04:00" level=info msg="TearDown network for sandbox \"49b4a2300d73a6b574f2251759f7a76f1549775a07353778a2fc31d35ca0f6fc\" successfully"
Sep 13 14:16:06 masternode containerd[1833980]: time="2025-09-13T14:16:06.692173025-04:00" level=info msg="RemovePodSandbox \"49b4a2300d73a6b574f2251759f7a76f1549775a07353778a2fc31d35ca0f6fc\" returns successfully"
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.268472358-04:00" level=info msg="StopContainer for \"90a8645cbf36eb188a3eca75a82a0b27307eb6f4ab175d8598257e8bc9aefd0a\" with timeout 30 (s)"
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.269051435-04:00" level=info msg="Stop container \"90a8645cbf36eb188a3eca75a82a0b27307eb6f4ab175d8598257e8bc9aefd0a\" with signal terminated"
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.352156186-04:00" level=info msg="shim disconnected" id=90a8645cbf36eb188a3eca75a82a0b27307eb6f4ab175d8598257e8bc9aefd0a
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.352233430-04:00" level=warning msg="cleaning up after shim disconnected" id=90a8645cbf36eb188a3eca75a82a0b27307eb6f4ab175d8598257e8bc9aefd0a namespace=k8s.io
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.352255953-04:00" level=info msg="cleaning up dead shim"
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.364075552-04:00" level=warning msg="cleanup warnings time=\"2025-09-13T14:20:43-04:00\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=1851933 runtime=io.containerd.runc.v2\n"
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.370142813-04:00" level=info msg="StopContainer for \"90a8645cbf36eb188a3eca75a82a0b27307eb6f4ab175d8598257e8bc9aefd0a\" returns successfully"
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.370676643-04:00" level=info msg="StopPodSandbox for \"27bccec338f32808293790c6fc896d12e0f8226674ff19515dab9fdf1cf98e4f\""
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.370855522-04:00" level=info msg="Container to stop \"90a8645cbf36eb188a3eca75a82a0b27307eb6f4ab175d8598257e8bc9aefd0a\" must be in running or unknown state, current state \"CONTAINER_EXITED\""
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.370901827-04:00" level=info msg="Container to stop \"be44b23f3fbb1813f7accc195015482d0159990e76ad649bf6ae220e36c62525\" must be in running or unknown state, current state \"CONTAINER_EXITED\""
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.370922249-04:00" level=info msg="Container to stop \"f2f2dc7b4a9432f7fb665ba29aa6fbeb7477adf04e900ec306f583fe8fb9309e\" must be in running or unknown state, current state \"CONTAINER_EXITED\""
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.416740603-04:00" level=info msg="shim disconnected" id=27bccec338f32808293790c6fc896d12e0f8226674ff19515dab9fdf1cf98e4f
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.416818169-04:00" level=warning msg="cleaning up after shim disconnected" id=27bccec338f32808293790c6fc896d12e0f8226674ff19515dab9fdf1cf98e4f namespace=k8s.io
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.416844979-04:00" level=info msg="cleaning up dead shim"
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.424747568-04:00" level=warning msg="cleanup warnings time=\"2025-09-13T14:20:43-04:00\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=1851964 runtime=io.containerd.runc.v2\n"
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.425216697-04:00" level=info msg="TearDown network for sandbox \"27bccec338f32808293790c6fc896d12e0f8226674ff19515dab9fdf1cf98e4f\" successfully"
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.425247642-04:00" level=info msg="StopPodSandbox for \"27bccec338f32808293790c6fc896d12e0f8226674ff19515dab9fdf1cf98e4f\" returns successfully"
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.631445914-04:00" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kube-flannel-ds-jzh7t,Uid:4cf49b2e-350d-4c47-a7d5-4c1d1649b5af,Namespace:kube-flannel,Attempt:0,}"
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.661984351-04:00" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.662075975-04:00" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.662095382-04:00" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.662280286-04:00" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/86d622046a830286d5f047d30126465db7334fce8a786bdd5745a0d3b74f31d4 pid=1851987 runtime=io.containerd.runc.v2
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.732797331-04:00" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kube-flannel-ds-jzh7t,Uid:4cf49b2e-350d-4c47-a7d5-4c1d1649b5af,Namespace:kube-flannel,Attempt:0,} returns sandbox id \"86d622046a830286d5f047d30126465db7334fce8a786bdd5745a0d3b74f31d4\""
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.735448358-04:00" level=info msg="CreateContainer within sandbox \"86d622046a830286d5f047d30126465db7334fce8a786bdd5745a0d3b74f31d4\" for container &ContainerMetadata{Name:install-cni-plugin,Attempt:0,}"
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.768979143-04:00" level=info msg="CreateContainer within sandbox \"86d622046a830286d5f047d30126465db7334fce8a786bdd5745a0d3b74f31d4\" for &ContainerMetadata{Name:install-cni-plugin,Attempt:0,} returns container id \"1880c8975d68414cc88269a6c75ecd9cc67b0170c8d1b7f24fc1fe2200a55da7\""
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.769448768-04:00" level=info msg="StartContainer for \"1880c8975d68414cc88269a6c75ecd9cc67b0170c8d1b7f24fc1fe2200a55da7\""
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.840444448-04:00" level=info msg="StartContainer for \"1880c8975d68414cc88269a6c75ecd9cc67b0170c8d1b7f24fc1fe2200a55da7\" returns successfully"
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.923202938-04:00" level=info msg="shim disconnected" id=1880c8975d68414cc88269a6c75ecd9cc67b0170c8d1b7f24fc1fe2200a55da7
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.923265893-04:00" level=warning msg="cleaning up after shim disconnected" id=1880c8975d68414cc88269a6c75ecd9cc67b0170c8d1b7f24fc1fe2200a55da7 namespace=k8s.io
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.923286378-04:00" level=info msg="cleaning up dead shim"
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.927241437-04:00" level=info msg="RemoveContainer for \"90a8645cbf36eb188a3eca75a82a0b27307eb6f4ab175d8598257e8bc9aefd0a\""
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.938866792-04:00" level=info msg="RemoveContainer for \"90a8645cbf36eb188a3eca75a82a0b27307eb6f4ab175d8598257e8bc9aefd0a\" returns successfully"
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.940486111-04:00" level=warning msg="cleanup warnings time=\"2025-09-13T14:20:43-04:00\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=1852066 runtime=io.containerd.runc.v2\n"
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.942319336-04:00" level=info msg="RemoveContainer for \"f2f2dc7b4a9432f7fb665ba29aa6fbeb7477adf04e900ec306f583fe8fb9309e\""
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.955669592-04:00" level=info msg="RemoveContainer for \"f2f2dc7b4a9432f7fb665ba29aa6fbeb7477adf04e900ec306f583fe8fb9309e\" returns successfully"
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.957083808-04:00" level=info msg="RemoveContainer for \"be44b23f3fbb1813f7accc195015482d0159990e76ad649bf6ae220e36c62525\""
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.972305271-04:00" level=info msg="RemoveContainer for \"be44b23f3fbb1813f7accc195015482d0159990e76ad649bf6ae220e36c62525\" returns successfully"
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.972787246-04:00" level=error msg="ContainerStatus for \"90a8645cbf36eb188a3eca75a82a0b27307eb6f4ab175d8598257e8bc9aefd0a\" failed" error="rpc error: code = NotFound desc = an error occurred when try to find container \"90a8645cbf36eb188a3eca75a82a0b27307eb6f4ab175d8598257e8bc9aefd0a\": not found"
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.973267500-04:00" level=error msg="ContainerStatus for \"f2f2dc7b4a9432f7fb665ba29aa6fbeb7477adf04e900ec306f583fe8fb9309e\" failed" error="rpc error: code = NotFound desc = an error occurred when try to find container \"f2f2dc7b4a9432f7fb665ba29aa6fbeb7477adf04e900ec306f583fe8fb9309e\": not found"
Sep 13 14:20:43 masternode containerd[1833980]: time="2025-09-13T14:20:43.973666880-04:00" level=error msg="ContainerStatus for \"be44b23f3fbb1813f7accc195015482d0159990e76ad649bf6ae220e36c62525\" failed" error="rpc error: code = NotFound desc = an error occurred when try to find container \"be44b23f3fbb1813f7accc195015482d0159990e76ad649bf6ae220e36c62525\": not found"
Sep 13 14:20:44 masternode containerd[1833980]: time="2025-09-13T14:20:44.943847131-04:00" level=info msg="CreateContainer within sandbox \"86d622046a830286d5f047d30126465db7334fce8a786bdd5745a0d3b74f31d4\" for container &ContainerMetadata{Name:install-cni,Attempt:0,}"
Sep 13 14:20:44 masternode containerd[1833980]: time="2025-09-13T14:20:44.986320142-04:00" level=info msg="CreateContainer within sandbox \"86d622046a830286d5f047d30126465db7334fce8a786bdd5745a0d3b74f31d4\" for &ContainerMetadata{Name:install-cni,Attempt:0,} returns container id \"efdbada3baa46f8ce24f2e9494c7e4e6104544a1e7ab754895175be75e61401a\""
Sep 13 14:20:44 masternode containerd[1833980]: time="2025-09-13T14:20:44.986805880-04:00" level=info msg="StartContainer for \"efdbada3baa46f8ce24f2e9494c7e4e6104544a1e7ab754895175be75e61401a\""
Sep 13 14:20:45 masternode containerd[1833980]: time="2025-09-13T14:20:45.056131036-04:00" level=info msg="StartContainer for \"efdbada3baa46f8ce24f2e9494c7e4e6104544a1e7ab754895175be75e61401a\" returns successfully"
Sep 13 14:20:45 masternode containerd[1833980]: time="2025-09-13T14:20:45.094887135-04:00" level=info msg="shim disconnected" id=efdbada3baa46f8ce24f2e9494c7e4e6104544a1e7ab754895175be75e61401a
Sep 13 14:20:45 masternode containerd[1833980]: time="2025-09-13T14:20:45.094963260-04:00" level=warning msg="cleaning up after shim disconnected" id=efdbada3baa46f8ce24f2e9494c7e4e6104544a1e7ab754895175be75e61401a namespace=k8s.io
Sep 13 14:20:45 masternode containerd[1833980]: time="2025-09-13T14:20:45.094987699-04:00" level=info msg="cleaning up dead shim"
Sep 13 14:20:45 masternode containerd[1833980]: time="2025-09-13T14:20:45.103991349-04:00" level=warning msg="cleanup warnings time=\"2025-09-13T14:20:45-04:00\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=1852120 runtime=io.containerd.runc.v2\n"
Sep 13 14:20:45 masternode containerd[1833980]: time="2025-09-13T14:20:45.944243989-04:00" level=info msg="CreateContainer within sandbox \"86d622046a830286d5f047d30126465db7334fce8a786bdd5745a0d3b74f31d4\" for container &ContainerMetadata{Name:kube-flannel,Attempt:0,}"
Sep 13 14:20:45 masternode containerd[1833980]: time="2025-09-13T14:20:45.973194548-04:00" level=info msg="CreateContainer within sandbox \"86d622046a830286d5f047d30126465db7334fce8a786bdd5745a0d3b74f31d4\" for &ContainerMetadata{Name:kube-flannel,Attempt:0,} returns container id \"50352268387147cb336c0b330648f2d44835ffd29ebc8391237c987ef287150f\""
Sep 13 14:20:45 masternode containerd[1833980]: time="2025-09-13T14:20:45.973698395-04:00" level=info msg="StartContainer for \"50352268387147cb336c0b330648f2d44835ffd29ebc8391237c987ef287150f\""
Sep 13 14:20:46 masternode containerd[1833980]: time="2025-09-13T14:20:46.042395083-04:00" level=info msg="StartContainer for \"50352268387147cb336c0b330648f2d44835ffd29ebc8391237c987ef287150f\" returns successfully"
Sep 13 14:21:06 masternode containerd[1833980]: time="2025-09-13T14:21:06.726305814-04:00" level=info msg="StopPodSandbox for \"27bccec338f32808293790c6fc896d12e0f8226674ff19515dab9fdf1cf98e4f\""
Sep 13 14:21:06 masternode containerd[1833980]: time="2025-09-13T14:21:06.727570854-04:00" level=info msg="TearDown network for sandbox \"27bccec338f32808293790c6fc896d12e0f8226674ff19515dab9fdf1cf98e4f\" successfully"
Sep 13 14:21:06 masternode containerd[1833980]: time="2025-09-13T14:21:06.727692393-04:00" level=info msg="StopPodSandbox for \"27bccec338f32808293790c6fc896d12e0f8226674ff19515dab9fdf1cf98e4f\" returns successfully"
Sep 13 14:21:06 masternode containerd[1833980]: time="2025-09-13T14:21:06.729011367-04:00" level=info msg="RemovePodSandbox for \"27bccec338f32808293790c6fc896d12e0f8226674ff19515dab9fdf1cf98e4f\""
Sep 13 14:21:06 masternode containerd[1833980]: time="2025-09-13T14:21:06.729325136-04:00" level=info msg="Forcibly stopping sandbox \"27bccec338f32808293790c6fc896d12e0f8226674ff19515dab9fdf1cf98e4f\""
Sep 13 14:21:06 masternode containerd[1833980]: time="2025-09-13T14:21:06.729608260-04:00" level=info msg="TearDown network for sandbox \"27bccec338f32808293790c6fc896d12e0f8226674ff19515dab9fdf1cf98e4f\" successfully"
Sep 13 14:21:06 masternode containerd[1833980]: time="2025-09-13T14:21:06.740725842-04:00" level=info msg="RemovePodSandbox \"27bccec338f32808293790c6fc896d12e0f8226674ff19515dab9fdf1cf98e4f\" returns successfully"
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.291254185-04:00" level=info msg="StopContainer for \"50352268387147cb336c0b330648f2d44835ffd29ebc8391237c987ef287150f\" with timeout 30 (s)"
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.292167980-04:00" level=info msg="Stop container \"50352268387147cb336c0b330648f2d44835ffd29ebc8391237c987ef287150f\" with signal terminated"
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.342283149-04:00" level=info msg="shim disconnected" id=50352268387147cb336c0b330648f2d44835ffd29ebc8391237c987ef287150f
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.342343840-04:00" level=warning msg="cleaning up after shim disconnected" id=50352268387147cb336c0b330648f2d44835ffd29ebc8391237c987ef287150f namespace=k8s.io
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.342359634-04:00" level=info msg="cleaning up dead shim"
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.350831483-04:00" level=warning msg="cleanup warnings time=\"2025-09-13T14:29:02-04:00\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=1861777 runtime=io.containerd.runc.v2\n"
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.356427318-04:00" level=info msg="StopContainer for \"50352268387147cb336c0b330648f2d44835ffd29ebc8391237c987ef287150f\" returns successfully"
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.356903358-04:00" level=info msg="StopPodSandbox for \"86d622046a830286d5f047d30126465db7334fce8a786bdd5745a0d3b74f31d4\""
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.357023815-04:00" level=info msg="Container to stop \"efdbada3baa46f8ce24f2e9494c7e4e6104544a1e7ab754895175be75e61401a\" must be in running or unknown state, current state \"CONTAINER_EXITED\""
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.357145524-04:00" level=info msg="Container to stop \"1880c8975d68414cc88269a6c75ecd9cc67b0170c8d1b7f24fc1fe2200a55da7\" must be in running or unknown state, current state \"CONTAINER_EXITED\""
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.357183014-04:00" level=info msg="Container to stop \"50352268387147cb336c0b330648f2d44835ffd29ebc8391237c987ef287150f\" must be in running or unknown state, current state \"CONTAINER_EXITED\""
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.424845194-04:00" level=info msg="shim disconnected" id=86d622046a830286d5f047d30126465db7334fce8a786bdd5745a0d3b74f31d4
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.424935840-04:00" level=warning msg="cleaning up after shim disconnected" id=86d622046a830286d5f047d30126465db7334fce8a786bdd5745a0d3b74f31d4 namespace=k8s.io
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.424960743-04:00" level=info msg="cleaning up dead shim"
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.433460097-04:00" level=warning msg="cleanup warnings time=\"2025-09-13T14:29:02-04:00\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=1861809 runtime=io.containerd.runc.v2\n"
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.433791517-04:00" level=info msg="TearDown network for sandbox \"86d622046a830286d5f047d30126465db7334fce8a786bdd5745a0d3b74f31d4\" successfully"
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.433820536-04:00" level=info msg="StopPodSandbox for \"86d622046a830286d5f047d30126465db7334fce8a786bdd5745a0d3b74f31d4\" returns successfully"
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.800915373-04:00" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kube-flannel-ds-vk9mg,Uid:6880a041-6398-401b-8525-c37d46489b70,Namespace:kube-flannel,Attempt:0,}"
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.829547114-04:00" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.829635965-04:00" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.829648779-04:00" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.830419712-04:00" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/3c34495bf89462536960da1c4a357a9e75283ddfb300a53423c5dae521de6b1f pid=1861830 runtime=io.containerd.runc.v2
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.908846871-04:00" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kube-flannel-ds-vk9mg,Uid:6880a041-6398-401b-8525-c37d46489b70,Namespace:kube-flannel,Attempt:0,} returns sandbox id \"3c34495bf89462536960da1c4a357a9e75283ddfb300a53423c5dae521de6b1f\""
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.910986145-04:00" level=info msg="CreateContainer within sandbox \"3c34495bf89462536960da1c4a357a9e75283ddfb300a53423c5dae521de6b1f\" for container &ContainerMetadata{Name:install-cni-plugin,Attempt:0,}"
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.944831444-04:00" level=info msg="CreateContainer within sandbox \"3c34495bf89462536960da1c4a357a9e75283ddfb300a53423c5dae521de6b1f\" for &ContainerMetadata{Name:install-cni-plugin,Attempt:0,} returns container id \"4c5c90966b7892c91fb8c0e4a970678caa5d03a35c0d8fdb7b5e840c40520ec9\""
Sep 13 14:29:02 masternode containerd[1833980]: time="2025-09-13T14:29:02.945295932-04:00" level=info msg="StartContainer for \"4c5c90966b7892c91fb8c0e4a970678caa5d03a35c0d8fdb7b5e840c40520ec9\""
Sep 13 14:29:03 masternode containerd[1833980]: time="2025-09-13T14:29:03.001878742-04:00" level=info msg="StartContainer for \"4c5c90966b7892c91fb8c0e4a970678caa5d03a35c0d8fdb7b5e840c40520ec9\" returns successfully"
Sep 13 14:29:03 masternode containerd[1833980]: time="2025-09-13T14:29:03.081115657-04:00" level=info msg="shim disconnected" id=4c5c90966b7892c91fb8c0e4a970678caa5d03a35c0d8fdb7b5e840c40520ec9
Sep 13 14:29:03 masternode containerd[1833980]: time="2025-09-13T14:29:03.081185950-04:00" level=warning msg="cleaning up after shim disconnected" id=4c5c90966b7892c91fb8c0e4a970678caa5d03a35c0d8fdb7b5e840c40520ec9 namespace=k8s.io
Sep 13 14:29:03 masternode containerd[1833980]: time="2025-09-13T14:29:03.081208563-04:00" level=info msg="cleaning up dead shim"
Sep 13 14:29:03 masternode containerd[1833980]: time="2025-09-13T14:29:03.089413828-04:00" level=warning msg="cleanup warnings time=\"2025-09-13T14:29:03-04:00\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=1861906 runtime=io.containerd.runc.v2\n"
Sep 13 14:29:03 masternode containerd[1833980]: time="2025-09-13T14:29:03.248393051-04:00" level=info msg="CreateContainer within sandbox \"3c34495bf89462536960da1c4a357a9e75283ddfb300a53423c5dae521de6b1f\" for container &ContainerMetadata{Name:install-cni,Attempt:0,}"
Sep 13 14:29:03 masternode containerd[1833980]: time="2025-09-13T14:29:03.252376121-04:00" level=info msg="RemoveContainer for \"50352268387147cb336c0b330648f2d44835ffd29ebc8391237c987ef287150f\""
Sep 13 14:29:03 masternode containerd[1833980]: time="2025-09-13T14:29:03.273591055-04:00" level=info msg="RemoveContainer for \"50352268387147cb336c0b330648f2d44835ffd29ebc8391237c987ef287150f\" returns successfully"
Sep 13 14:29:03 masternode containerd[1833980]: time="2025-09-13T14:29:03.274717273-04:00" level=info msg="RemoveContainer for \"efdbada3baa46f8ce24f2e9494c7e4e6104544a1e7ab754895175be75e61401a\""
Sep 13 14:29:03 masternode containerd[1833980]: time="2025-09-13T14:29:03.292207139-04:00" level=info msg="RemoveContainer for \"efdbada3baa46f8ce24f2e9494c7e4e6104544a1e7ab754895175be75e61401a\" returns successfully"
Sep 13 14:29:03 masternode containerd[1833980]: time="2025-09-13T14:29:03.293362471-04:00" level=info msg="RemoveContainer for \"1880c8975d68414cc88269a6c75ecd9cc67b0170c8d1b7f24fc1fe2200a55da7\""
Sep 13 14:29:03 masternode containerd[1833980]: time="2025-09-13T14:29:03.304994500-04:00" level=info msg="RemoveContainer for \"1880c8975d68414cc88269a6c75ecd9cc67b0170c8d1b7f24fc1fe2200a55da7\" returns successfully"
Sep 13 14:29:03 masternode containerd[1833980]: time="2025-09-13T14:29:03.305468487-04:00" level=error msg="ContainerStatus for \"50352268387147cb336c0b330648f2d44835ffd29ebc8391237c987ef287150f\" failed" error="rpc error: code = NotFound desc = an error occurred when try to find container \"50352268387147cb336c0b330648f2d44835ffd29ebc8391237c987ef287150f\": not found"
Sep 13 14:29:03 masternode containerd[1833980]: time="2025-09-13T14:29:03.305822296-04:00" level=error msg="ContainerStatus for \"efdbada3baa46f8ce24f2e9494c7e4e6104544a1e7ab754895175be75e61401a\" failed" error="rpc error: code = NotFound desc = an error occurred when try to find container \"efdbada3baa46f8ce24f2e9494c7e4e6104544a1e7ab754895175be75e61401a\": not found"
Sep 13 14:29:03 masternode containerd[1833980]: time="2025-09-13T14:29:03.311086791-04:00" level=error msg="ContainerStatus for \"1880c8975d68414cc88269a6c75ecd9cc67b0170c8d1b7f24fc1fe2200a55da7\" failed" error="rpc error: code = NotFound desc = an error occurred when try to find container \"1880c8975d68414cc88269a6c75ecd9cc67b0170c8d1b7f24fc1fe2200a55da7\": not found"
Sep 13 14:29:03 masternode containerd[1833980]: time="2025-09-13T14:29:03.337982868-04:00" level=info msg="CreateContainer within sandbox \"3c34495bf89462536960da1c4a357a9e75283ddfb300a53423c5dae521de6b1f\" for &ContainerMetadata{Name:install-cni,Attempt:0,} returns container id \"36b2184bf8ec7645970e6c9d051498c1a4f5d16f22d4755278b155f488e45db2\""
Sep 13 14:29:03 masternode containerd[1833980]: time="2025-09-13T14:29:03.338521882-04:00" level=info msg="StartContainer for \"36b2184bf8ec7645970e6c9d051498c1a4f5d16f22d4755278b155f488e45db2\""
Sep 13 14:29:03 masternode containerd[1833980]: time="2025-09-13T14:29:03.412751780-04:00" level=info msg="StartContainer for \"36b2184bf8ec7645970e6c9d051498c1a4f5d16f22d4755278b155f488e45db2\" returns successfully"
Sep 13 14:29:03 masternode containerd[1833980]: time="2025-09-13T14:29:03.449636766-04:00" level=info msg="shim disconnected" id=36b2184bf8ec7645970e6c9d051498c1a4f5d16f22d4755278b155f488e45db2
Sep 13 14:29:03 masternode containerd[1833980]: time="2025-09-13T14:29:03.449702433-04:00" level=warning msg="cleaning up after shim disconnected" id=36b2184bf8ec7645970e6c9d051498c1a4f5d16f22d4755278b155f488e45db2 namespace=k8s.io
Sep 13 14:29:03 masternode containerd[1833980]: time="2025-09-13T14:29:03.449723612-04:00" level=info msg="cleaning up dead shim"
Sep 13 14:29:03 masternode containerd[1833980]: time="2025-09-13T14:29:03.457366635-04:00" level=warning msg="cleanup warnings time=\"2025-09-13T14:29:03-04:00\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=1861960 runtime=io.containerd.runc.v2\n"
Sep 13 14:29:04 masternode containerd[1833980]: time="2025-09-13T14:29:04.271449539-04:00" level=info msg="CreateContainer within sandbox \"3c34495bf89462536960da1c4a357a9e75283ddfb300a53423c5dae521de6b1f\" for container &ContainerMetadata{Name:kube-flannel,Attempt:0,}"
Sep 13 14:29:04 masternode containerd[1833980]: time="2025-09-13T14:29:04.325618481-04:00" level=info msg="CreateContainer within sandbox \"3c34495bf89462536960da1c4a357a9e75283ddfb300a53423c5dae521de6b1f\" for &ContainerMetadata{Name:kube-flannel,Attempt:0,} returns container id \"597582628427259e203fcfccb2cb28158e245ddac698e5898de24eebb4836f7b\""
Sep 13 14:29:04 masternode containerd[1833980]: time="2025-09-13T14:29:04.326123186-04:00" level=info msg="StartContainer for \"597582628427259e203fcfccb2cb28158e245ddac698e5898de24eebb4836f7b\""
Sep 13 14:29:04 masternode containerd[1833980]: time="2025-09-13T14:29:04.394716833-04:00" level=info msg="StartContainer for \"597582628427259e203fcfccb2cb28158e245ddac698e5898de24eebb4836f7b\" returns successfully"
Sep 13 14:29:06 masternode containerd[1833980]: time="2025-09-13T14:29:06.774367078-04:00" level=info msg="StopPodSandbox for \"86d622046a830286d5f047d30126465db7334fce8a786bdd5745a0d3b74f31d4\""
Sep 13 14:29:06 masternode containerd[1833980]: time="2025-09-13T14:29:06.774766098-04:00" level=info msg="TearDown network for sandbox \"86d622046a830286d5f047d30126465db7334fce8a786bdd5745a0d3b74f31d4\" successfully"
Sep 13 14:29:06 masternode containerd[1833980]: time="2025-09-13T14:29:06.774864303-04:00" level=info msg="StopPodSandbox for \"86d622046a830286d5f047d30126465db7334fce8a786bdd5745a0d3b74f31d4\" returns successfully"
Sep 13 14:29:06 masternode containerd[1833980]: time="2025-09-13T14:29:06.775621585-04:00" level=info msg="RemovePodSandbox for \"86d622046a830286d5f047d30126465db7334fce8a786bdd5745a0d3b74f31d4\""
Sep 13 14:29:06 masternode containerd[1833980]: time="2025-09-13T14:29:06.775779552-04:00" level=info msg="Forcibly stopping sandbox \"86d622046a830286d5f047d30126465db7334fce8a786bdd5745a0d3b74f31d4\""
Sep 13 14:29:06 masternode containerd[1833980]: time="2025-09-13T14:29:06.776021106-04:00" level=info msg="TearDown network for sandbox \"86d622046a830286d5f047d30126465db7334fce8a786bdd5745a0d3b74f31d4\" successfully"
Sep 13 14:29:06 masternode containerd[1833980]: time="2025-09-13T14:29:06.787861995-04:00" level=info msg="RemovePodSandbox \"86d622046a830286d5f047d30126465db7334fce8a786bdd5745a0d3b74f31d4\" returns successfully"
Sep 13 14:45:25 masternode containerd[1833980]: time="2025-09-13T14:45:25.785250685-04:00" level=info msg="StopContainer for \"e08f780b197441d2c0f99fb4cfa238cdde9cabeb4ee699c099a1700416e73106\" with timeout 30 (s)"
Sep 13 14:45:25 masternode containerd[1833980]: time="2025-09-13T14:45:25.788097070-04:00" level=info msg="Stop container \"e08f780b197441d2c0f99fb4cfa238cdde9cabeb4ee699c099a1700416e73106\" with signal terminated"
Sep 13 14:45:25 masternode containerd[1833980]: time="2025-09-13T14:45:25.844377665-04:00" level=info msg="shim disconnected" id=e08f780b197441d2c0f99fb4cfa238cdde9cabeb4ee699c099a1700416e73106
Sep 13 14:45:25 masternode containerd[1833980]: time="2025-09-13T14:45:25.844438381-04:00" level=warning msg="cleaning up after shim disconnected" id=e08f780b197441d2c0f99fb4cfa238cdde9cabeb4ee699c099a1700416e73106 namespace=k8s.io
Sep 13 14:45:25 masternode containerd[1833980]: time="2025-09-13T14:45:25.844458915-04:00" level=info msg="cleaning up dead shim"
Sep 13 14:45:25 masternode containerd[1833980]: time="2025-09-13T14:45:25.853252254-04:00" level=warning msg="cleanup warnings time=\"2025-09-13T14:45:25-04:00\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=1868731 runtime=io.containerd.runc.v2\n"
Sep 13 14:45:25 masternode containerd[1833980]: time="2025-09-13T14:45:25.858908605-04:00" level=info msg="StopContainer for \"e08f780b197441d2c0f99fb4cfa238cdde9cabeb4ee699c099a1700416e73106\" returns successfully"
Sep 13 14:45:25 masternode containerd[1833980]: time="2025-09-13T14:45:25.859334563-04:00" level=info msg="StopPodSandbox for \"6198a9b50d0dd012d2ec3f380f0aaa788cdea5e2920a6d7592c67e8fbca2aa46\""
Sep 13 14:45:25 masternode containerd[1833980]: time="2025-09-13T14:45:25.859416460-04:00" level=info msg="Container to stop \"e08f780b197441d2c0f99fb4cfa238cdde9cabeb4ee699c099a1700416e73106\" must be in running or unknown state, current state \"CONTAINER_EXITED\""
Sep 13 14:45:25 masternode containerd[1833980]: time="2025-09-13T14:45:25.932854939-04:00" level=info msg="shim disconnected" id=6198a9b50d0dd012d2ec3f380f0aaa788cdea5e2920a6d7592c67e8fbca2aa46
Sep 13 14:45:25 masternode containerd[1833980]: time="2025-09-13T14:45:25.932953221-04:00" level=warning msg="cleaning up after shim disconnected" id=6198a9b50d0dd012d2ec3f380f0aaa788cdea5e2920a6d7592c67e8fbca2aa46 namespace=k8s.io
Sep 13 14:45:25 masternode containerd[1833980]: time="2025-09-13T14:45:25.932977305-04:00" level=info msg="cleaning up dead shim"
Sep 13 14:45:25 masternode containerd[1833980]: time="2025-09-13T14:45:25.940742712-04:00" level=warning msg="cleanup warnings time=\"2025-09-13T14:45:25-04:00\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=1868767 runtime=io.containerd.runc.v2\n"
Sep 13 14:45:25 masternode containerd[1833980]: time="2025-09-13T14:45:25.941157866-04:00" level=info msg="TearDown network for sandbox \"6198a9b50d0dd012d2ec3f380f0aaa788cdea5e2920a6d7592c67e8fbca2aa46\" successfully"
Sep 13 14:45:25 masternode containerd[1833980]: time="2025-09-13T14:45:25.941182213-04:00" level=info msg="StopPodSandbox for \"6198a9b50d0dd012d2ec3f380f0aaa788cdea5e2920a6d7592c67e8fbca2aa46\" returns successfully"
Sep 13 14:45:26 masternode containerd[1833980]: time="2025-09-13T14:45:26.083053686-04:00" level=info msg="RemoveContainer for \"e08f780b197441d2c0f99fb4cfa238cdde9cabeb4ee699c099a1700416e73106\""
Sep 13 14:45:26 masternode containerd[1833980]: time="2025-09-13T14:45:26.092613358-04:00" level=info msg="RemoveContainer for \"e08f780b197441d2c0f99fb4cfa238cdde9cabeb4ee699c099a1700416e73106\" returns successfully"
Sep 13 14:45:26 masternode containerd[1833980]: time="2025-09-13T14:45:26.093197150-04:00" level=error msg="ContainerStatus for \"e08f780b197441d2c0f99fb4cfa238cdde9cabeb4ee699c099a1700416e73106\" failed" error="rpc error: code = NotFound desc = an error occurred when try to find container \"e08f780b197441d2c0f99fb4cfa238cdde9cabeb4ee699c099a1700416e73106\": not found"
Sep 13 14:45:26 masternode containerd[1833980]: time="2025-09-13T14:45:26.283866362-04:00" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kube-proxy-hw8p6,Uid:042b0a43-8184-493f-b4a1-0309e75f2ab3,Namespace:kube-system,Attempt:0,}"
Sep 13 14:45:26 masternode containerd[1833980]: time="2025-09-13T14:45:26.317479148-04:00" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Sep 13 14:45:26 masternode containerd[1833980]: time="2025-09-13T14:45:26.317615801-04:00" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Sep 13 14:45:26 masternode containerd[1833980]: time="2025-09-13T14:45:26.317642329-04:00" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Sep 13 14:45:26 masternode containerd[1833980]: time="2025-09-13T14:45:26.317928277-04:00" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/35cd5dacaa63684b74de79ed4357d97ee35dbc1db661999bc1d94e181a5e4dc7 pid=1868787 runtime=io.containerd.runc.v2
Sep 13 14:45:26 masternode containerd[1833980]: time="2025-09-13T14:45:26.368160825-04:00" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kube-proxy-hw8p6,Uid:042b0a43-8184-493f-b4a1-0309e75f2ab3,Namespace:kube-system,Attempt:0,} returns sandbox id \"35cd5dacaa63684b74de79ed4357d97ee35dbc1db661999bc1d94e181a5e4dc7\""
Sep 13 14:45:26 masternode containerd[1833980]: time="2025-09-13T14:45:26.370290574-04:00" level=info msg="CreateContainer within sandbox \"35cd5dacaa63684b74de79ed4357d97ee35dbc1db661999bc1d94e181a5e4dc7\" for container &ContainerMetadata{Name:kube-proxy,Attempt:0,}"
Sep 13 14:45:26 masternode containerd[1833980]: time="2025-09-13T14:45:26.407003560-04:00" level=info msg="CreateContainer within sandbox \"35cd5dacaa63684b74de79ed4357d97ee35dbc1db661999bc1d94e181a5e4dc7\" for &ContainerMetadata{Name:kube-proxy,Attempt:0,} returns container id \"671037d2d133ff9019a44facb1f3d6f20a93096220298e73ec0946374ea4d46d\""
Sep 13 14:45:26 masternode containerd[1833980]: time="2025-09-13T14:45:26.407532384-04:00" level=info msg="StartContainer for \"671037d2d133ff9019a44facb1f3d6f20a93096220298e73ec0946374ea4d46d\""
Sep 13 14:45:26 masternode containerd[1833980]: time="2025-09-13T14:45:26.470010433-04:00" level=info msg="StartContainer for \"671037d2d133ff9019a44facb1f3d6f20a93096220298e73ec0946374ea4d46d\" returns successfully"
Sep 13 14:46:06 masternode containerd[1833980]: time="2025-09-13T14:46:06.885066813-04:00" level=info msg="StopPodSandbox for \"6198a9b50d0dd012d2ec3f380f0aaa788cdea5e2920a6d7592c67e8fbca2aa46\""
Sep 13 14:46:06 masternode containerd[1833980]: time="2025-09-13T14:46:06.885437453-04:00" level=info msg="TearDown network for sandbox \"6198a9b50d0dd012d2ec3f380f0aaa788cdea5e2920a6d7592c67e8fbca2aa46\" successfully"
Sep 13 14:46:06 masternode containerd[1833980]: time="2025-09-13T14:46:06.885502812-04:00" level=info msg="StopPodSandbox for \"6198a9b50d0dd012d2ec3f380f0aaa788cdea5e2920a6d7592c67e8fbca2aa46\" returns successfully"
Sep 13 14:46:06 masternode containerd[1833980]: time="2025-09-13T14:46:06.886213447-04:00" level=info msg="RemovePodSandbox for \"6198a9b50d0dd012d2ec3f380f0aaa788cdea5e2920a6d7592c67e8fbca2aa46\""
Sep 13 14:46:06 masternode containerd[1833980]: time="2025-09-13T14:46:06.886351634-04:00" level=info msg="Forcibly stopping sandbox \"6198a9b50d0dd012d2ec3f380f0aaa788cdea5e2920a6d7592c67e8fbca2aa46\""
Sep 13 14:46:06 masternode containerd[1833980]: time="2025-09-13T14:46:06.886595738-04:00" level=info msg="TearDown network for sandbox \"6198a9b50d0dd012d2ec3f380f0aaa788cdea5e2920a6d7592c67e8fbca2aa46\" successfully"
Sep 13 14:46:06 masternode containerd[1833980]: time="2025-09-13T14:46:06.899389078-04:00" level=info msg="RemovePodSandbox \"6198a9b50d0dd012d2ec3f380f0aaa788cdea5e2920a6d7592c67e8fbca2aa46\" returns successfully"
Sep 13 14:48:42 masternode containerd[1833980]: time="2025-09-13T14:48:42.958656487-04:00" level=info msg="StopContainer for \"671037d2d133ff9019a44facb1f3d6f20a93096220298e73ec0946374ea4d46d\" with timeout 30 (s)"
Sep 13 14:48:42 masternode containerd[1833980]: time="2025-09-13T14:48:42.959628265-04:00" level=info msg="Stop container \"671037d2d133ff9019a44facb1f3d6f20a93096220298e73ec0946374ea4d46d\" with signal terminated"
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.029759473-04:00" level=info msg="shim disconnected" id=671037d2d133ff9019a44facb1f3d6f20a93096220298e73ec0946374ea4d46d
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.029820325-04:00" level=warning msg="cleaning up after shim disconnected" id=671037d2d133ff9019a44facb1f3d6f20a93096220298e73ec0946374ea4d46d namespace=k8s.io
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.029842876-04:00" level=info msg="cleaning up dead shim"
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.039013334-04:00" level=warning msg="cleanup warnings time=\"2025-09-13T14:48:43-04:00\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=1869962 runtime=io.containerd.runc.v2\n"
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.044717996-04:00" level=info msg="StopContainer for \"671037d2d133ff9019a44facb1f3d6f20a93096220298e73ec0946374ea4d46d\" returns successfully"
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.045106149-04:00" level=info msg="StopPodSandbox for \"35cd5dacaa63684b74de79ed4357d97ee35dbc1db661999bc1d94e181a5e4dc7\""
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.045203733-04:00" level=info msg="Container to stop \"671037d2d133ff9019a44facb1f3d6f20a93096220298e73ec0946374ea4d46d\" must be in running or unknown state, current state \"CONTAINER_EXITED\""
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.095089345-04:00" level=info msg="shim disconnected" id=35cd5dacaa63684b74de79ed4357d97ee35dbc1db661999bc1d94e181a5e4dc7
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.095295116-04:00" level=warning msg="cleaning up after shim disconnected" id=35cd5dacaa63684b74de79ed4357d97ee35dbc1db661999bc1d94e181a5e4dc7 namespace=k8s.io
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.095332297-04:00" level=info msg="cleaning up dead shim"
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.103372102-04:00" level=warning msg="cleanup warnings time=\"2025-09-13T14:48:43-04:00\" level=info msg=\"starting signal loop\" namespace=k8s.io pid=1869996 runtime=io.containerd.runc.v2\n"
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.103815764-04:00" level=info msg="TearDown network for sandbox \"35cd5dacaa63684b74de79ed4357d97ee35dbc1db661999bc1d94e181a5e4dc7\" successfully"
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.103844821-04:00" level=info msg="StopPodSandbox for \"35cd5dacaa63684b74de79ed4357d97ee35dbc1db661999bc1d94e181a5e4dc7\" returns successfully"
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.447030681-04:00" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kube-proxy-2z4dg,Uid:6a77170e-42e3-4a2f-bb7b-7983c83e7290,Namespace:kube-system,Attempt:0,}"
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.480615213-04:00" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.480714896-04:00" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.480734959-04:00" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.480882143-04:00" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/e9bdc4f79da7200e251bb6c496ace50f24bc53071ff9109de8b05ab6c608f852 pid=1870018 runtime=io.containerd.runc.v2
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.543841921-04:00" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kube-proxy-2z4dg,Uid:6a77170e-42e3-4a2f-bb7b-7983c83e7290,Namespace:kube-system,Attempt:0,} returns sandbox id \"e9bdc4f79da7200e251bb6c496ace50f24bc53071ff9109de8b05ab6c608f852\""
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.546119567-04:00" level=info msg="CreateContainer within sandbox \"e9bdc4f79da7200e251bb6c496ace50f24bc53071ff9109de8b05ab6c608f852\" for container &ContainerMetadata{Name:kube-proxy,Attempt:0,}"
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.584358156-04:00" level=info msg="CreateContainer within sandbox \"e9bdc4f79da7200e251bb6c496ace50f24bc53071ff9109de8b05ab6c608f852\" for &ContainerMetadata{Name:kube-proxy,Attempt:0,} returns container id \"d024a8004c0e9e61d8cbd0c8bfd8e1dc6d1f8a67da1b0c013937fed507fa2c20\""
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.584842277-04:00" level=info msg="StartContainer for \"d024a8004c0e9e61d8cbd0c8bfd8e1dc6d1f8a67da1b0c013937fed507fa2c20\""
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.651840885-04:00" level=info msg="StartContainer for \"d024a8004c0e9e61d8cbd0c8bfd8e1dc6d1f8a67da1b0c013937fed507fa2c20\" returns successfully"
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.676462188-04:00" level=info msg="RemoveContainer for \"671037d2d133ff9019a44facb1f3d6f20a93096220298e73ec0946374ea4d46d\""
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.692101833-04:00" level=info msg="RemoveContainer for \"671037d2d133ff9019a44facb1f3d6f20a93096220298e73ec0946374ea4d46d\" returns successfully"
Sep 13 14:48:43 masternode containerd[1833980]: time="2025-09-13T14:48:43.692671342-04:00" level=error msg="ContainerStatus for \"671037d2d133ff9019a44facb1f3d6f20a93096220298e73ec0946374ea4d46d\" failed" error="rpc error: code = NotFound desc = an error occurred when try to find container \"671037d2d133ff9019a44facb1f3d6f20a93096220298e73ec0946374ea4d46d\": not found"
Sep 13 14:49:06 masternode containerd[1833980]: time="2025-09-13T14:49:06.914132151-04:00" level=info msg="StopPodSandbox for \"35cd5dacaa63684b74de79ed4357d97ee35dbc1db661999bc1d94e181a5e4dc7\""
Sep 13 14:49:06 masternode containerd[1833980]: time="2025-09-13T14:49:06.914526627-04:00" level=info msg="TearDown network for sandbox \"35cd5dacaa63684b74de79ed4357d97ee35dbc1db661999bc1d94e181a5e4dc7\" successfully"
Sep 13 14:49:06 masternode containerd[1833980]: time="2025-09-13T14:49:06.914611291-04:00" level=info msg="StopPodSandbox for \"35cd5dacaa63684b74de79ed4357d97ee35dbc1db661999bc1d94e181a5e4dc7\" returns successfully"
Sep 13 14:49:06 masternode containerd[1833980]: time="2025-09-13T14:49:06.915421349-04:00" level=info msg="RemovePodSandbox for \"35cd5dacaa63684b74de79ed4357d97ee35dbc1db661999bc1d94e181a5e4dc7\""
Sep 13 14:49:06 masternode containerd[1833980]: time="2025-09-13T14:49:06.915597223-04:00" level=info msg="Forcibly stopping sandbox \"35cd5dacaa63684b74de79ed4357d97ee35dbc1db661999bc1d94e181a5e4dc7\""
Sep 13 14:49:06 masternode containerd[1833980]: time="2025-09-13T14:49:06.915818420-04:00" level=info msg="TearDown network for sandbox \"35cd5dacaa63684b74de79ed4357d97ee35dbc1db661999bc1d94e181a5e4dc7\" successfully"
Sep 13 14:49:06 masternode containerd[1833980]: time="2025-09-13T14:49:06.929144044-04:00" level=info msg="RemovePodSandbox \"35cd5dacaa63684b74de79ed4357d97ee35dbc1db661999bc1d94e181a5e4dc7\" returns successfully"
Sep 13 14:49:39 masternode containerd[1833980]: time="2025-09-13T14:49:39.786115876-04:00" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:coredns-784db4cdd8-gszlz,Uid:a0e0124b-7bf2-4bbd-b18c-bb4cce91e249,Namespace:kube-system,Attempt:0,}"
Sep 13 14:49:39 masternode containerd[1833980]: time="2025-09-13T14:49:39.865149989-04:00" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Sep 13 14:49:39 masternode containerd[1833980]: time="2025-09-13T14:49:39.865315047-04:00" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Sep 13 14:49:39 masternode containerd[1833980]: time="2025-09-13T14:49:39.865349742-04:00" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Sep 13 14:49:39 masternode containerd[1833980]: time="2025-09-13T14:49:39.865668301-04:00" level=info msg="starting signal loop" namespace=k8s.io path=/run/containerd/io.containerd.runtime.v2.task/k8s.io/dc55919cb665e26970a10718883d31cf74b4f75271930a8ffb65483a1cd812c5 pid=1870524 runtime=io.containerd.runc.v2
Sep 13 14:49:39 masternode containerd[1833980]: time="2025-09-13T14:49:39.938291916-04:00" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:coredns-784db4cdd8-gszlz,Uid:a0e0124b-7bf2-4bbd-b18c-bb4cce91e249,Namespace:kube-system,Attempt:0,} returns sandbox id \"dc55919cb665e26970a10718883d31cf74b4f75271930a8ffb65483a1cd812c5\""
Sep 13 14:49:39 masternode containerd[1833980]: time="2025-09-13T14:49:39.940766180-04:00" level=info msg="CreateContainer within sandbox \"dc55919cb665e26970a10718883d31cf74b4f75271930a8ffb65483a1cd812c5\" for container &ContainerMetadata{Name:coredns,Attempt:0,}"
Sep 13 14:49:39 masternode containerd[1833980]: time="2025-09-13T14:49:39.974389732-04:00" level=info msg="CreateContainer within sandbox \"dc55919cb665e26970a10718883d31cf74b4f75271930a8ffb65483a1cd812c5\" for &ContainerMetadata{Name:coredns,Attempt:0,} returns container id \"7516f5ba0ecaa8deee6414b842f12366727554a5b34a1b04ca1a534a571367f5\""
Sep 13 14:49:39 masternode containerd[1833980]: time="2025-09-13T14:49:39.974835707-04:00" level=info msg="StartContainer for \"7516f5ba0ecaa8deee6414b842f12366727554a5b34a1b04ca1a534a571367f5\""
Sep 13 14:49:40 masternode containerd[1833980]: time="2025-09-13T14:49:40.037347836-04:00" level=info msg="StartContainer for \"7516f5ba0ecaa8deee6414b842f12366727554a5b34a1b04ca1a534a571367f5\" returns successfully"
error: error from server (NotFound): pods "kube-proxy-4g9mt" not found in namespace "kube-system"
Name:               homelab
Roles:              <none>
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=homelab
                    kubernetes.io/os=linux
                    node.kubernetes.io/instance-type=compute
                    vmstation.io/role=compute
Annotations:        flannel.alpha.coreos.com/backend-data: {"VNI":1,"VtepMAC":"5e:b3:e9:37:1f:d1"}
                    flannel.alpha.coreos.com/backend-type: vxlan
                    flannel.alpha.coreos.com/kube-subnet-manager: true
                    flannel.alpha.coreos.com/public-ip: 192.168.4.62
                    kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/containerd/containerd.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Sat, 13 Sep 2025 13:02:09 -0400
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  homelab
  AcquireTime:     <unset>
  RenewTime:       Sat, 13 Sep 2025 15:05:18 -0400
Conditions:
  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----                 ------  -----------------                 ------------------                ------                       -------
  NetworkUnavailable   False   Sat, 13 Sep 2025 15:02:52 -0400   Sat, 13 Sep 2025 15:02:52 -0400   FlannelIsUp                  Flannel is running on this node
  MemoryPressure       False   Sat, 13 Sep 2025 15:04:57 -0400   Sat, 13 Sep 2025 13:02:09 -0400   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure         False   Sat, 13 Sep 2025 15:04:57 -0400   Sat, 13 Sep 2025 13:02:09 -0400   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure          False   Sat, 13 Sep 2025 15:04:57 -0400   Sat, 13 Sep 2025 13:02:09 -0400   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready                True    Sat, 13 Sep 2025 15:04:57 -0400   Sat, 13 Sep 2025 13:02:12 -0400   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.4.62
  Hostname:    homelab
Capacity:
  cpu:                16
  ephemeral-storage:  69664568Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             65216188Ki
  pods:               110
Allocatable:
  cpu:                16
  ephemeral-storage:  64202865763
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             65113788Ki
  pods:               110
System Info:
  Machine ID:                 07bff45e6fe54e5a8006fa5cf8c19c93
  System UUID:                4c4c4544-0039-4810-8030-b3c04f594d32
  Boot ID:                    b7efa6c1-2b6a-4bb6-b2fa-849105e97934
  Kernel Version:             6.12.0-55.9.1.el10_0.x86_64
  OS Image:                   Red Hat Enterprise Linux 10.0 (Coughlan)
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  containerd://1.7.27
  Kubelet Version:            v1.29.15
  Kube-Proxy Version:         v1.29.15
PodCIDR:                      10.244.1.0/24
PodCIDRs:                     10.244.1.0/24
Non-terminated Pods:          (2 in total)
  Namespace                   Name                     CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                     ------------  ----------  ---------------  -------------  ---
  kube-flannel                kube-flannel-ds-s46qs    100m (0%)     0 (0%)      50Mi (0%)        0 (0%)         36m
  kube-system                 kube-proxy-5p8rs         0 (0%)        0 (0%)      0 (0%)           0 (0%)         16m
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests   Limits
  --------           --------   ------
  cpu                100m (0%)  0 (0%)
  memory             50Mi (0%)  0 (0%)
  ephemeral-storage  0 (0%)     0 (0%)
  hugepages-1Gi      0 (0%)     0 (0%)
  hugepages-2Mi      0 (0%)     0 (0%)
Events:
  Type    Reason    Age    From        Message
  ----    ------    ----   ----        -------
  Normal  Starting  60m    kube-proxy
  Normal  Starting  54m    kube-proxy
  Normal  Starting  50m    kube-proxy
  Normal  Starting  49m    kube-proxy
  Normal  Starting  47m    kube-proxy
  Normal  Starting  45m    kube-proxy
  Normal  Starting  43m    kube-proxy
  Normal  Starting  42m    kube-proxy
  Normal  Starting  38m    kube-proxy
  Normal  Starting  31m    kube-proxy
  Normal  Starting  26m    kube-proxy
  Normal  Starting  20m    kube-proxy
  Normal  Starting  19m    kube-proxy
  Normal  Starting  18m    kube-proxy
  Normal  Starting  16m    kube-proxy
  Normal  Starting  16m    kube-proxy
  Normal  Starting  13m    kube-proxy
  Normal  Starting  13m    kube-proxy
  Normal  Starting  11m    kube-proxy
  Normal  Starting  9m43s  kube-proxy
  Normal  Starting  7m16s  kube-proxy
  Normal  Starting  3m3s   kube-proxy


root@masternode:~# # check for flanneld process
ps aux | grep -E 'flanneld|flannel' | grep -v grep

# if CNI runs as a container, list CRI containers and filter
sudo crictl ps -a | grep -i flannel || sudo docker ps -a | grep -i flannel
root     1861989  0.1  0.4 1266704 38040 ?       Ssl  14:29   0:03 /opt/bin/flanneld --ip-masq --kube-subnet-mgr
5975826284272       f9c73fde068fd       36 minutes ago      Running             kube-flannel              0                   3c34495bf8946       kube-flannel-ds-vk9mg
36b2184bf8ec7       f9c73fde068fd       36 minutes ago      Exited              install-cni               0                   3c34495bf8946       kube-flannel-ds-vk9mg
4c5c90966b789       77c1250c26d96       36 minutes ago      Exited              install-cni-plugin        0                   3c34495bf8946       kube-flannel-ds-vk9mg
root@masternode:~# sudo journalctl -u flanneld -n 500 --no-pager || sudo crictl logs f9c73fde068fd --tail=200
-- No entries --
root@masternode:~# sudo journalctl -u flanneld -n 500 --no-pager || sudo crictl logs 5975826284272 --tail=200
-- No entries --
root@masternode:~# sudo journalctl -u flanneld -n 500 --no-pager || sudo crictl logs 3c34495bf8946 --tail=200
-- No entries --
root@masternode:~# sudo journalctl -u flanneld -n 500 --no-pager || sudo crictl logs kube-flannel-ds-vk9mg --tail=200
-- No entries --


root@masternode:~# sudo timeout 20 tcpdump -nni enp2s0 udp port 8472 -c 200 -w /tmp/vxlan-host.pcap
sudo tcpdump -nn -r /tmp/vxlan-host.pcap -c 40
tcpdump: listening on enp2s0, link-type EN10MB (Ethernet), snapshot length 262144 bytes
12 packets captured
12 packets received by filter
0 packets dropped by kernel
reading from file /tmp/vxlan-host.pcap, link-type EN10MB (Ethernet), snapshot length 262144
15:07:28.321836 IP 192.168.4.61.41052 > 192.168.4.63.8472: OTV, flags [I] (0x08), overlay 0, instance 1
IP 10.244.2.0.41106 > 10.244.0.6.8096: Flags [S], seq 3552051933, win 64860, options [mss 1410,sackOK,TS val 1383459890 ecr 0,nop,wscale 7], length 0
15:07:29.350640 IP 192.168.4.61.47657 > 192.168.4.63.8472: OTV, flags [I] (0x08), overlay 0, instance 1
IP 10.244.2.0.41106 > 10.244.0.6.8096: Flags [S], seq 3552051933, win 64860, options [mss 1410,sackOK,TS val 1383460919 ecr 0,nop,wscale 7], length 0
15:07:31.366760 IP 192.168.4.61.40943 > 192.168.4.63.8472: OTV, flags [I] (0x08), overlay 0, instance 1
IP 10.244.2.0.41106 > 10.244.0.6.8096: Flags [S], seq 3552051933, win 64860, options [mss 1410,sackOK,TS val 1383462935 ecr 0,nop,wscale 7], length 0
15:07:31.376344 IP 192.168.4.63.59181 > 192.168.4.61.8472: OTV, flags [I] (0x08), overlay 0, instance 1
IP 10.244.0.0 > 10.244.2.0: ICMP host 10.244.0.6 unreachable, length 68
15:07:31.376376 IP 192.168.4.63.59181 > 192.168.4.61.8472: OTV, flags [I] (0x08), overlay 0, instance 1
IP 10.244.0.0 > 10.244.2.0: ICMP host 10.244.0.6 unreachable, length 68
15:07:31.376393 IP 192.168.4.63.59181 > 192.168.4.61.8472: OTV, flags [I] (0x08), overlay 0, instance 1
IP 10.244.0.0 > 10.244.2.0: ICMP host 10.244.0.6 unreachable, length 68
15:07:43.322200 IP 192.168.4.61.59912 > 192.168.4.63.8472: OTV, flags [I] (0x08), overlay 0, instance 1
IP 10.244.2.0.36988 > 10.244.0.6.8096: Flags [S], seq 1393452295, win 64860, options [mss 1410,sackOK,TS val 1383474890 ecr 0,nop,wscale 7], length 0
15:07:44.326737 IP 192.168.4.61.34726 > 192.168.4.63.8472: OTV, flags [I] (0x08), overlay 0, instance 1
IP 10.244.2.0.36988 > 10.244.0.6.8096: Flags [S], seq 1393452295, win 64860, options [mss 1410,sackOK,TS val 1383475895 ecr 0,nop,wscale 7], length 0
15:07:46.342820 IP 192.168.4.61.57257 > 192.168.4.63.8472: OTV, flags [I] (0x08), overlay 0, instance 1
IP 10.244.2.0.36988 > 10.244.0.6.8096: Flags [S], seq 1393452295, win 64860, options [mss 1410,sackOK,TS val 1383477911 ecr 0,nop,wscale 7], length 0
15:07:46.384345 IP 192.168.4.63.59181 > 192.168.4.61.8472: OTV, flags [I] (0x08), overlay 0, instance 1
IP 10.244.0.0 > 10.244.2.0: ICMP host 10.244.0.6 unreachable, length 68
15:07:46.384376 IP 192.168.4.63.59181 > 192.168.4.61.8472: OTV, flags [I] (0x08), overlay 0, instance 1
IP 10.244.0.0 > 10.244.2.0: ICMP host 10.244.0.6 unreachable, length 68
15:07:46.384388 IP 192.168.4.63.59181 > 192.168.4.61.8472: OTV, flags [I] (0x08), overlay 0, instance 1
IP 10.244.0.0 > 10.244.2.0: ICMP host 10.244.0.6 unreachable, length 68


root@masternode:~# sudo sysctl net.ipv4.ip_forward net.ipv4.conf.all.rp_filter net.ipv4.conf.default.rp_filter net.bridge.bridge-nf-call-iptables
# if rp_filter != 0 try to test with 0 temporarily
sudo sysctl -w net.ipv4.conf.all.rp_filter=0 net.ipv4.conf.default.rp_filter=0
net.ipv4.ip_forward = 1
net.ipv4.conf.all.rp_filter = 0
net.ipv4.conf.default.rp_filter = 0
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.conf.all.rp_filter = 0
net.ipv4.conf.default.rp_filter = 0


root@masternode:~# # bridge fdb and ip neigh
bridge fdb show
ip neigh show
# confirm flannel has peer entries pointing to the other node(s) IPs
33:33:00:00:00:01 dev enp2s0 self permanent
01:00:5e:00:00:01 dev enp2s0 self permanent
01:80:c2:00:00:0e dev enp2s0 self permanent
01:80:c2:00:00:03 dev enp2s0 self permanent
01:80:c2:00:00:00 dev enp2s0 self permanent
33:33:ff:68:cb:bf dev enp2s0 self permanent
33:33:00:00:00:01 dev wlp3s0b1 self permanent
01:80:c2:00:00:0e dev wlp3s0b1 self permanent
01:80:c2:00:00:03 dev wlp3s0b1 self permanent
01:80:c2:00:00:00 dev wlp3s0b1 self permanent
01:00:5e:00:00:01 dev wlp3s0b1 self permanent
33:33:00:00:00:01 dev veth9d2dff38 self permanent
01:00:5e:00:00:01 dev veth9d2dff38 self permanent
33:33:ff:59:be:d1 dev veth9d2dff38 self permanent
01:80:c2:00:00:0e dev veth9d2dff38 self permanent
01:80:c2:00:00:03 dev veth9d2dff38 self permanent
01:80:c2:00:00:00 dev veth9d2dff38 self permanent
33:33:00:00:00:01 dev veth65d56622 self permanent
01:00:5e:00:00:01 dev veth65d56622 self permanent
33:33:ff:7f:44:43 dev veth65d56622 self permanent
01:80:c2:00:00:0e dev veth65d56622 self permanent
01:80:c2:00:00:03 dev veth65d56622 self permanent
01:80:c2:00:00:00 dev veth65d56622 self permanent
33:33:00:00:00:01 dev vethec7f95f1 self permanent
01:00:5e:00:00:01 dev vethec7f95f1 self permanent
33:33:ff:99:fb:89 dev vethec7f95f1 self permanent
01:80:c2:00:00:0e dev vethec7f95f1 self permanent
01:80:c2:00:00:03 dev vethec7f95f1 self permanent
01:80:c2:00:00:00 dev vethec7f95f1 self permanent
33:33:00:00:00:01 dev veth701f2970 self permanent
01:00:5e:00:00:01 dev veth701f2970 self permanent
33:33:ff:7e:68:aa dev veth701f2970 self permanent
01:80:c2:00:00:0e dev veth701f2970 self permanent
01:80:c2:00:00:03 dev veth701f2970 self permanent
01:80:c2:00:00:00 dev veth701f2970 self permanent
33:33:00:00:00:01 dev vethadc55b67 self permanent
01:00:5e:00:00:01 dev vethadc55b67 self permanent
33:33:ff:f5:f9:f1 dev vethadc55b67 self permanent
01:80:c2:00:00:0e dev vethadc55b67 self permanent
01:80:c2:00:00:03 dev vethadc55b67 self permanent
01:80:c2:00:00:00 dev vethadc55b67 self permanent
33:33:00:00:00:01 dev veth4138f7c4 self permanent
01:00:5e:00:00:01 dev veth4138f7c4 self permanent
33:33:ff:e8:e6:52 dev veth4138f7c4 self permanent
01:80:c2:00:00:0e dev veth4138f7c4 self permanent
01:80:c2:00:00:03 dev veth4138f7c4 self permanent
01:80:c2:00:00:00 dev veth4138f7c4 self permanent
33:33:00:00:00:01 dev veth03903f1f self permanent
01:00:5e:00:00:01 dev veth03903f1f self permanent
33:33:ff:45:7f:6f dev veth03903f1f self permanent
01:80:c2:00:00:0e dev veth03903f1f self permanent
01:80:c2:00:00:03 dev veth03903f1f self permanent
01:80:c2:00:00:00 dev veth03903f1f self permanent
33:33:00:00:00:01 dev veth71b4a812 self permanent
01:00:5e:00:00:01 dev veth71b4a812 self permanent
33:33:ff:36:8c:c5 dev veth71b4a812 self permanent
01:80:c2:00:00:0e dev veth71b4a812 self permanent
01:80:c2:00:00:03 dev veth71b4a812 self permanent
01:80:c2:00:00:00 dev veth71b4a812 self permanent
33:33:00:00:00:01 dev veth9ccd5878 self permanent
01:00:5e:00:00:01 dev veth9ccd5878 self permanent
33:33:ff:45:71:7e dev veth9ccd5878 self permanent
01:80:c2:00:00:0e dev veth9ccd5878 self permanent
01:80:c2:00:00:03 dev veth9ccd5878 self permanent
01:80:c2:00:00:00 dev veth9ccd5878 self permanent
33:33:00:00:00:01 dev veth4a04d6d5 self permanent
01:00:5e:00:00:01 dev veth4a04d6d5 self permanent
33:33:ff:5c:d7:f4 dev veth4a04d6d5 self permanent
01:80:c2:00:00:0e dev veth4a04d6d5 self permanent
01:80:c2:00:00:03 dev veth4a04d6d5 self permanent
01:80:c2:00:00:00 dev veth4a04d6d5 self permanent
33:33:00:00:00:01 dev veth114c1d2b self permanent
01:00:5e:00:00:01 dev veth114c1d2b self permanent
33:33:ff:dd:a2:83 dev veth114c1d2b self permanent
01:80:c2:00:00:0e dev veth114c1d2b self permanent
01:80:c2:00:00:03 dev veth114c1d2b self permanent
01:80:c2:00:00:00 dev veth114c1d2b self permanent
33:33:00:00:00:01 dev veth21d5632c self permanent
01:00:5e:00:00:01 dev veth21d5632c self permanent
33:33:ff:42:b6:e8 dev veth21d5632c self permanent
01:80:c2:00:00:0e dev veth21d5632c self permanent
01:80:c2:00:00:03 dev veth21d5632c self permanent
01:80:c2:00:00:00 dev veth21d5632c self permanent
33:33:00:00:00:01 dev veth7cb86bad self permanent
01:00:5e:00:00:01 dev veth7cb86bad self permanent
33:33:ff:26:5e:22 dev veth7cb86bad self permanent
01:80:c2:00:00:0e dev veth7cb86bad self permanent
01:80:c2:00:00:03 dev veth7cb86bad self permanent
01:80:c2:00:00:00 dev veth7cb86bad self permanent
33:33:00:00:00:01 dev veth78b844e5 self permanent
01:00:5e:00:00:01 dev veth78b844e5 self permanent
33:33:ff:ef:b8:ef dev veth78b844e5 self permanent
01:80:c2:00:00:0e dev veth78b844e5 self permanent
01:80:c2:00:00:03 dev veth78b844e5 self permanent
01:80:c2:00:00:00 dev veth78b844e5 self permanent
33:33:00:00:00:01 dev vethec893a45 self permanent
01:00:5e:00:00:01 dev vethec893a45 self permanent
33:33:ff:8e:92:97 dev vethec893a45 self permanent
01:80:c2:00:00:0e dev vethec893a45 self permanent
01:80:c2:00:00:03 dev vethec893a45 self permanent
01:80:c2:00:00:00 dev vethec893a45 self permanent
33:33:00:00:00:01 dev vetha8076e49 self permanent
01:00:5e:00:00:01 dev vetha8076e49 self permanent
33:33:ff:f1:f8:87 dev vetha8076e49 self permanent
01:80:c2:00:00:0e dev vetha8076e49 self permanent
01:80:c2:00:00:03 dev vetha8076e49 self permanent
01:80:c2:00:00:00 dev vetha8076e49 self permanent
33:33:00:00:00:01 dev veth59cc4f99 self permanent
01:00:5e:00:00:01 dev veth59cc4f99 self permanent
33:33:ff:86:ef:2f dev veth59cc4f99 self permanent
01:80:c2:00:00:0e dev veth59cc4f99 self permanent
01:80:c2:00:00:03 dev veth59cc4f99 self permanent
01:80:c2:00:00:00 dev veth59cc4f99 self permanent
de:29:87:ed:04:e1 dev flannel.1 dst 192.168.4.61 self permanent
5e:b3:e9:37:1f:d1 dev flannel.1 dst 192.168.4.62 self permanent
1e:61:58:2a:85:97 dev flannel.1 dst 192.168.4.62 self permanent
33:33:00:00:00:01 dev cni0 self permanent
01:00:5e:00:00:6a dev cni0 self permanent
33:33:00:00:00:6a dev cni0 self permanent
01:00:5e:00:00:01 dev cni0 self permanent
33:33:ff:de:c1:f8 dev cni0 self permanent
de:c0:75:de:c1:f8 dev cni0 vlan 1 master cni0 permanent
de:c0:75:de:c1:f8 dev cni0 master cni0 permanent
02:ae:b6:1f:5e:30 dev veth9d4a1a2c master cni0
be:78:80:97:2a:b1 dev veth9d4a1a2c vlan 1 master cni0 permanent
be:78:80:97:2a:b1 dev veth9d4a1a2c master cni0 permanent
33:33:00:00:00:01 dev veth9d4a1a2c self permanent
01:00:5e:00:00:01 dev veth9d4a1a2c self permanent
33:33:ff:97:2a:b1 dev veth9d4a1a2c self permanent
01:80:c2:00:00:0e dev veth9d4a1a2c self permanent
01:80:c2:00:00:03 dev veth9d4a1a2c self permanent
01:80:c2:00:00:00 dev veth9d4a1a2c self permanent
1e:d2:f6:d5:81:f8 dev vetha7ab7ffe vlan 1 master cni0 permanent
1e:d2:f6:d5:81:f8 dev vetha7ab7ffe master cni0 permanent
33:33:00:00:00:01 dev vetha7ab7ffe self permanent
01:00:5e:00:00:01 dev vetha7ab7ffe self permanent
33:33:ff:d5:81:f8 dev vetha7ab7ffe self permanent
01:80:c2:00:00:0e dev vetha7ab7ffe self permanent
01:80:c2:00:00:03 dev vetha7ab7ffe self permanent
01:80:c2:00:00:00 dev vetha7ab7ffe self permanent
5a:9c:04:c2:bd:5d dev vethecd57269 master cni0
82:33:bd:53:84:43 dev vethecd57269 vlan 1 master cni0 permanent
82:33:bd:53:84:43 dev vethecd57269 master cni0 permanent
33:33:00:00:00:01 dev vethecd57269 self permanent
01:00:5e:00:00:01 dev vethecd57269 self permanent
33:33:ff:53:84:43 dev vethecd57269 self permanent
01:80:c2:00:00:0e dev vethecd57269 self permanent
01:80:c2:00:00:03 dev vethecd57269 self permanent
01:80:c2:00:00:00 dev vethecd57269 self permanent
192.168.4.48 dev enp2s0 lladdr f0:70:4f:8d:71:3b STALE
10.244.0.3 dev cni0 FAILED
169.254.169.253 dev enp2s0 FAILED
10.244.0.11 dev cni0 FAILED
192.168.4.32 dev enp2s0 lladdr cc:f9:e4:36:71:85 REACHABLE
192.168.4.22 dev enp2s0 lladdr dc:ef:ca:fa:4d:95 STALE
10.244.0.2 dev cni0 FAILED
10.244.2.0 dev flannel.1 lladdr de:29:87:ed:04:e1 PERMANENT
169.254.169.254 dev enp2s0 FAILED
10.244.0.10 dev cni0 lladdr 5a:9c:04:c2:bd:5d REACHABLE
192.168.4.23 dev enp2s0 lladdr 66:59:e7:12:53:7d STALE
10.244.0.9 dev cni0 lladdr a6:14:ec:46:c8:59 STALE
10.244.0.7 dev cni0 lladdr 1a:84:8b:46:b9:9f STALE
10.244.0.17 dev cni0 FAILED
10.244.0.8 dev cni0 lladdr 02:ae:b6:1f:5e:30 REACHABLE
192.168.4.61 dev enp2s0 lladdr b8:ac:6f:7e:6c:9d REACHABLE
10.244.0.15 dev cni0 FAILED
10.244.1.0 dev flannel.1 lladdr 5e:b3:e9:37:1f:d1 PERMANENT
10.244.0.6 dev cni0 INCOMPLETE
10.244.0.16 dev cni0 FAILED
192.168.4.1 dev enp2s0 lladdr f0:21:e0:c4:79:ed REACHABLE
192.168.4.62 dev enp2s0 lladdr d0:94:66:30:d6:63 REACHABLE
192.168.4.10 dev enp2s0 lladdr 80:e0:1d:1c:cd:47 STALE
10.244.0.5 dev cni0 lladdr 9e:9a:9e:c5:56:0e STALE
10.244.0.22 dev cni0 FAILED
10.244.0.13 dev cni0 FAILED
10.244.0.21 dev cni0 FAILED
fe80::f221:e0ff:fec4:79ed dev enp2s0 lladdr f0:21:e0:c4:79:ed router STALE
