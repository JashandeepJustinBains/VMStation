you are causing more and more problems the more you "work" on the fix to join this storagenodet3500 to the cluster, it should not be a hard task. in fact it should be one of the easiest. Everytime I run the deploy script it gets worse and worse outputs. Do not just go down a rabbit hole of upping and upping the timeout that is moronic and a waste of time. Instead look through root issues and debug all possiblities. Regardless here is the output of the latest 'deploy.sh full' I just want a simple kubernetes cluster of 3 nodes handling different tasks how is this so difficult. And lower the timeout duration its just wasting my time when I know the symptom is the timeout not the cause of errors being timing out.

TASK [Copy enhanced join scripts to worker nodes] *********************************************************************************************************************************************
skipping: [192.168.4.62] => (item=../../scripts/validate_join_prerequisites.sh)
skipping: [192.168.4.62] => (item=../../scripts/enhanced_kubeadm_join.sh)
skipping: [192.168.4.62]
ok: [192.168.4.61] => (item=../../scripts/validate_join_prerequisites.sh)
changed: [192.168.4.61] => (item=../../scripts/enhanced_kubeadm_join.sh)

TASK [Execute enhanced join process] **********************************************************************************************************************************************************
skipping: [192.168.4.62]
fatal: [192.168.4.61]: FAILED! => {"changed": true, "cmd": "# Set environment variables for enhanced join\nexport MASTER_IP=\"192.168.4.63\"\nexport JOIN_TIMEOUT=300\nexport MAX_RETRIES=2\n\n# Extract base join command from script (remove \"$@\" placeholder)\nJOIN_COMMAND=$(grep -v '^#' /tmp/kubeadm-join.sh | grep kubeadm | head -1 | sed 's/ \"\\$@\"$//')\n\n# Run enhanced join process with properly quoted command\n/tmp/enhanced_kubeadm_join.sh \"$JOIN_COMMAND\"\n", "delta": "0:11:17.522209", "end": "2025-09-10 16:07:03.709478", "failed_when_result": true, "msg": "non-zero return code", "rc": 1, "start": "2025-09-10 15:55:46.187269", "stderr": "", "stderr_lines": [], "stdout": "=== VMStation Enhanced Kubeadm Join Process ===\nTimestamp: Wed Sep 10 15:55:46 EDT 2025\nMaster IP: 192.168.4.63\nJoin timeout: 300s\nLog file: /tmp/kubeadm-join-20250910-155546.log\n\n=== Enhanced Kubeadm Join Process Started ===\nCommand: kubeadm join 192.168.4.63:6443 --token lcdkmw.h6nbbtuxap5mz3pf --discovery-token-ca-cert-hash sha256:95d2831b85d03685274b19af0ba0ac7495a8410bace8263f6a7628fd1e129473 \nTimestamp: Wed Sep 10 15:55:46 EDT 2025\n\u001b[0;32m[INFO]\u001b[0m Checking existing join status...\n\u001b[0;32m[INFO]\u001b[0m No existing join detected\n\u001b[0;32m[INFO]\u001b[0m Running comprehensive prerequisite validation...\n=== VMStation Join Prerequisites Validator ===\nTimestamp: Wed Sep 10 15:55:46 EDT 2025\nValidating prerequisites for joining master: 192.168.4.63\n\n\u001b[0;32m[INFO]\u001b[0m Checking system requirements...\n\u001b[0;32m[INFO]\u001b[0m ✓ Memory: 7GB\n\u001b[0;32m[INFO]\u001b[0m ✓ Disk space OK for /var/lib/kubelet\n\u001b[0;32m[INFO]\u001b[0m ✓ Disk space OK for /var/lib/containerd\n\u001b[0;32m[INFO]\u001b[0m ✓ Disk space OK for /etc/kubernetes\n\u001b[0;32m[INFO]\u001b[0m ✓ Swap is disabled\n\u001b[0;32m[INFO]\u001b[0m Checking connectivity to master node...\n\u001b[0;32m[INFO]\u001b[0m ✓ Basic ping to master successful\n\u001b[0;32m[INFO]\u001b[0m ✓ API server port 6443 is reachable\n\u001b[0;32m[INFO]\u001b[0m ✓ API server health endpoint responds\n\u001b[0;32m[INFO]\u001b[0m Checking container runtime...\n\u001b[0;32m[INFO]\u001b[0m ✓ containerd service is active\n\u001b[0;32m[INFO]\u001b[0m ✓ containerd socket exists\n\u001b[0;32m[INFO]\u001b[0m ✓ containerd client connection works\n\u001b[0;32m[INFO]\u001b[0m ✓ crictl can connect to runtime\n\u001b[0;32m[INFO]\u001b[0m Checking Kubernetes packages...\n\u001b[0;32m[INFO]\u001b[0m ✓ kubelet installed: Kubernetes v1.29.15\n\u001b[0;32m[INFO]\u001b[0m ✓ kubeadm installed: \n\u001b[0;32m[INFO]\u001b[0m ✓ kubectl installed: \n\u001b[0;32m[INFO]\u001b[0m ✓ kubelet service unit exists\n\u001b[0;32m[INFO]\u001b[0m Checking network configuration...\n\u001b[0;32m[INFO]\u001b[0m ✓ br_netfilter module loaded\n\u001b[0;32m[INFO]\u001b[0m ✓ overlay module loaded\n\u001b[0;32m[INFO]\u001b[0m ✓ net.bridge.bridge-nf-call-iptables = 1\n\u001b[0;32m[INFO]\u001b[0m ✓ net.bridge.bridge-nf-call-ip6tables = 1\n\u001b[0;32m[INFO]\u001b[0m ✓ net.ipv4.ip_forward = 1\n\u001b[0;32m[INFO]\u001b[0m Checking existing Kubernetes configuration...\n\u001b[0;32m[INFO]\u001b[0m ✓ No existing kubelet.conf (clean state)\n\u001b[0;32m[INFO]\u001b[0m Checking system resources...\n\u001b[0;32m[INFO]\u001b[0m ✓ CPU cores: 8\n\u001b[0;32m[INFO]\u001b[0m ✓ System load: 0.34\n\n=== Validation Summary ===\n\u001b[0;32m[INFO]\u001b[0m ✅ All prerequisites validated successfully!\n\u001b[0;32m[INFO]\u001b[0m System is ready for kubeadm join\n\n\u001b[0;32m[INFO]\u001b[0m Recommended next steps:\n\u001b[0;32m[INFO]\u001b[0m 1. Ensure master node has a valid join token\n\u001b[0;32m[INFO]\u001b[0m 2. Run kubeadm join with appropriate parameters\n\u001b[0;32m[INFO]\u001b[0m 3. Monitor kubelet logs during join process\n\u001b[0;32m[INFO]\u001b[0m ✅ All prerequisites validated successfully\n\u001b[0;32m[INFO]\u001b[0m === Join Attempt 1/2 ===\n\u001b[0;32m[INFO]\u001b[0m Preparing system for join...\n\u001b[0;32m[INFO]\u001b[0m Stopping kubelet service...\n\u001b[0;32m[INFO]\u001b[0m Cleaning existing kubelet state...\n\u001b[0;32m[INFO]\u001b[0m Restarting containerd...\n\u001b[0;32m[INFO]\u001b[0m ✓ System prepared for join\n\u001b[0;32m[INFO]\u001b[0m Performing kubeadm join (attempt 1)...\nJoin command: kubeadm join 192.168.4.63:6443 --token lcdkmw.h6nbbtuxap5mz3pf --discovery-token-ca-cert-hash sha256:95d2831b85d03685274b19af0ba0ac7495a8410bace8263f6a7628fd1e129473 \n\u001b[0;32m[INFO]\u001b[0m Monitoring kubelet join process (timeout: 300s)...\nEnhanced command: timeout 360 kubeadm join 192.168.4.63:6443 --token lcdkmw.h6nbbtuxap5mz3pf --discovery-token-ca-cert-hash sha256:95d2831b85d03685274b19af0ba0ac7495a8410bace8263f6a7628fd1e129473  --v=5\nI0910 15:56:04.170764  389740 join.go:413] [preflight] found NodeName empty; using OS hostname as NodeName\nI0910 15:56:04.170989  389740 initconfiguration.go:122] detected and using CRI socket: unix:///var/run/containerd/containerd.sock\n[preflight] Running pre-flight checks\nI0910 15:56:04.171071  389740 preflight.go:93] [preflight] Running general checks\nI0910 15:56:04.171128  389740 checks.go:280] validating the existence of file /etc/kubernetes/kubelet.conf\nI0910 15:56:04.171142  389740 checks.go:280] validating the existence of file /etc/kubernetes/bootstrap-kubelet.conf\nI0910 15:56:04.171153  389740 checks.go:104] validating the container runtime\nI0910 15:56:04.196853  389740 checks.go:639] validating whether swap is enabled or not\nI0910 15:56:04.196933  389740 checks.go:370] validating the presence of executable crictl\nI0910 15:56:04.196974  389740 checks.go:370] validating the presence of executable conntrack\nI0910 15:56:04.197000  389740 checks.go:370] validating the presence of executable ip\nI0910 15:56:04.197023  389740 checks.go:370] validating the presence of executable iptables\nI0910 15:56:04.197047  389740 checks.go:370] validating the presence of executable mount\nI0910 15:56:04.197070  389740 checks.go:370] validating the presence of executable nsenter\nI0910 15:56:04.197093  389740 checks.go:370] validating the presence of executable ethtool\nI0910 15:56:04.197114  389740 checks.go:370] validating the presence of executable tc\nI0910 15:56:04.197133  389740 checks.go:370] validating the presence of executable touch\nI0910 15:56:04.197157  389740 checks.go:516] running all checks\nI0910 15:56:04.210219  389740 checks.go:401] checking whether the given node name is valid and reachable using net.LookupHost\nI0910 15:56:04.210511  389740 checks.go:605] validating kubelet version\nI0910 15:56:04.265495  389740 checks.go:130] validating if the \"kubelet\" service is enabled and active\nI0910 15:56:04.299706  389740 checks.go:203] validating availability of port 10250\nI0910 15:56:04.299967  389740 checks.go:280] validating the existence of file /etc/kubernetes/pki/ca.crt\nI0910 15:56:04.299985  389740 checks.go:430] validating if the connectivity type is via proxy or direct\nI0910 15:56:04.300029  389740 checks.go:329] validating the contents of file /proc/sys/net/bridge/bridge-nf-call-iptables\nI0910 15:56:04.300082  389740 checks.go:329] validating the contents of file /proc/sys/net/ipv4/ip_forward\nI0910 15:56:04.300138  389740 join.go:532] [preflight] Discovering cluster-info\nI0910 15:56:04.300167  389740 token.go:80] [discovery] Created cluster-info discovery client, requesting info from \"192.168.4.63:6443\"\nI0910 15:56:04.325851  389740 token.go:118] [discovery] Requesting info from \"192.168.4.63:6443\" again to validate TLS against the pinned public key\nI0910 15:56:04.343620  389740 token.go:135] [discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server \"192.168.4.63:6443\"\nI0910 15:56:04.343643  389740 discovery.go:52] [discovery] Using provided TLSBootstrapToken as authentication credentials for the join process\nI0910 15:56:04.343659  389740 join.go:546] [preflight] Fetching init configuration\nI0910 15:56:04.343668  389740 join.go:592] [preflight] Retrieving KubeConfig objects\n[preflight] Reading configuration from the cluster...\n[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'\nI0910 15:56:04.363777  389740 kubeproxy.go:55] attempting to download the KubeProxyConfiguration from ConfigMap \"kube-proxy\"\nI0910 15:56:04.371094  389740 kubelet.go:74] attempting to download the KubeletConfiguration from ConfigMap \"kubelet-config\"\nI0910 15:56:04.387977  389740 initconfiguration.go:114] skip CRI socket detection, fill with the default CRI socket unix:///var/run/containerd/containerd.sock\nI0910 15:56:04.388214  389740 interface.go:432] Looking for default routes with IPv4 addresses\nI0910 15:56:04.388233  389740 interface.go:437] Default route transits interface \"enp5s0\"\nI0910 15:56:04.388359  389740 interface.go:209] Interface enp5s0 is up\nI0910 15:56:04.388451  389740 interface.go:257] Interface \"enp5s0\" has 3 addresses :[192.168.4.61/24 fd91:176e:252c:1:baac:6fff:fe7e:6c9d/64 fe80::baac:6fff:fe7e:6c9d/64].\nI0910 15:56:04.388479  389740 interface.go:224] Checking addr  192.168.4.61/24.\nI0910 15:56:04.388497  389740 interface.go:231] IP found 192.168.4.61\nI0910 15:56:04.388516  389740 interface.go:263] Found valid IPv4 address 192.168.4.61 for interface \"enp5s0\".\nI0910 15:56:04.388534  389740 interface.go:443] Found active IP 192.168.4.61 \nI0910 15:56:04.399904  389740 preflight.go:104] [preflight] Running configuration dependant checks\nI0910 15:56:04.399934  389740 controlplaneprepare.go:225] [download-certs] Skipping certs download\nI0910 15:56:04.399973  389740 kubelet.go:121] [kubelet-start] writing bootstrap kubelet config file at /etc/kubernetes/bootstrap-kubelet.conf\nI0910 15:56:04.401370  389740 kubelet.go:136] [kubelet-start] writing CA certificate at /etc/kubernetes/pki/ca.crt\nI0910 15:56:04.402439  389740 kubelet.go:157] [kubelet-start] Checking for an existing Node in the cluster with name \"storagenodet3500\" and status \"Ready\"\nI0910 15:56:04.407024  389740 kubelet.go:172] [kubelet-start] Stopping the kubelet\n[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet-start] Starting the kubelet\n[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...\n[kubelet-check] Initial timeout of 40s passed.\n\nUnfortunately, an error has occurred:\n\ttimed out waiting for the condition\n\nThis error is likely caused by:\n\t- The kubelet is not running\n\t- The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled)\n\nIf you are on a systemd-powered system, you can try to troubleshoot the error with the following commands:\n\t- 'systemctl status kubelet'\n\t- 'journalctl -xeu kubelet'\ntimed out waiting for the condition\nerror execution phase kubelet-start\nk8s.io/kubernetes/cmd/kubeadm/app/cmd/phases/workflow.(*Runner).Run.func1\n\tk8s.io/kubernetes/cmd/kubeadm/app/cmd/phases/workflow/runner.go:260\nk8s.io/kubernetes/cmd/kubeadm/app/cmd/phases/workflow.(*Runner).visitAll\n\tk8s.io/kubernetes/cmd/kubeadm/app/cmd/phases/workflow/runner.go:446\nk8s.io/kubernetes/cmd/kubeadm/app/cmd/phases/workflow.(*Runner).Run\n\tk8s.io/kubernetes/cmd/kubeadm/app/cmd/phases/workflow/runner.go:232\nk8s.io/kubernetes/cmd/kubeadm/app/cmd.newCmdJoin.func1\n\tk8s.io/kubernetes/cmd/kubeadm/app/cmd/join.go:180\ngithub.com/spf13/cobra.(*Command).execute\n\tgithub.com/spf13/cobra@v1.7.0/command.go:940\ngithub.com/spf13/cobra.(*Command).ExecuteC\n\tgithub.com/spf13/cobra@v1.7.0/command.go:1068\ngithub.com/spf13/cobra.(*Command).Execute\n\tgithub.com/spf13/cobra@v1.7.0/command.go:992\nk8s.io/kubernetes/cmd/kubeadm/app.Run\n\tk8s.io/kubernetes/cmd/kubeadm/app/kubeadm.go:50\nmain.main\n\tk8s.io/kubernetes/cmd/kubeadm/kubeadm.go:25\nruntime.main\n\truntime/proc.go:272\nruntime.goexit\n\truntime/asm_amd64.s:1700\n\u001b[0;31m[ERROR]\u001b[0m Kubelet join monitoring timed out after 300s\n\u001b[1;33m[WARN]\u001b[0m kubeadm join command succeeded but kubelet monitoring failed\n\u001b[1;33m[WARN]\u001b[0m Join attempt 1 failed\n\u001b[1;33m[WARN]\u001b[0m Cleaning up for retry...\n\u001b[0;32m[INFO]\u001b[0m Cleaning up after failed join...\n[preflight] Running pre-flight checks\n[reset] Deleted contents of the etcd data directory: /var/lib/etcd\n[reset] Stopping the kubelet service\n[reset] Unmounting mounted directories in \"/var/lib/kubelet\"\n[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]\n[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/super-admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]\n\nThe reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d\n\nThe reset process does not reset or clean up iptables rules or IPVS tables.\nIf you wish to reset iptables, you must do so manually by using the \"iptables\" command.\n\nIf your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)\nto reset your system's IPVS tables.\n\nThe reset process does not clean your kubeconfig files and you must remove them manually.\nPlease, check the contents of the $HOME/.kube/config file.\n\u001b[0;32m[INFO]\u001b[0m ✓ Cleanup completed\n\u001b[0;32m[INFO]\u001b[0m Waiting 30s before retry...\n\u001b[0;32m[INFO]\u001b[0m === Join Attempt 2/2 ===\n\u001b[0;32m[INFO]\u001b[0m Preparing system for join...\n\u001b[0;32m[INFO]\u001b[0m Stopping kubelet service...\n\u001b[0;32m[INFO]\u001b[0m Cleaning existing kubelet state...\n\u001b[0;32m[INFO]\u001b[0m Restarting containerd...\n\u001b[0;32m[INFO]\u001b[0m ✓ System prepared for join\n\u001b[0;32m[INFO]\u001b[0m Performing kubeadm join (attempt 2)...\nJoin command: kubeadm join 192.168.4.63:6443 --token lcdkmw.h6nbbtuxap5mz3pf --discovery-token-ca-cert-hash sha256:95d2831b85d03685274b19af0ba0ac7495a8410bace8263f6a7628fd1e129473 \n\u001b[0;32m[INFO]\u001b[0m Monitoring kubelet join process (timeout: 300s)...\nEnhanced command: timeout 360 kubeadm join 192.168.4.63:6443 --token lcdkmw.h6nbbtuxap5mz3pf --discovery-token-ca-cert-hash sha256:95d2831b85d03685274b19af0ba0ac7495a8410bace8263f6a7628fd1e129473  --v=5\nI0910 16:02:02.000164  390416 join.go:413] [preflight] found NodeName empty; using OS hostname as NodeName\nI0910 16:02:02.000404  390416 initconfiguration.go:122] detected and using CRI socket: unix:///var/run/containerd/containerd.sock\n[preflight] Running pre-flight checks\nI0910 16:02:02.000494  390416 preflight.go:93] [preflight] Running general checks\nI0910 16:02:02.000551  390416 checks.go:280] validating the existence of file /etc/kubernetes/kubelet.conf\nI0910 16:02:02.000566  390416 checks.go:280] validating the existence of file /etc/kubernetes/bootstrap-kubelet.conf\nI0910 16:02:02.000577  390416 checks.go:104] validating the container runtime\nI0910 16:02:02.027895  390416 checks.go:639] validating whether swap is enabled or not\nI0910 16:02:02.027991  390416 checks.go:370] validating the presence of executable crictl\nI0910 16:02:02.028030  390416 checks.go:370] validating the presence of executable conntrack\nI0910 16:02:02.028065  390416 checks.go:370] validating the presence of executable ip\nI0910 16:02:02.028089  390416 checks.go:370] validating the presence of executable iptables\nI0910 16:02:02.028114  390416 checks.go:370] validating the presence of executable mount\nI0910 16:02:02.028140  390416 checks.go:370] validating the presence of executable nsenter\nI0910 16:02:02.028164  390416 checks.go:370] validating the presence of executable ethtool\nI0910 16:02:02.028185  390416 checks.go:370] validating the presence of executable tc\nI0910 16:02:02.028206  390416 checks.go:370] validating the presence of executable touch\nI0910 16:02:02.028230  390416 checks.go:516] running all checks\nI0910 16:02:02.041959  390416 checks.go:401] checking whether the given node name is valid and reachable using net.LookupHost\nI0910 16:02:02.042132  390416 checks.go:605] validating kubelet version\nI0910 16:02:02.099151  390416 checks.go:130] validating if the \"kubelet\" service is enabled and active\nI0910 16:02:02.132394  390416 checks.go:203] validating availability of port 10250\nI0910 16:02:02.132641  390416 checks.go:280] validating the existence of file /etc/kubernetes/pki/ca.crt\nI0910 16:02:02.132663  390416 checks.go:430] validating if the connectivity type is via proxy or direct\nI0910 16:02:02.132716  390416 checks.go:329] validating the contents of file /proc/sys/net/bridge/bridge-nf-call-iptables\nI0910 16:02:02.132797  390416 checks.go:329] validating the contents of file /proc/sys/net/ipv4/ip_forward\nI0910 16:02:02.132842  390416 join.go:532] [preflight] Discovering cluster-info\nI0910 16:02:02.132874  390416 token.go:80] [discovery] Created cluster-info discovery client, requesting info from \"192.168.4.63:6443\"\nI0910 16:02:02.148593  390416 token.go:118] [discovery] Requesting info from \"192.168.4.63:6443\" again to validate TLS against the pinned public key\nI0910 16:02:02.163858  390416 token.go:135] [discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server \"192.168.4.63:6443\"\nI0910 16:02:02.163879  390416 discovery.go:52] [discovery] Using provided TLSBootstrapToken as authentication credentials for the join process\nI0910 16:02:02.163893  390416 join.go:546] [preflight] Fetching init configuration\nI0910 16:02:02.163901  390416 join.go:592] [preflight] Retrieving KubeConfig objects\n[preflight] Reading configuration from the cluster...\n[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'\nI0910 16:02:02.183107  390416 kubeproxy.go:55] attempting to download the KubeProxyConfiguration from ConfigMap \"kube-proxy\"\nI0910 16:02:02.188384  390416 kubelet.go:74] attempting to download the KubeletConfiguration from ConfigMap \"kubelet-config\"\nI0910 16:02:02.193830  390416 initconfiguration.go:114] skip CRI socket detection, fill with the default CRI socket unix:///var/run/containerd/containerd.sock\nI0910 16:02:02.194015  390416 interface.go:432] Looking for default routes with IPv4 addresses\nI0910 16:02:02.194029  390416 interface.go:437] Default route transits interface \"enp5s0\"\nI0910 16:02:02.194133  390416 interface.go:209] Interface enp5s0 is up\nI0910 16:02:02.194200  390416 interface.go:257] Interface \"enp5s0\" has 3 addresses :[192.168.4.61/24 fd91:176e:252c:1:baac:6fff:fe7e:6c9d/64 fe80::baac:6fff:fe7e:6c9d/64].\nI0910 16:02:02.194222  390416 interface.go:224] Checking addr  192.168.4.61/24.\nI0910 16:02:02.194236  390416 interface.go:231] IP found 192.168.4.61\nI0910 16:02:02.194250  390416 interface.go:263] Found valid IPv4 address 192.168.4.61 for interface \"enp5s0\".\nI0910 16:02:02.194263  390416 interface.go:443] Found active IP 192.168.4.61 \nI0910 16:02:02.205263  390416 preflight.go:104] [preflight] Running configuration dependant checks\nI0910 16:02:02.205287  390416 controlplaneprepare.go:225] [download-certs] Skipping certs download\nI0910 16:02:02.205316  390416 kubelet.go:121] [kubelet-start] writing bootstrap kubelet config file at /etc/kubernetes/bootstrap-kubelet.conf\nI0910 16:02:02.206437  390416 kubelet.go:136] [kubelet-start] writing CA certificate at /etc/kubernetes/pki/ca.crt\nI0910 16:02:02.207553  390416 kubelet.go:157] [kubelet-start] Checking for an existing Node in the cluster with name \"storagenodet3500\" and status \"Ready\"\nI0910 16:02:02.211811  390416 kubelet.go:172] [kubelet-start] Stopping the kubelet\n[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet-start] Starting the kubelet\n[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...\n[kubelet-check] Initial timeout of 40s passed.\n\nUnfortunately, an error has occurred:\n\ttimed out waiting for the condition\n\nThis error is likely caused by:\n\t- The kubelet is not running\n\t- The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled)\n\nIf you are on a systemd-powered system, you can try to troubleshoot the error with the following commands:\n\t- 'systemctl status kubelet'\n\t- 'journalctl -xeu kubelet'\ntimed out waiting for the condition\nerror execution phase kubelet-start\nk8s.io/kubernetes/cmd/kubeadm/app/cmd/phases/workflow.(*Runner).Run.func1\n\tk8s.io/kubernetes/cmd/kubeadm/app/cmd/phases/workflow/runner.go:260\nk8s.io/kubernetes/cmd/kubeadm/app/cmd/phases/workflow.(*Runner).visitAll\n\tk8s.io/kubernetes/cmd/kubeadm/app/cmd/phases/workflow/runner.go:446\nk8s.io/kubernetes/cmd/kubeadm/app/cmd/phases/workflow.(*Runner).Run\n\tk8s.io/kubernetes/cmd/kubeadm/app/cmd/phases/workflow/runner.go:232\nk8s.io/kubernetes/cmd/kubeadm/app/cmd.newCmdJoin.func1\n\tk8s.io/kubernetes/cmd/kubeadm/app/cmd/join.go:180\ngithub.com/spf13/cobra.(*Command).execute\n\tgithub.com/spf13/cobra@v1.7.0/command.go:940\ngithub.com/spf13/cobra.(*Command).ExecuteC\n\tgithub.com/spf13/cobra@v1.7.0/command.go:1068\ngithub.com/spf13/cobra.(*Command).Execute\n\tgithub.com/spf13/cobra@v1.7.0/command.go:992\nk8s.io/kubernetes/cmd/kubeadm/app.Run\n\tk8s.io/kubernetes/cmd/kubeadm/app/kubeadm.go:50\nmain.main\n\tk8s.io/kubernetes/cmd/kubeadm/kubeadm.go:25\nruntime.main\n\truntime/proc.go:272\nruntime.goexit\n\truntime/asm_amd64.s:1700\n\u001b[0;31m[ERROR]\u001b[0m Kubelet join monitoring timed out after 300s\n\u001b[1;33m[WARN]\u001b[0m kubeadm join command succeeded but kubelet monitoring failed\n\u001b[1;33m[WARN]\u001b[0m Join attempt 2 failed\n\u001b[0;31m[ERROR]\u001b[0m ❌ All join attempts failed after 2 tries\nAll join attempts failed at Wed Sep 10 16:07:03 EDT 2025\n\n\u001b[0;31m[ERROR]\u001b[0m Diagnostic information:\n\u001b[0;31m[ERROR]\u001b[0m 1. Check log file: /tmp/kubeadm-join-20250910-155546.log\n\u001b[0;31m[ERROR]\u001b[0m 2. Check kubelet status: systemctl status kubelet\n\u001b[0;31m[ERROR]\u001b[0m 3. Check kubelet logs: journalctl -u kubelet -f\n\u001b[0;31m[ERROR]\u001b[0m 4. Check containerd status: systemctl status containerd\n\u001b[0;31m[ERROR]\u001b[0m 5. Verify master node connectivity: curl -k https://192.168.4.63:6443/healthz", "stdout_lines": ["=== VMStation Enhanced Kubeadm Join Process ===", "Timestamp: Wed Sep 10 15:55:46 EDT 2025", "Master IP: 192.168.4.63", "Join timeout: 300s", "Log file: /tmp/kubeadm-join-20250910-155546.log", "", "=== Enhanced Kubeadm Join Process Started ===", "Command: kubeadm join 192.168.4.63:6443 --token lcdkmw.h6nbbtuxap5mz3pf --discovery-token-ca-cert-hash sha256:95d2831b85d03685274b19af0ba0ac7495a8410bace8263f6a7628fd1e129473 ", "Timestamp: Wed Sep 10 15:55:46 EDT 2025", "\u001b[0;32m[INFO]\u001b[0m Checking existing join status...", "\u001b[0;32m[INFO]\u001b[0m No existing join detected", "\u001b[0;32m[INFO]\u001b[0m Running comprehensive prerequisite validation...", "=== VMStation Join Prerequisites Validator ===", "Timestamp: Wed Sep 10 15:55:46 EDT 2025", "Validating prerequisites for joining master: 192.168.4.63", "", "\u001b[0;32m[INFO]\u001b[0m Checking system requirements...", "\u001b[0;32m[INFO]\u001b[0m ✓ Memory: 7GB", "\u001b[0;32m[INFO]\u001b[0m ✓ Disk space OK for /var/lib/kubelet", "\u001b[0;32m[INFO]\u001b[0m ✓ Disk space OK for /var/lib/containerd", "\u001b[0;32m[INFO]\u001b[0m ✓ Disk space OK for /etc/kubernetes", "\u001b[0;32m[INFO]\u001b[0m ✓ Swap is disabled", "\u001b[0;32m[INFO]\u001b[0m Checking connectivity to master node...", "\u001b[0;32m[INFO]\u001b[0m ✓ Basic ping to master successful", "\u001b[0;32m[INFO]\u001b[0m ✓ API server port 6443 is reachable", "\u001b[0;32m[INFO]\u001b[0m ✓ API server health endpoint responds", "\u001b[0;32m[INFO]\u001b[0m Checking container runtime...", "\u001b[0;32m[INFO]\u001b[0m ✓ containerd service is active", "\u001b[0;32m[INFO]\u001b[0m ✓ containerd socket exists", "\u001b[0;32m[INFO]\u001b[0m ✓ containerd client connection works", "\u001b[0;32m[INFO]\u001b[0m ✓ crictl can connect to runtime", "\u001b[0;32m[INFO]\u001b[0m Checking Kubernetes packages...", "\u001b[0;32m[INFO]\u001b[0m ✓ kubelet installed: Kubernetes v1.29.15", "\u001b[0;32m[INFO]\u001b[0m ✓ kubeadm installed: ", "\u001b[0;32m[INFO]\u001b[0m ✓ kubectl installed: ", "\u001b[0;32m[INFO]\u001b[0m ✓ kubelet service unit exists", "\u001b[0;32m[INFO]\u001b[0m Checking network configuration...", "\u001b[0;32m[INFO]\u001b[0m ✓ br_netfilter module loaded", "\u001b[0;32m[INFO]\u001b[0m ✓ overlay module loaded", "\u001b[0;32m[INFO]\u001b[0m ✓ net.bridge.bridge-nf-call-iptables = 1", "\u001b[0;32m[INFO]\u001b[0m ✓ net.bridge.bridge-nf-call-ip6tables = 1", "\u001b[0;32m[INFO]\u001b[0m ✓ net.ipv4.ip_forward = 1", "\u001b[0;32m[INFO]\u001b[0m Checking existing Kubernetes configuration...", "\u001b[0;32m[INFO]\u001b[0m ✓ No existing kubelet.conf (clean state)", "\u001b[0;32m[INFO]\u001b[0m Checking system resources...", "\u001b[0;32m[INFO]\u001b[0m ✓ CPU cores: 8", "\u001b[0;32m[INFO]\u001b[0m ✓ System load: 0.34", "", "=== Validation Summary ===", "\u001b[0;32m[INFO]\u001b[0m ✅ All prerequisites validated successfully!", "\u001b[0;32m[INFO]\u001b[0m System is ready for kubeadm join", "", "\u001b[0;32m[INFO]\u001b[0m Recommended next steps:", "\u001b[0;32m[INFO]\u001b[0m 1. Ensure master node has a valid join token", "\u001b[0;32m[INFO]\u001b[0m 2. Run kubeadm join with appropriate parameters", "\u001b[0;32m[INFO]\u001b[0m 3. Monitor kubelet logs during join process", "\u001b[0;32m[INFO]\u001b[0m ✅ All prerequisites validated successfully", "\u001b[0;32m[INFO]\u001b[0m === Join Attempt 1/2 ===", "\u001b[0;32m[INFO]\u001b[0m Preparing system for join...", "\u001b[0;32m[INFO]\u001b[0m Stopping kubelet service...", "\u001b[0;32m[INFO]\u001b[0m Cleaning existing kubelet state...", "\u001b[0;32m[INFO]\u001b[0m Restarting containerd...", "\u001b[0;32m[INFO]\u001b[0m ✓ System prepared for join", "\u001b[0;32m[INFO]\u001b[0m Performing kubeadm join (attempt 1)...", "Join command: kubeadm join 192.168.4.63:6443 --token lcdkmw.h6nbbtuxap5mz3pf --discovery-token-ca-cert-hash sha256:95d2831b85d03685274b19af0ba0ac7495a8410bace8263f6a7628fd1e129473 ", "\u001b[0;32m[INFO]\u001b[0m Monitoring kubelet join process (timeout: 300s)...", "Enhanced command: timeout 360 kubeadm join 192.168.4.63:6443 --token lcdkmw.h6nbbtuxap5mz3pf --discovery-token-ca-cert-hash sha256:95d2831b85d03685274b19af0ba0ac7495a8410bace8263f6a7628fd1e129473  --v=5", "I0910 15:56:04.170764  389740 join.go:413] [preflight] found NodeName empty; using OS hostname as NodeName", "I0910 15:56:04.170989  389740 initconfiguration.go:122] detected and using CRI socket: unix:///var/run/containerd/containerd.sock", "[preflight] Running pre-flight checks", "I0910 15:56:04.171071  389740 preflight.go:93] [preflight] Running general checks", "I0910 15:56:04.171128  389740 checks.go:280] validating the existence of file /etc/kubernetes/kubelet.conf", "I0910 15:56:04.171142  389740 checks.go:280] validating the existence of file /etc/kubernetes/bootstrap-kubelet.conf", "I0910 15:56:04.171153  389740 checks.go:104] validating the container runtime", "I0910 15:56:04.196853  389740 checks.go:639] validating whether swap is enabled or not", "I0910 15:56:04.196933  389740 checks.go:370] validating the presence of executable crictl", "I0910 15:56:04.196974  389740 checks.go:370] validating the presence of executable conntrack", "I0910 15:56:04.197000  389740 checks.go:370] validating the presence of executable ip", "I0910 15:56:04.197023  389740 checks.go:370] validating the presence of executable iptables", "I0910 15:56:04.197047  389740 checks.go:370] validating the presence of executable mount", "I0910 15:56:04.197070  389740 checks.go:370] validating the presence of executable nsenter", "I0910 15:56:04.197093  389740 checks.go:370] validating the presence of executable ethtool", "I0910 15:56:04.197114  389740 checks.go:370] validating the presence of executable tc", "I0910 15:56:04.197133  389740 checks.go:370] validating the presence of executable touch", "I0910 15:56:04.197157  389740 checks.go:516] running all checks", "I0910 15:56:04.210219  389740 checks.go:401] checking whether the given node name is valid and reachable using net.LookupHost", "I0910 15:56:04.210511  389740 checks.go:605] validating kubelet version", "I0910 15:56:04.265495  389740 checks.go:130] validating if the \"kubelet\" service is enabled and active", "I0910 15:56:04.299706  389740 checks.go:203] validating availability of port 10250", "I0910 15:56:04.299967  389740 checks.go:280] validating the existence of file /etc/kubernetes/pki/ca.crt", "I0910 15:56:04.299985  389740 checks.go:430] validating if the connectivity type is via proxy or direct", "I0910 15:56:04.300029  389740 checks.go:329] validating the contents of file /proc/sys/net/bridge/bridge-nf-call-iptables", "I0910 15:56:04.300082  389740 checks.go:329] validating the contents of file /proc/sys/net/ipv4/ip_forward", "I0910 15:56:04.300138  389740 join.go:532] [preflight] Discovering cluster-info", "I0910 15:56:04.300167  389740 token.go:80] [discovery] Created cluster-info discovery client, requesting info from \"192.168.4.63:6443\"", "I0910 15:56:04.325851  389740 token.go:118] [discovery] Requesting info from \"192.168.4.63:6443\" again to validate TLS against the pinned public key", "I0910 15:56:04.343620  389740 token.go:135] [discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server \"192.168.4.63:6443\"", "I0910 15:56:04.343643  389740 discovery.go:52] [discovery] Using provided TLSBootstrapToken as authentication credentials for the join process", "I0910 15:56:04.343659  389740 join.go:546] [preflight] Fetching init configuration", "I0910 15:56:04.343668  389740 join.go:592] [preflight] Retrieving KubeConfig objects", "[preflight] Reading configuration from the cluster...", "[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'", "I0910 15:56:04.363777  389740 kubeproxy.go:55] attempting to download the KubeProxyConfiguration from ConfigMap \"kube-proxy\"", "I0910 15:56:04.371094  389740 kubelet.go:74] attempting to download the KubeletConfiguration from ConfigMap \"kubelet-config\"", "I0910 15:56:04.387977  389740 initconfiguration.go:114] skip CRI socket detection, fill with the default CRI socket unix:///var/run/containerd/containerd.sock", "I0910 15:56:04.388214  389740 interface.go:432] Looking for default routes with IPv4 addresses", "I0910 15:56:04.388233  389740 interface.go:437] Default route transits interface \"enp5s0\"", "I0910 15:56:04.388359  389740 interface.go:209] Interface enp5s0 is up", "I0910 15:56:04.388451  389740 interface.go:257] Interface \"enp5s0\" has 3 addresses :[192.168.4.61/24 fd91:176e:252c:1:baac:6fff:fe7e:6c9d/64 fe80::baac:6fff:fe7e:6c9d/64].", "I0910 15:56:04.388479  389740 interface.go:224] Checking addr  192.168.4.61/24.", "I0910 15:56:04.388497  389740 interface.go:231] IP found 192.168.4.61", "I0910 15:56:04.388516  389740 interface.go:263] Found valid IPv4 address 192.168.4.61 for interface \"enp5s0\".", "I0910 15:56:04.388534  389740 interface.go:443] Found active IP 192.168.4.61 ", "I0910 15:56:04.399904  389740 preflight.go:104] [preflight] Running configuration dependant checks", "I0910 15:56:04.399934  389740 controlplaneprepare.go:225] [download-certs] Skipping certs download", "I0910 15:56:04.399973  389740 kubelet.go:121] [kubelet-start] writing bootstrap kubelet config file at /etc/kubernetes/bootstrap-kubelet.conf", "I0910 15:56:04.401370  389740 kubelet.go:136] [kubelet-start] writing CA certificate at /etc/kubernetes/pki/ca.crt", "I0910 15:56:04.402439  389740 kubelet.go:157] [kubelet-start] Checking for an existing Node in the cluster with name \"storagenodet3500\" and status \"Ready\"", "I0910 15:56:04.407024  389740 kubelet.go:172] [kubelet-start] Stopping the kubelet", "[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"", "[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"", "[kubelet-start] Starting the kubelet", "[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...", "[kubelet-check] Initial timeout of 40s passed.", "", "Unfortunately, an error has occurred:", "\ttimed out waiting for the condition", "", "This error is likely caused by:", "\t- The kubelet is not running", "\t- The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled)", "", "If you are on a systemd-powered system, you can try to troubleshoot the error with the following commands:", "\t- 'systemctl status kubelet'", "\t- 'journalctl -xeu kubelet'", "timed out waiting for the condition", "error execution phase kubelet-start", "k8s.io/kubernetes/cmd/kubeadm/app/cmd/phases/workflow.(*Runner).Run.func1", "\tk8s.io/kubernetes/cmd/kubeadm/app/cmd/phases/workflow/runner.go:260", "k8s.io/kubernetes/cmd/kubeadm/app/cmd/phases/workflow.(*Runner).visitAll", "\tk8s.io/kubernetes/cmd/kubeadm/app/cmd/phases/workflow/runner.go:446", "k8s.io/kubernetes/cmd/kubeadm/app/cmd/phases/workflow.(*Runner).Run", "\tk8s.io/kubernetes/cmd/kubeadm/app/cmd/phases/workflow/runner.go:232", "k8s.io/kubernetes/cmd/kubeadm/app/cmd.newCmdJoin.func1", "\tk8s.io/kubernetes/cmd/kubeadm/app/cmd/join.go:180", "github.com/spf13/cobra.(*Command).execute", "\tgithub.com/spf13/cobra@v1.7.0/command.go:940", "github.com/spf13/cobra.(*Command).ExecuteC", "\tgithub.com/spf13/cobra@v1.7.0/command.go:1068", "github.com/spf13/cobra.(*Command).Execute", "\tgithub.com/spf13/cobra@v1.7.0/command.go:992", "k8s.io/kubernetes/cmd/kubeadm/app.Run", "\tk8s.io/kubernetes/cmd/kubeadm/app/kubeadm.go:50", "main.main", "\tk8s.io/kubernetes/cmd/kubeadm/kubeadm.go:25", "runtime.main", "\truntime/proc.go:272", "runtime.goexit", "\truntime/asm_amd64.s:1700", "\u001b[0;31m[ERROR]\u001b[0m Kubelet join monitoring timed out after 300s", "\u001b[1;33m[WARN]\u001b[0m kubeadm join command succeeded but kubelet monitoring failed", "\u001b[1;33m[WARN]\u001b[0m Join attempt 1 failed", "\u001b[1;33m[WARN]\u001b[0m Cleaning up for retry...", "\u001b[0;32m[INFO]\u001b[0m Cleaning up after failed join...", "[preflight] Running pre-flight checks", "[reset] Deleted contents of the etcd data directory: /var/lib/etcd", "[reset] Stopping the kubelet service", "[reset] Unmounting mounted directories in \"/var/lib/kubelet\"", "[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]", "[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/super-admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]", "", "The reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d", "", "The reset process does not reset or clean up iptables rules or IPVS tables.", "If you wish to reset iptables, you must do so manually by using the \"iptables\" command.", "", "If your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)", "to reset your system's IPVS tables.", "", "The reset process does not clean your kubeconfig files and you must remove them manually.", "Please, check the contents of the $HOME/.kube/config file.", "\u001b[0;32m[INFO]\u001b[0m ✓ Cleanup completed", "\u001b[0;32m[INFO]\u001b[0m Waiting 30s before retry...", "\u001b[0;32m[INFO]\u001b[0m === Join Attempt 2/2 ===", "\u001b[0;32m[INFO]\u001b[0m Preparing system for join...", "\u001b[0;32m[INFO]\u001b[0m Stopping kubelet service...", "\u001b[0;32m[INFO]\u001b[0m Cleaning existing kubelet state...", "\u001b[0;32m[INFO]\u001b[0m Restarting containerd...", "\u001b[0;32m[INFO]\u001b[0m ✓ System prepared for join", "\u001b[0;32m[INFO]\u001b[0m Performing kubeadm join (attempt 2)...", "Join command: kubeadm join 192.168.4.63:6443 --token lcdkmw.h6nbbtuxap5mz3pf --discovery-token-ca-cert-hash sha256:95d2831b85d03685274b19af0ba0ac7495a8410bace8263f6a7628fd1e129473 ", "\u001b[0;32m[INFO]\u001b[0m Monitoring kubelet join process (timeout: 300s)...", "Enhanced command: timeout 360 kubeadm join 192.168.4.63:6443 --token lcdkmw.h6nbbtuxap5mz3pf --discovery-token-ca-cert-hash sha256:95d2831b85d03685274b19af0ba0ac7495a8410bace8263f6a7628fd1e129473  --v=5", "I0910 16:02:02.000164  390416 join.go:413] [preflight] found NodeName empty; using OS hostname as NodeName", "I0910 16:02:02.000404  390416 initconfiguration.go:122] detected and using CRI socket: unix:///var/run/containerd/containerd.sock", "[preflight] Running pre-flight checks", "I0910 16:02:02.000494  390416 preflight.go:93] [preflight] Running general checks", "I0910 16:02:02.000551  390416 checks.go:280] validating the existence of file /etc/kubernetes/kubelet.conf", "I0910 16:02:02.000566  390416 checks.go:280] validating the existence of file /etc/kubernetes/bootstrap-kubelet.conf", "I0910 16:02:02.000577  390416 checks.go:104] validating the container runtime", "I0910 16:02:02.027895  390416 checks.go:639] validating whether swap is enabled or not", "I0910 16:02:02.027991  390416 checks.go:370] validating the presence of executable crictl", "I0910 16:02:02.028030  390416 checks.go:370] validating the presence of executable conntrack", "I0910 16:02:02.028065  390416 checks.go:370] validating the presence of executable ip", "I0910 16:02:02.028089  390416 checks.go:370] validating the presence of executable iptables", "I0910 16:02:02.028114  390416 checks.go:370] validating the presence of executable mount", "I0910 16:02:02.028140  390416 checks.go:370] validating the presence of executable nsenter", "I0910 16:02:02.028164  390416 checks.go:370] validating the presence of executable ethtool", "I0910 16:02:02.028185  390416 checks.go:370] validating the presence of executable tc", "I0910 16:02:02.028206  390416 checks.go:370] validating the presence of executable touch", "I0910 16:02:02.028230  390416 checks.go:516] running all checks", "I0910 16:02:02.041959  390416 checks.go:401] checking whether the given node name is valid and reachable using net.LookupHost", "I0910 16:02:02.042132  390416 checks.go:605] validating kubelet version", "I0910 16:02:02.099151  390416 checks.go:130] validating if the \"kubelet\" service is enabled and active", "I0910 16:02:02.132394  390416 checks.go:203] validating availability of port 10250", "I0910 16:02:02.132641  390416 checks.go:280] validating the existence of file /etc/kubernetes/pki/ca.crt", "I0910 16:02:02.132663  390416 checks.go:430] validating if the connectivity type is via proxy or direct", "I0910 16:02:02.132716  390416 checks.go:329] validating the contents of file /proc/sys/net/bridge/bridge-nf-call-iptables", "I0910 16:02:02.132797  390416 checks.go:329] validating the contents of file /proc/sys/net/ipv4/ip_forward", "I0910 16:02:02.132842  390416 join.go:532] [preflight] Discovering cluster-info", "I0910 16:02:02.132874  390416 token.go:80] [discovery] Created cluster-info discovery client, requesting info from \"192.168.4.63:6443\"", "I0910 16:02:02.148593  390416 token.go:118] [discovery] Requesting info from \"192.168.4.63:6443\" again to validate TLS against the pinned public key", "I0910 16:02:02.163858  390416 token.go:135] [discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server \"192.168.4.63:6443\"", "I0910 16:02:02.163879  390416 discovery.go:52] [discovery] Using provided TLSBootstrapToken as authentication credentials for the join process", "I0910 16:02:02.163893  390416 join.go:546] [preflight] Fetching init configuration", "I0910 16:02:02.163901  390416 join.go:592] [preflight] Retrieving KubeConfig objects", "[preflight] Reading configuration from the cluster...", "[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'", "I0910 16:02:02.183107  390416 kubeproxy.go:55] attempting to download the KubeProxyConfiguration from ConfigMap \"kube-proxy\"", "I0910 16:02:02.188384  390416 kubelet.go:74] attempting to download the KubeletConfiguration from ConfigMap \"kubelet-config\"", "I0910 16:02:02.193830  390416 initconfiguration.go:114] skip CRI socket detection, fill with the default CRI socket unix:///var/run/containerd/containerd.sock", "I0910 16:02:02.194015  390416 interface.go:432] Looking for default routes with IPv4 addresses", "I0910 16:02:02.194029  390416 interface.go:437] Default route transits interface \"enp5s0\"", "I0910 16:02:02.194133  390416 interface.go:209] Interface enp5s0 is up", "I0910 16:02:02.194200  390416 interface.go:257] Interface \"enp5s0\" has 3 addresses :[192.168.4.61/24 fd91:176e:252c:1:baac:6fff:fe7e:6c9d/64 fe80::baac:6fff:fe7e:6c9d/64].", "I0910 16:02:02.194222  390416 interface.go:224] Checking addr  192.168.4.61/24.", "I0910 16:02:02.194236  390416 interface.go:231] IP found 192.168.4.61", "I0910 16:02:02.194250  390416 interface.go:263] Found valid IPv4 address 192.168.4.61 for interface \"enp5s0\".", "I0910 16:02:02.194263  390416 interface.go:443] Found active IP 192.168.4.61 ", "I0910 16:02:02.205263  390416 preflight.go:104] [preflight] Running configuration dependant checks", "I0910 16:02:02.205287  390416 controlplaneprepare.go:225] [download-certs] Skipping certs download", "I0910 16:02:02.205316  390416 kubelet.go:121] [kubelet-start] writing bootstrap kubelet config file at /etc/kubernetes/bootstrap-kubelet.conf", "I0910 16:02:02.206437  390416 kubelet.go:136] [kubelet-start] writing CA certificate at /etc/kubernetes/pki/ca.crt", "I0910 16:02:02.207553  390416 kubelet.go:157] [kubelet-start] Checking for an existing Node in the cluster with name \"storagenodet3500\" and status \"Ready\"", "I0910 16:02:02.211811  390416 kubelet.go:172] [kubelet-start] Stopping the kubelet", "[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"", "[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"", "[kubelet-start] Starting the kubelet", "[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...", "[kubelet-check] Initial timeout of 40s passed.", "", "Unfortunately, an error has occurred:", "\ttimed out waiting for the condition", "", "This error is likely caused by:", "\t- The kubelet is not running", "\t- The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled)", "", "If you are on a systemd-powered system, you can try to troubleshoot the error with the following commands:", "\t- 'systemctl status kubelet'", "\t- 'journalctl -xeu kubelet'", "timed out waiting for the condition", "error execution phase kubelet-start", "k8s.io/kubernetes/cmd/kubeadm/app/cmd/phases/workflow.(*Runner).Run.func1", "\tk8s.io/kubernetes/cmd/kubeadm/app/cmd/phases/workflow/runner.go:260", "k8s.io/kubernetes/cmd/kubeadm/app/cmd/phases/workflow.(*Runner).visitAll", "\tk8s.io/kubernetes/cmd/kubeadm/app/cmd/phases/workflow/runner.go:446", "k8s.io/kubernetes/cmd/kubeadm/app/cmd/phases/workflow.(*Runner).Run", "\tk8s.io/kubernetes/cmd/kubeadm/app/cmd/phases/workflow/runner.go:232", "k8s.io/kubernetes/cmd/kubeadm/app/cmd.newCmdJoin.func1", "\tk8s.io/kubernetes/cmd/kubeadm/app/cmd/join.go:180", "github.com/spf13/cobra.(*Command).execute", "\tgithub.com/spf13/cobra@v1.7.0/command.go:940", "github.com/spf13/cobra.(*Command).ExecuteC", "\tgithub.com/spf13/cobra@v1.7.0/command.go:1068", "github.com/spf13/cobra.(*Command).Execute", "\tgithub.com/spf13/cobra@v1.7.0/command.go:992", "k8s.io/kubernetes/cmd/kubeadm/app.Run", "\tk8s.io/kubernetes/cmd/kubeadm/app/kubeadm.go:50", "main.main", "\tk8s.io/kubernetes/cmd/kubeadm/kubeadm.go:25", "runtime.main", "\truntime/proc.go:272", "runtime.goexit", "\truntime/asm_amd64.s:1700", "\u001b[0;31m[ERROR]\u001b[0m Kubelet join monitoring timed out after 300s", "\u001b[1;33m[WARN]\u001b[0m kubeadm join command succeeded but kubelet monitoring failed", "\u001b[1;33m[WARN]\u001b[0m Join attempt 2 failed", "\u001b[0;31m[ERROR]\u001b[0m ❌ All join attempts failed after 2 tries", "All join attempts failed at Wed Sep 10 16:07:03 EDT 2025", "", "\u001b[0;31m[ERROR]\u001b[0m Diagnostic information:", "\u001b[0;31m[ERROR]\u001b[0m 1. Check log file: /tmp/kubeadm-join-20250910-155546.log", "\u001b[0;31m[ERROR]\u001b[0m 2. Check kubelet status: systemctl status kubelet", "\u001b[0;31m[ERROR]\u001b[0m 3. Check kubelet logs: journalctl -u kubelet -f", "\u001b[0;31m[ERROR]\u001b[0m 4. Check containerd status: systemctl status containerd", "\u001b[0;31m[ERROR]\u001b[0m 5. Verify master node connectivity: curl -k https://192.168.4.63:6443/healthz"]}

