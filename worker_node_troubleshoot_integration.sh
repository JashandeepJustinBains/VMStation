#!/bin/bash

# Worker Node Troubleshooting Integration Script
# Provides unified troubleshooting workflow for worker node join issues
# Integrates diagnostic, remediation, and log collection

set -euo pipefail

# Color codes for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Logging functions
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

# Check if script exists and is executable
check_script() {
    local script_path="$1"
    local script_name="$2"
    
    if [ ! -f "$script_path" ]; then
        log_error "$script_name not found at: $script_path"
        return 1
    fi
    
    if [ ! -x "$script_path" ]; then
        log_warn "$script_name not executable, making it executable..."
        chmod +x "$script_path"
    fi
    
    return 0
}

# Main function
main() {
    echo "=== Worker Node Troubleshooting Integration ==="
    echo "Timestamp: $(date)"
    echo "Hostname: $(hostname)"
    echo "IP Address: $(hostname -I | awk '{print $1}')"
    echo ""
    
    # Define script paths
    DIAGNOSTICS_SCRIPT="./worker_node_join_diagnostics.sh"
    REMEDIATION_SCRIPT="./worker_node_join_remediation.sh"
    OUTPUT_FILE="worker_node_join_scripts_output.txt"
    
    log_info "Checking for required scripts..."
    
    # Check if scripts exist
    if ! check_script "$DIAGNOSTICS_SCRIPT" "Diagnostics script"; then
        log_error "Cannot proceed without diagnostics script"
        exit 1
    fi
    
    if ! check_script "$REMEDIATION_SCRIPT" "Remediation script"; then
        log_error "Cannot proceed without remediation script"
        exit 1
    fi
    
    log_success "Required scripts found and ready"
    echo ""
    
    # Create structured output file
    log_info "Creating structured troubleshooting output file: $OUTPUT_FILE"
    
    cat > "$OUTPUT_FILE" << EOF
=== Worker Node Join Troubleshooting Session ===
Start Time: $(date)
Hostname: $(hostname)
IP Address: $(hostname -I | awk '{print $1}')
User: $(whoami)

This file contains the complete troubleshooting session for worker node join issues.
Generated by: worker_node_troubleshoot_integration.sh

=== SECTION 1: DIAGNOSTIC PHASE ===
Running worker_node_join_diagnostics.sh to identify issues...

EOF
    
    # Run diagnostics and capture output
    log_info "Running worker node diagnostics..."
    if "$DIAGNOSTICS_SCRIPT" >> "$OUTPUT_FILE" 2>&1; then
        log_success "Diagnostics completed successfully"
    else
        log_warn "Diagnostics completed with warnings"
    fi
    
    # Add separator and remediation section
    cat >> "$OUTPUT_FILE" << EOF

=== SECTION 2: REMEDIATION PHASE ===
Running worker_node_join_remediation.sh to fix identified issues...

EOF
    
    # Ask user if they want to run remediation
    echo ""
    log_warn "Remediation script will make changes to the system."
    log_warn "Please review the diagnostic output above before proceeding."
    echo ""
    read -p "Do you want to run the remediation script? (y/N): " -n 1 -r
    echo
    
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        log_info "Running worker node remediation..."
        if "$REMEDIATION_SCRIPT" >> "$OUTPUT_FILE" 2>&1; then
            log_success "Remediation completed successfully"
        else
            log_error "Remediation failed or completed with errors"
        fi
    else
        echo "User chose not to run remediation." >> "$OUTPUT_FILE"
        log_info "Remediation skipped by user choice"
    fi
    
    # Add post-remediation logs section
    cat >> "$OUTPUT_FILE" << EOF

=== SECTION 3: POST-REMEDIATION LOGS ===
Collecting system logs after troubleshooting...

--- Current kubelet status ---
EOF
    
    # Collect current system status
    log_info "Collecting post-troubleshooting system status..."
    
    echo "Kubelet service status:" >> "$OUTPUT_FILE"
    systemctl status kubelet --no-pager -l 2>/dev/null >> "$OUTPUT_FILE" || echo "Could not get kubelet status" >> "$OUTPUT_FILE"
    echo "" >> "$OUTPUT_FILE"
    
    echo "Containerd service status:" >> "$OUTPUT_FILE"
    systemctl status containerd --no-pager -l 2>/dev/null >> "$OUTPUT_FILE" || echo "Could not get containerd status" >> "$OUTPUT_FILE"
    echo "" >> "$OUTPUT_FILE"
    
    echo "Recent kubelet logs (last 20 lines):" >> "$OUTPUT_FILE"
    journalctl -u kubelet --no-pager -l --since='10 minutes ago' 2>/dev/null | tail -20 >> "$OUTPUT_FILE" || echo "Could not retrieve kubelet logs" >> "$OUTPUT_FILE"
    echo "" >> "$OUTPUT_FILE"
    
    echo "Recent containerd logs (last 20 lines):" >> "$OUTPUT_FILE"
    journalctl -u containerd --no-pager -l --since='10 minutes ago' 2>/dev/null | tail -20 >> "$OUTPUT_FILE" || echo "Could not retrieve containerd logs" >> "$OUTPUT_FILE"
    echo "" >> "$OUTPUT_FILE"
    
    # Add completion timestamp
    cat >> "$OUTPUT_FILE" << EOF

=== TROUBLESHOOTING SESSION COMPLETE ===
End Time: $(date)
Output file: $OUTPUT_FILE

Next Steps:
1. Review the diagnostic output in Section 1 to understand the identified issues
2. Check the remediation results in Section 2 
3. Verify system status in Section 3
4. If issues persist, run: kubectl get nodes -o wide (from control plane)
5. For cluster deployment logs, check deployment_logs_*.txt files

EOF
    
    echo ""
    log_success "Troubleshooting integration completed!"
    log_info "Complete output saved to: $OUTPUT_FILE"
    echo ""
    log_info "Summary of collected information:"
    log_info "  - Diagnostic scan results"
    log_info "  - Remediation actions taken (if approved)"
    log_info "  - Current system service status"
    log_info "  - Recent kubelet and containerd logs"
    echo ""
    log_info "To review the full troubleshooting session:"
    log_info "  cat $OUTPUT_FILE"
}

# Run main function
main "$@"