Even after these changes 
Problem
The Kubernetes deployment playbook was failing at Phase 2: Control Plane Validation with kubectl prompting for username/password authentication instead of using the admin certificate:

TASK [Verify control plane is responding] **************************************
FAILED - RETRYING: [masternode]: Verify control plane is responding (10 retries left).
...
fatal: [masternode]: FAILED! => changed=true
  attempts: 10
  cmd: kubectl cluster-info
  rc: 1
  stderr: 'error: EOF'
  stdout: 'Please enter Username: '
Root Cause
The playbook was relying on Ansible's environment: parameter to set the KUBECONFIG environment variable for kubectl commands:

- name: "Verify control plane is responding"
  shell: kubectl cluster-info
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
When using the shell: module with environment:, environment variables don't always propagate correctly to the spawned shell process, especially when using ansible_connection: local or in certain shell configurations. This caused kubectl to fall back to interactive authentication, prompting for a username.

Solution
Replace all kubectl commands to use the --kubeconfig flag explicitly instead of relying on environment variable propagation:

- name: "Verify control plane is responding"
  shell: kubectl --kubeconfig=/etc/kubernetes/admin.conf cluster-info
This ensures kubectl always uses the correct kubeconfig file regardless of environment variable behavior.

Changes
Updated 14 kubectl commands across 4 deployment phases in ansible/playbooks/deploy-cluster.yaml:

Phase 2 (Control Plane Validation): 1 command
Phase 4 (CNI Deployment): 3 commands
Phase 6 (Cluster Validation): 3 commands
Phase 7 (Application Deployment): 7 commands
Also removed unnecessary KUBECONFIG environment variable from Phase 3's kubeadm command (kubeadm reads /etc/kubernetes/admin.conf by default).

Net impact: -28 lines (removed 41 lines of environment: blocks, added 13 lines with --kubeconfig flags)

and 
Problem
The Kubernetes deployment was failing at Phase 2 with an authentication error when validating the control plane:

TASK [Verify control plane is responding] **************************************
fatal: [masternode]: FAILED!
  cmd: kubectl cluster-info
  stderr: 'error: EOF'
  stdout: 'Please enter Username: '
This occurred because kubectl cluster-info was prompting for credentials instead of using the admin certificate automatically.

Root Cause
Phase 1 (Control Plane Initialization) contained duplicate and complex logic that created a custom kubectl context requiring manual authentication. Specifically:

Lines 209-229: First set of duplicate tasks creating custom admin credentials and context
Lines 238-250: Second set of duplicate tasks doing the same thing
Phase 2 was using KUBECONFIG: /root/.kube/config which referenced this broken custom context
The custom context setup was attempting to manually configure credentials with kubectl config set-credentials and kubectl config set-context, but this created an authentication context that required interactive login instead of using the admin certificate embedded in /etc/kubernetes/admin.conf.

Solution
Phase 1 - Simplified kubeconfig setup (removed 43 lines):

Removed duplicate Copy admin.conf tasks with conditional logic
Removed both Set admin context and credentials tasks that created the problematic custom context
Kept simple, unconditional copy of admin.conf to /root/.kube/config for convenience
Retained KUBECONFIG environment variable setup pointing to /etc/kubernetes/admin.conf
Phase 2 - Fixed KUBECONFIG path:

Changed KUBECONFIG: /root/.kube/config to KUBECONFIG: /etc/kubernetes/admin.conf
Result
✅ kubectl now uses the admin certificate directly via /etc/kubernetes/admin.conf
✅ No custom authentication context is created that requires manual login
✅ Phase 2 validation will work without prompting for username/password
✅ Reduced playbook from 579 lines to 535 lines (44 lines removed)
✅ All syntax validation tests pass

This fix aligns with the documented behavior in PLAYBOOK_SIMPLIFICATION_SUMMARY.md and DEPLOYMENT_FIX_COMPLETE.md, where kubectl should work automatically without login by using /etc/kubernetes/admin.conf via the KUBECONFIG environment variable.

It sdoes not work 
LAY [Phase 0: System Preparation - Install Kubernetes Binaries] ***************

TASK [Gathering Facts] *********************************************************
ok: [masternode]
ok: [storagenodet3500]

TASK [Display Phase 0 banner] **************************************************
ok: [masternode] =>
  msg: |-
    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
    Phase 0: System Preparation
    Target: masternode
    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
ok: [storagenodet3500] =>
  msg: |-
    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
    Phase 0: System Preparation
    Target: storagenodet3500
    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

TASK [Disable swap] ************************************************************
ok: [masternode]
ok: [storagenodet3500]

TASK [Remove swap from fstab] **************************************************
ok: [masternode]
ok: [storagenodet3500]

TASK [Load kernel modules for containerd] **************************************
ok: [masternode] => (item=overlay)
ok: [storagenodet3500] => (item=overlay)
ok: [masternode] => (item=br_netfilter)
ok: [storagenodet3500] => (item=br_netfilter)

TASK [Ensure modules load on boot] *********************************************
ok: [masternode]
ok: [storagenodet3500]

TASK [Configure sysctl for Kubernetes] *****************************************
ok: [masternode] => (item={'name': 'net.bridge.bridge-nf-call-iptables', 'value': '1'})
ok: [storagenodet3500] => (item={'name': 'net.bridge.bridge-nf-call-iptables', 'value': '1'})
ok: [masternode] => (item={'name': 'net.bridge.bridge-nf-call-ip6tables', 'value': '1'})
ok: [storagenodet3500] => (item={'name': 'net.bridge.bridge-nf-call-ip6tables', 'value': '1'})
ok: [masternode] => (item={'name': 'net.ipv4.ip_forward', 'value': '1'})
ok: [storagenodet3500] => (item={'name': 'net.ipv4.ip_forward', 'value': '1'})

TASK [Check if containerd is installed] ****************************************
ok: [masternode]
ok: [storagenodet3500]

TASK [Install containerd (try containerd.io first)] ****************************
skipping: [masternode]
skipping: [storagenodet3500]

TASK [Install containerd (fallback to containerd package)] *********************
skipping: [masternode]
skipping: [storagenodet3500]

TASK [Create containerd config directory] **************************************
ok: [masternode]
ok: [storagenodet3500]

TASK [Generate containerd default config] **************************************
ok: [masternode]
ok: [storagenodet3500]

TASK [Enable SystemdCgroup in containerd] **************************************
ok: [masternode]
ok: [storagenodet3500]

TASK [Restart containerd] ******************************************************
changed: [masternode]
changed: [storagenodet3500]

TASK [Configure crictl runtime endpoint] ***************************************
ok: [masternode]
ok: [storagenodet3500]

TASK [Add Kubernetes apt key] **************************************************
ok: [masternode]
ok: [storagenodet3500]

TASK [Add Kubernetes apt repository] *******************************************
ok: [masternode]
ok: [storagenodet3500]

TASK [Install Kubernetes binaries] *********************************************
ok: [masternode]
ok: [storagenodet3500]

TASK [Hold Kubernetes packages at current version] *****************************
ok: [masternode] => (item=kubelet)
ok: [storagenodet3500] => (item=kubelet)
ok: [masternode] => (item=kubeadm)
ok: [storagenodet3500] => (item=kubeadm)
ok: [masternode] => (item=kubectl)
ok: [storagenodet3500] => (item=kubectl)

TASK [Enable kubelet service] **************************************************
ok: [masternode]
ok: [storagenodet3500]

TASK [Create required Kubernetes directories] **********************************
ok: [masternode] => (item=/opt/cni/bin)
ok: [storagenodet3500] => (item=/opt/cni/bin)
ok: [masternode] => (item=/etc/cni/net.d)
ok: [storagenodet3500] => (item=/etc/cni/net.d)
ok: [masternode] => (item=/var/lib/kubelet)
ok: [storagenodet3500] => (item=/var/lib/kubelet)

PLAY [Phase 1: Control Plane Initialization] ***********************************

TASK [Display Phase 1 banner] **************************************************
ok: [masternode] =>
  msg: |-
    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
    Phase 1: Control Plane Initialization
    Target: masternode
    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

TASK [Check if cluster is already initialized] *********************************
ok: [masternode]

TASK [Initialize control plane (if not exists)] ********************************
skipping: [masternode]

TASK [Create .kube directory for root] *****************************************
ok: [masternode]

TASK [Copy admin.conf to /root/.kube/config] ***********************************
ok: [masternode]

TASK [Set KUBECONFIG environment variable globally] ****************************
ok: [masternode]

TASK [Add KUBECONFIG to root's bash profile] ***********************************
ok: [masternode]

PLAY [Phase 2: Control Plane Validation] ***************************************

TASK [Display Phase 2 banner] **************************************************
ok: [masternode] =>
  msg: |-
    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
    Phase 2: Control Plane Validation
    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

TASK [Wait for API server to be ready] *****************************************
ok: [masternode]

TASK [Verify control plane is responding] **************************************
FAILED - RETRYING: [masternode]: Verify control plane is responding (10 retries left).
FAILED - RETRYING: [masternode]: Verify control plane is responding (9 retries left).
FAILED - RETRYING: [masternode]: Verify control plane is responding (8 retries left).
FAILED - RETRYING: [masternode]: Verify control plane is responding (7 retries left).
FAILED - RETRYING: [masternode]: Verify control plane is responding (6 retries left).
FAILED - RETRYING: [masternode]: Verify control plane is responding (5 retries left).
FAILED - RETRYING: [masternode]: Verify control plane is responding (4 retries left).
FAILED - RETRYING: [masternode]: Verify control plane is responding (3 retries left).
FAILED - RETRYING: [masternode]: Verify control plane is responding (2 retries left).
FAILED - RETRYING: [masternode]: Verify control plane is responding (1 retries left).
fatal: [masternode]: FAILED! => changed=true
  attempts: 10
  cmd: kubectl --kubeconfig=/etc/kubernetes/admin.conf cluster-info
  delta: '0:00:00.049543'
  end: '2025-10-07 10:23:21.954128'
  msg: non-zero return code
  rc: 1
  start: '2025-10-07 10:23:21.904585'
  stderr: 'error: EOF'
  stderr_lines: <omitted>
  stdout: 'Please enter Username: '
  stdout_lines: <omitted>

PLAY RECAP *********************************************************************
masternode                 : ok=27   changed=1    unreachable=0    failed=1    skipped=3    rescued=0    ignored=0
storagenodet3500           : ok=19   changed=1    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0


