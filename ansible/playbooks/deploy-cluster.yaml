---
# =============================================================================
# VMStation Kubernetes Cluster - Deploy Playbook
# Idempotent deployment for mixed OS cluster (Debian + RHEL 10)
# =============================================================================

# -----------------------------------------------------------------------------
# PHASE 1: System Preparation
# -----------------------------------------------------------------------------
- name: Phase 1 - System preparation
  hosts: all
  become: true
  gather_facts: true
  tasks:
    - name: Ensure /etc/hosts has cluster nodes
      ansible.builtin.blockinfile:
        path: /etc/hosts
        block: |
          192.168.4.63 masternode
          192.168.4.61 storagenodet3500
          192.168.4.62 homelab
        marker: "# {mark} VMStation Cluster"
        create: yes

  roles:
    - preflight
    - network-fix

# -----------------------------------------------------------------------------
# PHASE 2: CNI Plugins Installation
# -----------------------------------------------------------------------------
- name: Phase 2 - Install CNI plugins
  hosts: all
  become: true
  tasks:
    - name: Ensure /opt/cni/bin directory exists
      ansible.builtin.file:
        path: /opt/cni/bin
        state: directory
        mode: '0755'

    - name: Check if CNI plugins installed
      ansible.builtin.stat:
        path: /opt/cni/bin/loopback
      register: cni_installed

    - name: Set CNI architecture fact
      ansible.builtin.set_fact:
        cni_arch: "{{ 'amd64' if ansible_architecture == 'x86_64' else ('arm64' if ansible_architecture == 'aarch64' else ansible_architecture) }}"
      when: not cni_installed.stat.exists

    - name: Download CNI plugins (primary attempt)
      ansible.builtin.get_url:
        url: "https://github.com/containernetworking/plugins/releases/download/v1.8.0/cni-plugins-linux-{{ cni_arch }}-v1.8.0.tgz"
        dest: /tmp/cni-plugins.tgz
        mode: '0644'
        timeout: 60
        validate_certs: false
      when: not cni_installed.stat.exists
      register: cni_download
      ignore_errors: true

    - name: Download CNI plugins (curl fallback)
      ansible.builtin.shell: |
        curl -fsSL -o /tmp/cni-plugins.tgz \
          "https://github.com/containernetworking/plugins/releases/download/v1.8.0/cni-plugins-linux-{{ cni_arch }}-v1.8.0.tgz"
      args:
        creates: /tmp/cni-plugins.tgz
      when: 
        - not cni_installed.stat.exists
        - cni_download is failed or 'cert_file' in (cni_download.msg | default('')) or 'urllib3' in (cni_download.msg | default(''))

    - name: Verify CNI archive downloaded
      ansible.builtin.stat:
        path: /tmp/cni-plugins.tgz
      register: cni_archive
      when: not cni_installed.stat.exists

    - name: Fail if CNI download failed
      ansible.builtin.fail:
        msg: "Failed to download CNI plugins. Check network connectivity and GitHub availability."
      when: 
        - not cni_installed.stat.exists
        - not cni_archive.stat.exists

    - name: Extract CNI plugins
      ansible.builtin.unarchive:
        src: /tmp/cni-plugins.tgz
        dest: /opt/cni/bin/
        remote_src: yes
      when: not cni_installed.stat.exists

    - name: Clean up CNI archive
      ansible.builtin.file:
        path: /tmp/cni-plugins.tgz
        state: absent
      when: not cni_installed.stat.exists

# -----------------------------------------------------------------------------
# PHASE 3: Control Plane Initialization
# -----------------------------------------------------------------------------
- name: Phase 3 - Initialize control plane
  hosts: monitoring_nodes
  become: true
  tasks:
    - name: Check if control plane initialized
      ansible.builtin.stat:
        path: /etc/kubernetes/admin.conf
      register: admin_conf

    - name: Initialize control plane
      ansible.builtin.shell: |
        kubeadm init \
          --pod-network-cidr=10.244.0.0/16 \
          --service-cidr=10.96.0.0/12 \
          --upload-certs
      when: not admin_conf.stat.exists

    - name: Set KUBECONFIG
      ansible.builtin.lineinfile:
        path: /root/.bashrc
        line: 'export KUBECONFIG=/etc/kubernetes/admin.conf'
        create: yes

    - name: Wait for API server
      ansible.builtin.wait_for:
        host: 127.0.0.1
        port: 6443
        timeout: 60

# -----------------------------------------------------------------------------
# PHASE 4: Worker Node Join
# -----------------------------------------------------------------------------
- name: Phase 4 - Join worker nodes
  hosts: storage_nodes:compute_nodes
  become: true
  tasks:
    - name: Check if node already joined
      ansible.builtin.stat:
        path: /etc/kubernetes/kubelet.conf
      register: kubelet_conf

    - name: Generate join command
      ansible.builtin.shell: kubeadm token create --print-join-command
      delegate_to: "{{ groups['monitoring_nodes'][0] }}"
      register: join_command
      when: not kubelet_conf.stat.exists
      run_once: true

    - name: Join worker to cluster
      ansible.builtin.shell: "{{ join_command.stdout }}"
      when: not kubelet_conf.stat.exists

# -----------------------------------------------------------------------------
# PHASE 5: Flannel CNI Deployment
# -----------------------------------------------------------------------------
- name: Phase 5 - Deploy Flannel CNI
  hosts: monitoring_nodes
  become: true
  tasks:
    - name: Apply Flannel manifest
      ansible.builtin.shell: |
        kubectl --kubeconfig=/etc/kubernetes/admin.conf apply -f {{ playbook_dir }}/../../manifests/cni/flannel.yaml
      register: flannel_apply
      changed_when: "'created' in flannel_apply.stdout or 'configured' in flannel_apply.stdout"

    - name: Wait for Flannel DaemonSet rollout
      ansible.builtin.shell: |
        kubectl --kubeconfig=/etc/kubernetes/admin.conf -n kube-flannel rollout status daemonset/kube-flannel-ds --timeout=180s
      retries: 2
      delay: 5
      register: flannel_rollout
      until: flannel_rollout.rc == 0

    - name: Verify CNI config exists on all nodes via SSH
      ansible.builtin.stat:
        path: /etc/cni/net.d/10-flannel.conflist
      delegate_to: "{{ item }}"
      loop:
        - masternode
        - storagenodet3500
        - homelab
      register: cni_file_check
      failed_when: not cni_file_check.stat.exists

    - name: Wait for all nodes Ready
      ansible.builtin.shell: |
        total=$(kubectl --kubeconfig=/etc/kubernetes/admin.conf get nodes --no-headers | wc -l)
        ready=$(kubectl --kubeconfig=/etc/kubernetes/admin.conf get nodes --no-headers | grep ' Ready ' | wc -l)
        test $ready -eq $total
      retries: 30
      delay: 5
      register: nodes_ready
      until: nodes_ready.rc == 0

    - name: Uncordon all nodes
      ansible.builtin.shell: |
        kubectl --kubeconfig=/etc/kubernetes/admin.conf uncordon --all
      changed_when: false
      ignore_errors: true

    - name: Remove control-plane taint
      ansible.builtin.shell: |
        kubectl --kubeconfig=/etc/kubernetes/admin.conf taint nodes --all node-role.kubernetes.io/control-plane:NoSchedule- || true
      changed_when: false

# -----------------------------------------------------------------------------
# PHASE 6: Validation
# -----------------------------------------------------------------------------
- name: Phase 6 - Validate deployment
  hosts: monitoring_nodes
  become: true
  tasks:
    - name: Check for CrashLoopBackOff pods
      ansible.builtin.shell: |
        kubectl --kubeconfig=/etc/kubernetes/admin.conf get pods -A | grep -i crash || echo "No CrashLoopBackOff pods"
      register: crash_check
      changed_when: false
      failed_when: "'CrashLoop' in crash_check.stdout"

    - name: Display cluster status
      ansible.builtin.shell: |
        echo "=== Nodes ==="
        kubectl --kubeconfig=/etc/kubernetes/admin.conf get nodes -o wide
        echo ""
        echo "=== kube-system pods ==="
        kubectl --kubeconfig=/etc/kubernetes/admin.conf -n kube-system get pods -o wide
        echo ""
        echo "=== Flannel pods ==="
        kubectl --kubeconfig=/etc/kubernetes/admin.conf -n kube-flannel get pods -o wide
      register: cluster_status
      changed_when: false

    - name: Show cluster status
      ansible.builtin.debug:
        var: cluster_status.stdout_lines

# -----------------------------------------------------------------------------
# PHASE 7: Application Deployment
# -----------------------------------------------------------------------------
- import_playbook: ../plays/deploy-apps.yaml
- import_playbook: ../plays/jellyfin.yml
