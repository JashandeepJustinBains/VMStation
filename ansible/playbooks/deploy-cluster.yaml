---
# =============================================================================
# VMStation Kubernetes Cluster - Deploy Playbook
# Idempotent deployment for mixed OS cluster (Debian + RHEL 10)
# =============================================================================

# -----------------------------------------------------------------------------
# PHASE 1: System Preparation
# -----------------------------------------------------------------------------
- name: Phase 1 - System preparation
  hosts: all
  become: true
  gather_facts: true
  tasks:
    - name: Ensure /etc/hosts has cluster nodes
      ansible.builtin.blockinfile:
        path: /etc/hosts
        block: |
          192.168.4.63 masternode
          192.168.4.61 storagenodet3500
          192.168.4.62 homelab
        marker: "# {mark} VMStation Cluster"
        create: yes

  roles:
    - preflight
    - network-fix

# -----------------------------------------------------------------------------
# PHASE 2: CNI Plugins Installation
# -----------------------------------------------------------------------------
- name: Phase 2 - Install CNI plugins
  hosts: all
  become: true
  gather_facts: true
  tasks:
    - name: Detect architecture
      ansible.builtin.set_fact:
        cni_arch: "{{ 'amd64' if ansible_architecture == 'x86_64' else ansible_architecture }}"

    - name: Check if CNI plugins installed
      ansible.builtin.stat:
        path: /opt/cni/bin/bridge
      register: cni_installed

    - name: Download CNI plugins (get_url)
      ansible.builtin.get_url:
        url: "https://github.com/containernetworking/plugins/releases/download/v1.8.0/cni-plugins-linux-{{ cni_arch }}-v1.8.0.tgz"
        dest: /tmp/cni-plugins.tgz
        mode: '0644'
        validate_certs: false
      when: not cni_installed.stat.exists
      register: cni_download
      ignore_errors: true

    - name: Download CNI plugins (curl fallback)
      ansible.builtin.shell: |
        curl -fsSL -o /tmp/cni-plugins.tgz \
          "https://github.com/containernetworking/plugins/releases/download/v1.8.0/cni-plugins-linux-{{ cni_arch }}-v1.8.0.tgz"
      args:
        creates: /tmp/cni-plugins.tgz
      when: 
        - not cni_installed.stat.exists
        - cni_download is failed or 'cert_file' in (cni_download.msg | default('')) or 'urllib3' in (cni_download.msg | default(''))

    - name: Verify CNI archive downloaded
      ansible.builtin.stat:
        path: /tmp/cni-plugins.tgz
      register: cni_archive
      when: not cni_installed.stat.exists

    - name: Extract CNI plugins
      ansible.builtin.unarchive:
        src: /tmp/cni-plugins.tgz
        dest: /opt/cni/bin
        remote_src: yes
      when: not cni_installed.stat.exists and cni_archive.stat.exists

# -----------------------------------------------------------------------------
# PHASE 3: Control Plane Initialization
# -----------------------------------------------------------------------------
- name: Phase 3 - Initialize control plane
  hosts: monitoring_nodes
  become: true
  tasks:
    - name: Check if control plane initialized
      ansible.builtin.stat:
        path: /etc/kubernetes/admin.conf
      register: admin_conf

    - name: Initialize control plane
      ansible.builtin.shell: |
        kubeadm init \
          --pod-network-cidr=10.244.0.0/16 \
          --service-cidr=10.96.0.0/12 \
          --upload-certs
      when: not admin_conf.stat.exists

    - name: Set KUBECONFIG
      ansible.builtin.lineinfile:
        path: /root/.bashrc
        line: 'export KUBECONFIG=/etc/kubernetes/admin.conf'
        create: yes

    - name: Wait for API server
      ansible.builtin.wait_for:
        host: 127.0.0.1
        port: 6443
        timeout: 120

# -----------------------------------------------------------------------------
# PHASE 4: Worker Node Join
# -----------------------------------------------------------------------------
- name: Phase 4 - Join worker nodes
  hosts: storage_nodes:compute_nodes
  become: true
  tasks:
    - name: Check if node already joined
      ansible.builtin.stat:
        path: /etc/kubernetes/kubelet.conf
      register: kubelet_conf

    - name: Generate join command
      ansible.builtin.shell: kubeadm token create --print-join-command
      delegate_to: "{{ groups['monitoring_nodes'][0] }}"
      register: join_command
      when: not kubelet_conf.stat.exists
      run_once: true

    - name: Join worker to cluster
      ansible.builtin.shell: "{{ join_command.stdout }}"
      when: not kubelet_conf.stat.exists

# -----------------------------------------------------------------------------
# PHASE 5: Flannel CNI Deployment
# -----------------------------------------------------------------------------
- name: Phase 5 - Deploy Flannel CNI
  hosts: monitoring_nodes
  become: true
  tasks:
    - name: Apply Flannel manifest
      ansible.builtin.shell: |
        kubectl --kubeconfig=/etc/kubernetes/admin.conf apply -f {{ playbook_dir }}/../../manifests/cni/flannel.yaml
      register: flannel_apply
      changed_when: "'created' in flannel_apply.stdout or 'configured' in flannel_apply.stdout"

    - name: Wait for Flannel DaemonSet rollout
      ansible.builtin.shell: |
        kubectl --kubeconfig=/etc/kubernetes/admin.conf -n kube-flannel rollout status daemonset/kube-flannel-ds --timeout=90s
      retries: 3
      delay: 10
      register: flannel_rollout
      until: flannel_rollout.rc == 0

    - name: Wait for all Flannel pods to be Ready (not just Running)
      ansible.builtin.shell: |
        set -e
        total_nodes=$(kubectl --kubeconfig=/etc/kubernetes/admin.conf get nodes --no-headers | wc -l)
        ready_flannel=$(kubectl --kubeconfig=/etc/kubernetes/admin.conf -n kube-flannel get pods -l app=flannel --field-selector=status.phase=Running -o json | \
          jq '[.items[] | select(.status.conditions[] | select(.type=="Ready" and .status=="True"))] | length')
        echo "Flannel pods ready: $ready_flannel / $total_nodes"
        test "$ready_flannel" -eq "$total_nodes"
      retries: 20
      delay: 10
      register: flannel_ready
      until: flannel_ready.rc == 0

    - name: Verify subnet.env exists on all nodes
      ansible.builtin.stat:
        path: /run/flannel/subnet.env
      delegate_to: "{{ item }}"
      loop:
        - masternode
        - storagenodet3500
        - homelab
      register: subnet_check
      retries: 10
      delay: 5
      until: subnet_check is defined and (subnet_check.results is defined and (subnet_check.results | selectattr('stat.exists', 'equalto', true) | list | length == 3))
      failed_when: subnet_check is not defined or (subnet_check.results is defined and (subnet_check.results | selectattr('stat.exists', 'equalto', true) | list | length != 3)) or (subnet_check.results is not defined)

    - name: Debug missing subnet.env nodes
      ansible.builtin.debug:
        msg: "subnet.env missing on: {{ item.item }}"
      loop: "{{ subnet_check.results | rejectattr('stat.exists', 'equalto', true) | list }}"
      when: subnet_check is defined and subnet_check.results is defined and (subnet_check.results | selectattr('stat.exists', 'equalto', true) | list | length != 3)

    - name: Verify CNI config exists on all nodes via SSH
      ansible.builtin.stat:
        path: /etc/cni/net.d/10-flannel.conflist
      delegate_to: "{{ item }}"
      loop:
        - masternode
        - storagenodet3500
        - homelab
      register: cni_file_check
      failed_when: not cni_file_check.stat.exists

    - name: Verify CNI flannel binary exists on all nodes
      ansible.builtin.stat:
        path: /opt/cni/bin/flannel
      delegate_to: "{{ item }}"
      loop:
        - masternode
        - storagenodet3500
        - homelab
      register: cni_binary_check
      failed_when: not cni_binary_check.stat.exists

    - name: Wait for all nodes Ready
      ansible.builtin.shell: |
        total=$(kubectl --kubeconfig=/etc/kubernetes/admin.conf get nodes --no-headers | wc -l)
        ready=$(kubectl --kubeconfig=/etc/kubernetes/admin.conf get nodes --no-headers | grep ' Ready ' | wc -l)
        test $ready -eq $total
      retries: 20
      delay: 10
      register: nodes_ready
      until: nodes_ready.rc == 0

    - name: Uncordon all nodes
      ansible.builtin.shell: |
        kubectl --kubeconfig=/etc/kubernetes/admin.conf get nodes -o name | \
          xargs -n1 -r kubectl --kubeconfig=/etc/kubernetes/admin.conf uncordon
      changed_when: false
      ignore_errors: true

    - name: Remove control-plane taint
      ansible.builtin.shell: |
        kubectl --kubeconfig=/etc/kubernetes/admin.conf taint nodes --all node-role.kubernetes.io/control-plane:NoSchedule- || true
      changed_when: false

# -----------------------------------------------------------------------------
# PHASE 6: Validation
# -----------------------------------------------------------------------------
- name: Phase 6 - Validate deployment
  hosts: monitoring_nodes
  become: true
  tasks:
    - name: Validate kube-system pods are healthy (no CrashLoopBackOff)
      ansible.builtin.shell: |
        set -e
        # Get all kube-system pods with status
        CRASH=$(kubectl --kubeconfig=/etc/kubernetes/admin.conf get pods -n kube-system --no-headers | grep -i crash || true)
        if [ -n "$CRASH" ]; then
          echo "ERROR: Found CrashLoopBackOff pods:"
          echo "$CRASH"
          echo ""
          echo "=== Collecting diagnostic logs ==="
          for pod in $(echo "$CRASH" | awk '{print $1}'); do
            echo "--- Pod: $pod ---"
            kubectl --kubeconfig=/etc/kubernetes/admin.conf -n kube-system describe pod "$pod" || true
            echo "--- Current logs ---"
            kubectl --kubeconfig=/etc/kubernetes/admin.conf -n kube-system logs "$pod" --tail=50 || true
            echo "--- Previous logs ---"
            kubectl --kubeconfig=/etc/kubernetes/admin.conf -n kube-system logs "$pod" --previous --tail=50 || true
            echo ""
          done
          exit 1
        fi
        echo "All kube-system pods healthy (no CrashLoopBackOff)"
      register: crash_check
      changed_when: false
      failed_when: crash_check.rc != 0

    - name: Display cluster status
      ansible.builtin.shell: |
        echo "=== Nodes ==="
        kubectl --kubeconfig=/etc/kubernetes/admin.conf get nodes -o wide
        echo ""
        echo "=== kube-system pods ==="
        kubectl --kubeconfig=/etc/kubernetes/admin.conf -n kube-system get pods -o wide
        echo ""
        echo "=== Flannel pods ==="
        kubectl --kubeconfig=/etc/kubernetes/admin.conf -n kube-flannel get pods -o wide
      register: cluster_status
      changed_when: false

    - name: Show cluster status
      ansible.builtin.debug:
        var: cluster_status.stdout_lines

# -----------------------------------------------------------------------------
# PHASE 7: Application Deployment
# -----------------------------------------------------------------------------
- import_playbook: ../plays/deploy-apps.yaml
- import_playbook: ../plays/jellyfin.yml
