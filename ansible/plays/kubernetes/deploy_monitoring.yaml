---
# Deploy monitoring stack (Prometheus, Grafana, Loki) using Helm charts
- name: Deploy monitoring stack on Kubernetes
  hosts: monitoring_nodes
  become: true
  vars:
    monitoring_namespace: monitoring
    
  tasks:
    - name: Ensure kubernetes Python package is available (Debian package preferred)
      apt:
        name: python3-kubernetes
        state: present
        update_cache: yes
      when: ansible_facts['pkg_mgr'] == 'apt' or ansible_pkg_mgr is defined and ansible_pkg_mgr == 'apt'

    - name: Fallback - install kubernetes Python library via pip if apt package missing
      pip:
        name: kubernetes
        state: present
        executable: pip3
      become: true
      when: ansible_facts['pkg_mgr'] is not defined or ansible_facts['pkg_mgr'] != 'apt'

    - name: Install kube-prometheus-stack (Prometheus + Grafana)
      kubernetes.core.helm:
        name: kube-prometheus-stack
        chart_ref: prometheus-community/kube-prometheus-stack
        release_namespace: "{{ monitoring_namespace }}"
        create_namespace: yes
        values:
          # Prometheus configuration
          prometheus:
            prometheusSpec:
              retention: 30d
              storageSpec:
                volumeClaimTemplate:
                  spec:
                    storageClassName: local-path
                    accessModes: ["ReadWriteOnce"]
                    resources:
                      requests:
                        storage: 10Gi
              serviceMonitorSelectorNilUsesHelmValues: false
              podMonitorSelectorNilUsesHelmValues: false
              ruleSelectorNilUsesHelmValues: false
              # Ensure Prometheus runs on monitoring nodes
              nodeSelector:
                kubernetes.io/hostname: "{{ ansible_hostname }}"
            service:
              type: NodePort
              nodePort: 30090
              
          # Grafana configuration
          grafana:
            enabled: true
            adminPassword: admin  # TODO: Use vault for production
            service:
              type: NodePort
              nodePort: 30300
            persistence:
              enabled: true
              storageClassName: local-path
              size: 5Gi
            ingress:
              enabled: false
            grafana.ini:
              security:
                allow_embedding: true
              auth.anonymous:
                enabled: true
                org_role: Viewer
            sidecar:
              dashboards:
                enabled: true
              datasources:
                enabled: true
            # Ensure Grafana runs on monitoring nodes  
            nodeSelector:
              kubernetes.io/hostname: "{{ ansible_hostname }}"
                
          # AlertManager configuration
          alertmanager:
            alertmanagerSpec:
              storage:
                volumeClaimTemplate:
                  spec:
                    storageClassName: local-path
                    accessModes: ["ReadWriteOnce"]
                    resources:
                      requests:
                        storage: 2Gi
              # Ensure AlertManager runs on monitoring nodes
              nodeSelector:
                kubernetes.io/hostname: "{{ ansible_hostname }}"
            service:
              type: NodePort
              nodePort: 30903
              
          # Node exporter configuration
          nodeExporter:
            enabled: true
            
          # Prometheus operator configuration
          prometheusOperator:
            enabled: true
            
        kubeconfig: /root/.kube/config

    - name: Install Loki stack
      kubernetes.core.helm:
        name: loki-stack
        chart_ref: grafana/loki-stack
        release_namespace: "{{ monitoring_namespace }}"
        values:
          loki:
            enabled: true
            image:
              tag: "2.9.2"  # Use stable version to prevent crashloop
              
            # Resource limits to prevent OOM kills and crashloops
            resources:
              limits:
                cpu: 1000m
                memory: 1Gi
              requests:
                cpu: 200m
                memory: 256Mi
                
            persistence:
              enabled: true
              storageClassName: local-path
              size: 10Gi
              accessModes:
                - ReadWriteOnce
                
            # Ensure Loki runs on monitoring nodes
            nodeSelector:
              kubernetes.io/hostname: "{{ ansible_hostname }}"
              
            # Security context for proper permissions
            securityContext:
              fsGroup: 10001
              runAsGroup: 10001
              runAsNonRoot: true
              runAsUser: 10001
              
            config:
              auth_enabled: false
              server:
                http_listen_port: 3100
                grpc_listen_port: 9095
                
              # Distributor configuration
              distributor:
                ring:
                  kvstore:
                    store: inmemory
                    
              # Optimized ingester configuration to prevent crashes
              ingester:
                lifecycler:
                  address: 127.0.0.1
                  ring:
                    kvstore:
                      store: inmemory
                    replication_factor: 1
                  final_sleep: 0s
                chunk_idle_period: 1h
                max_chunk_age: 1h
                chunk_target_size: 1048576
                chunk_retain_period: 30s
                max_transfer_retries: 0
                
              schema_config:
                configs:
                - from: 2020-10-24
                  store: boltdb-shipper
                  object_store: filesystem
                  schema: v11
                  index:
                    prefix: index_
                    period: 24h
                    
              # Storage configuration with safer paths
              storage_config:
                boltdb_shipper:
                  active_index_directory: /loki/boltdb-shipper-active
                  cache_location: /loki/boltdb-shipper-cache
                  shared_store: filesystem
                filesystem:
                  directory: /loki/chunks
                  
              # Limits configuration to prevent crashes
              limits_config:
                enforce_metric_name: false
                reject_old_samples: true
                reject_old_samples_max_age: 168h
                ingestion_rate_mb: 16
                ingestion_burst_size_mb: 32
                max_streams_per_user: 10000
                max_line_size: 256000
                split_queries_by_interval: 30s
                max_retries: 5
                
              # Table manager configuration
              table_manager:
                retention_deletes_enabled: false
                retention_period: 0s
                
              # Query configuration
              querier:
                max_concurrent: 16
                
              # Compactor configuration
              compactor:
                working_directory: /loki/boltdb-shipper-compactor
                shared_store: filesystem
                
            service:
              type: NodePort
              nodePort: 31100
              
          promtail:
            enabled: true
            image:
              tag: "2.9.2"  # Match Loki version
              
            # Resource limits for promtail to prevent container creation issues
            resources:
              limits:
                cpu: 500m
                memory: 256Mi
              requests:
                cpu: 100m
                memory: 128Mi
                
            # Security context for log access
            securityContext:
              readOnlyRootFilesystem: true
              runAsGroup: 0
              runAsUser: 0
              
            config:
              server:
                http_listen_port: 3101
                grpc_listen_port: 0
                
              positions:
                filename: /tmp/positions.yaml
                
              clients:
                - url: http://loki-stack:3100/loki/api/v1/push
                  timeout: 60s
                  backoff_config:
                    min_period: 500ms
                    max_period: 5m
                    max_retries: 10
                    
              scrape_configs:
                - job_name: kubernetes-pods
                  kubernetes_sd_configs:
                    - role: pod
                  relabel_configs:
                    - source_labels:
                        - __meta_kubernetes_pod_controller_name
                      regex: ([0-9a-z-.]+?)(-[0-9a-f]{8,10})?
                      action: replace
                      target_label: __tmp_controller_name
                    - source_labels:
                        - __meta_kubernetes_pod_label_app_kubernetes_io_name
                        - __meta_kubernetes_pod_label_app
                        - __tmp_controller_name
                        - __meta_kubernetes_pod_name
                      regex: ^;*([^;]+)(;.*)?$
                      action: replace
                      target_label: app
                    - source_labels:
                        - __meta_kubernetes_pod_label_app_kubernetes_io_instance
                        - __meta_kubernetes_pod_label_release
                      regex: ^;*([^;]+)(;.*)?$
                      action: replace
                      target_label: instance
                    - action: replace
                      source_labels:
                      - __meta_kubernetes_pod_node_name
                      target_label: node_name
                    - action: replace
                      source_labels:
                      - __meta_kubernetes_namespace
                      target_label: namespace
                    - action: replace
                      replacement: /var/log/pods/*$1/*.log
                      separator: /
                      source_labels:
                      - __meta_kubernetes_pod_uid
                      - __meta_kubernetes_pod_container_name
                      target_label: __path__
                      
            # Volume mounts for proper log access
            volumeMounts:
              - name: varlog
                mountPath: /var/log
                readOnly: true
              - name: varlibdockercontainers
                mountPath: /var/lib/docker/containers
                readOnly: true
                
            volumes:
              - name: varlog
                hostPath:
                  path: /var/log
              - name: varlibdockercontainers
                hostPath:
                  path: /var/lib/docker/containers
                  
          grafana:
            enabled: false  # We already have Grafana from kube-prometheus-stack
            
        kubeconfig: /root/.kube/config

    - name: Create node exporter service monitor
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: monitoring.coreos.com/v1
          kind: ServiceMonitor
          metadata:
            name: node-exporter
            namespace: "{{ monitoring_namespace }}"
            labels:
              app: node-exporter
          spec:
            selector:
              matchLabels:
                app.kubernetes.io/name: node-exporter
            endpoints:
            - port: http-metrics
              interval: 30s
              path: /metrics
        kubeconfig: /root/.kube/config

    - name: Create Loki data source for Grafana
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: loki-datasource
            namespace: "{{ monitoring_namespace }}"
            labels:
              grafana_datasource: "1"
          data:
            loki-datasource.yaml: |
              apiVersion: 1
              datasources:
                - name: Loki
                  type: loki
                  access: proxy
                  url: http://loki-stack:3100
                  jsonData:
                    maxLines: 1000
        kubeconfig: /root/.kube/config

    - name: Create Prometheus datasource for Grafana (provisioning)
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: prometheus-datasource
            namespace: "{{ monitoring_namespace }}"
            labels:
              grafana_datasource: "1"
          data:
            prometheus-datasource.yaml: "{{ lookup('file', playbook_dir + '/ansible/files/grafana_datasources/prometheus-datasource.yaml') }}"
        kubeconfig: /root/.kube/config

    - name: Provision Grafana dashboards as ConfigMaps
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: grafana-dashboards
            namespace: "{{ monitoring_namespace }}"
            labels:
              grafana_dashboard: "1"
          data:
            prometheus-dashboard.json: "{{ lookup('file', playbook_dir + '/ansible/files/grafana_dashboards/prometheus-dashboard.json') }}"
            loki-dashboard.json: "{{ lookup('file', playbook_dir + '/ansible/files/grafana_dashboards/loki-dashboard.json') }}"
            node-dashboard.json: "{{ lookup('file', playbook_dir + '/ansible/files/grafana_dashboards/node-dashboard.json') }}"
        kubeconfig: /root/.kube/config

    - block:
        - name: Wait for monitoring stack to be ready
          kubernetes.core.k8s_info:
            api_version: v1
            kind: Pod
            namespace: "{{ monitoring_namespace }}"
            label_selectors:
              - app.kubernetes.io/name=prometheus
            wait: true
            wait_condition:
              type: Ready
              status: "True"
            wait_timeout: 300
            kubeconfig: /root/.kube/config
          register: monitoring_wait
      rescue:
        - name: Gather pods in monitoring namespace
          kubernetes.core.k8s_info:
            api_version: v1
            kind: Pod
            namespace: "{{ monitoring_namespace }}"
            kubeconfig: /root/.kube/config
          register: monitoring_pods

        - name: Gather events in monitoring namespace
          kubernetes.core.k8s_info:
            api_version: v1
            kind: Event
            namespace: "{{ monitoring_namespace }}"
            kubeconfig: /root/.kube/config
          register: monitoring_events

        - name: Describe non-ready pods for diagnostics
          shell: kubectl describe pod {{ item.metadata.name }} -n {{ monitoring_namespace }}
          environment:
            KUBECONFIG: /root/.kube/config
          register: pod_describes
          loop: "{{ monitoring_pods.resources }}"
          when: item.status.conditions is defined and (item.status.conditions | selectattr('type','equalto','Ready') | selectattr('status','equalto','False') | list) | length > 0

        - name: Collect recent logs for non-ready pods
          shell: kubectl logs {{ item.metadata.name }} -n {{ monitoring_namespace }} --tail=200 --all-containers
          environment:
            KUBECONFIG: /root/.kube/config
          register: pod_logs
          loop: "{{ monitoring_pods.resources }}"
          when: item.status.conditions is defined and (item.status.conditions | selectattr('type','equalto','Ready') | selectattr('status','equalto','False') | list) | length > 0

        - name: Build safe pod_describes output list
          ansible.builtin.set_fact:
            pod_describes_out: "{{ [ item.stdout if (item is defined and item.stdout is defined) else '' for item in (pod_describes.results | default([])) ] }}"

        - name: Build safe pod_logs output list
          ansible.builtin.set_fact:
            pod_logs_out: "{{ [ item.stdout if (item is defined and item.stdout is defined) else '' for item in (pod_logs.results | default([])) ] }}"

        - name: Show monitoring diagnostics summary
          debug:
            msg:
              pods: "{{ (monitoring_pods.resources | default([])) | map(attribute='metadata.name') | list }}"
              events_count: "{{ (monitoring_events.resources | default([])) | length }}"
              pod_describes: "{{ pod_describes_out | default([]) }}"
              pod_logs: "{{ pod_logs_out | default([]) }}"

    - name: Get monitoring service endpoints
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Service
        namespace: "{{ monitoring_namespace }}"
        kubeconfig: /root/.kube/config
      register: monitoring_services

    - name: Display monitoring access URLs
      debug:
        msg: |
          Monitoring stack deployed successfully!
          
          Access URLs (NodePort services):
          - Grafana: http://{{ ansible_default_ipv4.address }}:30300 (admin/admin)
          - Prometheus: http://{{ ansible_default_ipv4.address }}:30090
          - AlertManager: http://{{ ansible_default_ipv4.address }}:30903
          - Loki: http://{{ ansible_default_ipv4.address }}:31100