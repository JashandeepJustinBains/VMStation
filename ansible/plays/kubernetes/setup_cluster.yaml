---
# Kubernetes Cluster Setup Playbook
# Sets up monitoring_nodes as control plane and other nodes as workers
- name: Setup Kubernetes cluster with monitoring_nodes as control plane
  hosts: all
  become: true
  vars:
    kubernetes_version: "1.29"
    pod_network_cidr: "10.244.0.0/16"
    
  pre_tasks:
    - name: Remove bad kubernetes-upstream repo and clean yum/dnf cache (preflight)
      shell: |
        rm -f /etc/yum.repos.d/kubernetes-upstream.repo || true
        if command -v dnf >/dev/null 2>&1; then
          dnf clean all || true
        else
          yum clean all || true
        fi
      when: ansible_os_family == 'RedHat'
      ignore_errors: yes

  tasks:
    - name: Update apt cache
      apt:
        update_cache: yes
      when: ansible_os_family == 'Debian'

    - name: Install required packages
      apt:
        name:
          - apt-transport-https
          - ca-certificates
          - curl
          - gpg
        state: present
      when: ansible_os_family == 'Debian'

    - name: Add Kubernetes GPG key
      apt_key:
        url: https://pkgs.k8s.io/core:/stable:/v{{ kubernetes_version }}/deb/Release.key
        state: present
      when: ansible_os_family == 'Debian'

    - name: Add Kubernetes repository
      apt_repository:
        repo: "deb https://pkgs.k8s.io/core:/stable:/v{{ kubernetes_version }}/deb/ /"
        state: present
        filename: kubernetes
      when: ansible_os_family == 'Debian'

    - name: Update apt cache after adding repository
      apt:
        update_cache: yes
      when: ansible_os_family == 'Debian'

    - name: Install Kubernetes packages
      apt:
        name:
          - kubelet
          - kubeadm
          - kubectl
        state: present
      when: ansible_os_family == 'Debian'

    - name: Remove user-added kubernetes-upstream repo file if present (prevents broken metadata)
      file:
        path: /etc/yum.repos.d/kubernetes-upstream.repo
        state: absent
      when: ansible_os_family == 'RedHat'
      ignore_errors: yes

    - name: Ensure yum-utils is installed on RHEL-family systems
      package:
        name: yum-utils
        state: present
      when: ansible_os_family == 'RedHat'

    - name: Determine RHEL major version
      set_fact:
        rhel_major: "{{ ansible_distribution_major_version | int }}"
      when: ansible_os_family == 'RedHat'
    - block:
        - name: Add Kubernetes yum repository for RHEL-family systems (EL9/EL8)
          yum_repository:
            name: kubernetes
            description: Kubernetes repo
            baseurl: "https://pkgs.k8s.io/core:/stable:/v{{ kubernetes_version }}/rpm/"
            gpgcheck: yes
            repo_gpgcheck: yes
            gpgkey: "https://pkgs.k8s.io/core:/stable:/v{{ kubernetes_version }}/rpm/Release.key"
            enabled: yes
        - name: Update yum cache on RHEL-family systems (EL9/EL8)
          command: yum makecache -q
        - name: Install Kubernetes and containerd packages on RHEL-family systems (EL9/EL8)
          package:
            name:
              - kubelet
              - kubeadm
              - kubectl
              - containerd
            state: present
      when: ansible_os_family == 'RedHat' and (rhel_major | int) < 10

    - block:
        - name: Add Docker CE repo for containerd (RHEL 10+ fallback)
          shell: |
            if command -v curl >/dev/null 2>&1; then
              curl -fsSL https://download.docker.com/linux/centos/docker-ce.repo -o /etc/yum.repos.d/docker-ce.repo
            elif command -v wget >/dev/null 2>&1; then
              wget -q -O /etc/yum.repos.d/docker-ce.repo https://download.docker.com/linux/centos/docker-ce.repo
            else
              dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo || true
            fi
          args:
            creates: /etc/yum.repos.d/docker-ce.repo
        - name: Ensure Docker CE repo file has correct permissions
          file:
            path: /etc/yum.repos.d/docker-ce.repo
            mode: '0644'
            owner: root
            group: root
        - name: Refresh package cache (dnf)
          command: dnf makecache --refresh
        - name: Try install containerd.io (RHEL 10+)
          package:
            name: containerd.io
            state: present
          register: containerd_install
          ignore_errors: yes
        - name: Fallback install containerd package name (containerd) if containerd.io not available
          package:
            name: containerd
            state: present
          when: containerd_install is failed
        - name: Ensure containerd directory exists
          file:
            path: /etc/containerd
            state: directory
        - name: Start and enable containerd (RHEL 10+)
          systemd:
            name: containerd
            state: restarted
            enabled: yes
        - name: Download kubeadm binary (RHEL 10+ fallback)
          shell: |
            if command -v curl >/dev/null 2>&1; then
              curl -fsSL "https://dl.k8s.io/release/stable-{{ kubernetes_version }}/bin/linux/amd64/kubeadm" -o /usr/bin/kubeadm
            elif command -v wget >/dev/null 2>&1; then
              wget -q -O /usr/bin/kubeadm "https://dl.k8s.io/release/stable-{{ kubernetes_version }}/bin/linux/amd64/kubeadm"
            fi
          args:
            creates: /usr/bin/kubeadm
        - name: Ensure kubeadm is executable
          file:
            path: /usr/bin/kubeadm
            mode: '0755'
            owner: root
            group: root
        - name: Download kubectl binary (RHEL 10+ fallback)
          shell: |
            if command -v curl >/dev/null 2>&1; then
              curl -fsSL "https://dl.k8s.io/release/stable-{{ kubernetes_version }}/bin/linux/amd64/kubectl" -o /usr/bin/kubectl
            elif command -v wget >/dev/null 2>&1; then
              wget -q -O /usr/bin/kubectl "https://dl.k8s.io/release/stable-{{ kubernetes_version }}/bin/linux/amd64/kubectl"
            fi
          args:
            creates: /usr/bin/kubectl
        - name: Ensure kubectl is executable
          file:
            path: /usr/bin/kubectl
            mode: '0755'
            owner: root
            group: root
        - name: Download kubelet binary (RHEL 10+ fallback)
          shell: |
            if command -v curl >/dev/null 2>&1; then
              curl -fsSL "https://dl.k8s.io/release/stable-{{ kubernetes_version }}/bin/linux/amd64/kubelet" -o /usr/bin/kubelet
            elif command -v wget >/dev/null 2>&1; then
              wget -q -O /usr/bin/kubelet "https://dl.k8s.io/release/stable-{{ kubernetes_version }}/bin/linux/amd64/kubelet"
            fi
          args:
            creates: /usr/bin/kubelet
        - name: Ensure kubelet is executable
          file:
            path: /usr/bin/kubelet
            mode: '0755'
            owner: root
            group: root
        - name: Download crictl binary (RHEL 10+ fallback)
          shell: |
            if command -v curl >/dev/null 2>&1; then
              curl -fsSL \
                "https://github.com/kubernetes-sigs/cri-tools/releases/download/v{{ kubernetes_version }}.0/crictl-v{{ kubernetes_version }}.0-linux-amd64.tar.gz" \
                -o /tmp/crictl.tar.gz
            elif command -v wget >/dev/null 2>&1; then
              wget -q -O /tmp/crictl.tar.gz \
                "https://github.com/kubernetes-sigs/cri-tools/releases/download/v{{ kubernetes_version }}.0/crictl-v{{ kubernetes_version }}.0-linux-amd64.tar.gz"
            fi
          args:
            creates: /usr/bin/crictl
        - name: Extract and install crictl
          shell: |
            tar -xzf /tmp/crictl.tar.gz -C /tmp/
            mv /tmp/crictl /usr/bin/crictl
            chmod +x /usr/bin/crictl
            rm -f /tmp/crictl.tar.gz
          args:
            creates: /usr/bin/crictl
        - name: Install conntrack package (RHEL 10+ fallback)
          package:
            name: conntrack-tools
            state: present
          ignore_errors: yes
        - name: Install conntrack if conntrack-tools not available (RHEL 10+)
          package:
            name: conntrack
            state: present
          ignore_errors: yes
        - name: Create minimal kubelet systemd unit (RHEL 10+ fallback)
          copy:
            dest: /etc/systemd/system/kubelet.service
            content: |
              [Unit]
              Description=kubelet: The Kubernetes Node Agent
              Documentation=https://kubernetes.io/docs/
              After=network.target containerd.service
              Requires=containerd.service

              [Service]
              ExecStart=/usr/bin/kubelet
              Restart=always
              RestartSec=10

              [Install]
              WantedBy=multi-user.target
        - name: Reload systemd and enable/start kubelet (RHEL 10+ fallback)
          systemd:
            name: kubelet
            state: restarted
            enabled: yes
      when: ansible_os_family == 'RedHat' and (rhel_major | int) >= 10

    - name: Ensure SELinux is permissive on RHEL-family systems (required for some container setups)
      selinux:
        state: permissive
        policy: targeted
      when: ansible_os_family == 'RedHat' and (ansible_selinux is defined and ansible_selinux.status != 'Disabled')

    - name: Hold Kubernetes packages
      dpkg_selections:
        name: "{{ item }}"
        selection: hold
      loop:
        - kubelet
        - kubeadm
        - kubectl
      when: ansible_os_family == 'Debian'

    - name: Disable swap permanently
      replace:
        path: /etc/fstab
        regexp: '^([^#].*?\sswap\s.*)$'
        replace: '# \1'

    - name: Disable swap immediately
      command: swapoff -a
      changed_when: false

    - name: Load required kernel modules
      modprobe:
        name: "{{ item }}"
      loop:
        - overlay
        - br_netfilter

    - name: Create kernel modules config
      copy:
        content: |
          overlay
          br_netfilter
        dest: /etc/modules-load.d/k8s.conf

    - name: Set sysctl parameters for Kubernetes
      sysctl:
        name: "{{ item.key }}"
        value: "{{ item.value }}"
        state: present
        reload: yes
      loop:
        - { key: 'net.bridge.bridge-nf-call-iptables', value: '1' }
        - { key: 'net.bridge.bridge-nf-call-ip6tables', value: '1' }
        - { key: 'net.ipv4.ip_forward', value: '1' }

    - name: Install containerd
      apt:
        name: containerd
        state: present
      when: ansible_os_family == 'Debian'

    - name: Create containerd configuration directory
      file:
        path: /etc/containerd
        state: directory

    - name: Check if containerd binary exists
      stat:
        path: /usr/bin/containerd
      register: containerd_bin

    - name: Generate containerd configuration
      shell: containerd config default
      register: containerd_config
      when: containerd_bin.stat.exists

    - name: Write containerd configuration
      copy:
        content: "{{ containerd_config.stdout }}"
        dest: /etc/containerd/config.toml
      when: containerd_bin.stat.exists

    - name: Configure containerd to use systemd cgroup driver
      replace:
        path: /etc/containerd/config.toml
        regexp: 'SystemdCgroup = false'
        replace: 'SystemdCgroup = true'
      when: containerd_bin.stat.exists

    - name: Restart and enable containerd
      systemd:
        name: containerd
        state: restarted
        enabled: yes
      when: containerd_bin.stat.exists

    - name: Gather service facts
      service_facts:

    - name: Restart and enable kubelet (only if service exists)
      systemd:
        name: kubelet
        state: restarted
        enabled: yes
      when: "'kubelet.service' in ansible_facts.services"

# Control plane initialization (only on monitoring_nodes)
- name: Initialize Kubernetes control plane
  hosts: monitoring_nodes
  become: true
  vars:
    pod_network_cidr: "10.244.0.0/16"
  tasks:
    - name: Check if cluster is already initialized
      stat:
        path: /etc/kubernetes/admin.conf
      register: kubeconfig

    - name: Initialize Kubernetes cluster
      command: >
        kubeadm init 
        --pod-network-cidr={{ pod_network_cidr }}
        --apiserver-advertise-address={{ ansible_default_ipv4.address }}
        --control-plane-endpoint={{ ansible_default_ipv4.address }}
      when: not kubeconfig.stat.exists
      register: kubeadm_init

    - name: Create .kube directory for root
      file:
        path: /root/.kube
        state: directory
        owner: root
        group: root
        mode: '0755'

    - name: Copy admin.conf to root's kubeconfig
      copy:
        src: /etc/kubernetes/admin.conf
        dest: /root/.kube/config
        owner: root
        group: root
        mode: '0644'
        remote_src: yes

    - name: Install Flannel CNI
      shell: kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf

    - name: Get join command
      shell: kubeadm token create --print-join-command
      register: join_command

    - name: Save join command to file
      copy:
        content: "{{ join_command.stdout }}"
        dest: /tmp/kubeadm-join.sh
        mode: '0755'

    - name: Fetch join command to local machine
      fetch:
        src: /tmp/kubeadm-join.sh
        dest: /tmp/kubeadm-join.sh
        flat: yes

# Join worker nodes
- name: Join worker nodes to cluster
  hosts: storage_nodes:compute_nodes
  become: true
  tasks:
    - name: Check if node is already joined
      stat:
        path: /etc/kubernetes/kubelet.conf
      register: kubelet_conf

    - name: Stop kubelet service if running (to prevent port conflicts)
      systemd:
        name: kubelet
        state: stopped
      when: not kubelet_conf.stat.exists
      ignore_errors: yes

    - name: Copy join command to worker nodes
      copy:
        src: /tmp/kubeadm-join.sh
        dest: /tmp/kubeadm-join.sh
        mode: '0755'
      when: not kubelet_conf.stat.exists

    - name: Join worker nodes to cluster
      # Run join with extra verbosity and capture output so we can gather logs on failure.
      # We run the script with --v=5 for detailed stack traces from kubeadm if available.
      shell: /tmp/kubeadm-join.sh --v=5
      register: join_result
      failed_when: join_result.rc != 0
      when: not kubelet_conf.stat.exists

    - name: If join failed, extract join target from script (for connectivity checks)
      shell: "awk '{print $3}' /tmp/kubeadm-join.sh"
      register: join_target
      changed_when: false
      failed_when: false
      when: not kubelet_conf.stat.exists and (join_result is defined and join_result.rc != 0)

    - name: If join failed, test API server reachability from node
      shell: "curl -k --connect-timeout 5 https://{{ join_target.stdout }}/healthz"
      register: api_health
      failed_when: false
      changed_when: false
      when: not kubelet_conf.stat.exists and (join_result is defined and join_result.rc != 0)

    - name: If join failed, collect kubelet and containerd status for debugging
      shell: |
        systemctl status kubelet --no-pager || true
        systemctl is-active containerd || true
        systemctl status containerd --no-pager || true
        echo '--- /var/lib/kubelet/kubeadm-flags.env ---' && cat /var/lib/kubelet/kubeadm-flags.env || true
        echo '--- /var/lib/kubelet/config.yaml ---' && sed -n '1,200p' /var/lib/kubelet/config.yaml || true
      register: runtime_debug
      changed_when: false
      failed_when: false
      when: not kubelet_conf.stat.exists and (join_result is defined and join_result.rc != 0)

    - name: If join failed, save kubelet journal to a file for fetch
      shell: "journalctl -u kubelet -n 200 --no-pager > /tmp/kubelet-journal.log || true"
      changed_when: false
      when: not kubelet_conf.stat.exists and (join_result is defined and join_result.rc != 0)

    - name: If join failed, save containerd journal to a file for fetch
      shell: "journalctl -u containerd -n 200 --no-pager > /tmp/containerd-journal.log || true"
      changed_when: false
      when: not kubelet_conf.stat.exists and (join_result is defined and join_result.rc != 0)

    - name: If join failed, fetch kubelet journal to control machine
      fetch:
        src: /tmp/kubelet-journal.log
        dest: ./debug_logs/{{ inventory_hostname }}-kubelet-journal.log
        flat: yes
      when: not kubelet_conf.stat.exists and (join_result is defined and join_result.rc != 0)

    - name: If join failed, fetch containerd journal to control machine
      fetch:
        src: /tmp/containerd-journal.log
        dest: ./debug_logs/{{ inventory_hostname }}-containerd-journal.log
        flat: yes
      when: not kubelet_conf.stat.exists and (join_result is defined and join_result.rc != 0)

    - name: Remove join command file
      file:
        path: /tmp/kubeadm-join.sh
        state: absent