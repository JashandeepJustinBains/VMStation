

- name: Podman Metrics Exporter Setup
  hosts: all
  become: true
  tasks:
    - name: Validate /srv/monitoring_data is mounted on monitoring nodes
      ansible.builtin.fail:
        msg: "/srv/monitoring_data is not mounted. Mount your monitoring partition (e.g. /dev/sda1) to /srv/monitoring_data and re-run the playbook."
      when: (inventory_hostname in groups['monitoring_nodes']) and ((ansible_mounts | selectattr('mount','equalto','/srv/monitoring_data') | list | length) == 0)

    - name: Validate /srv/monitoring_data is writable on monitoring nodes
      ansible.builtin.command: test -w /srv/monitoring_data
      register: monitoring_write_test
      failed_when: monitoring_write_test.rc != 0
      changed_when: false
      when: inventory_hostname in groups['monitoring_nodes']

    # ...existing code...
    - name: Add Podman repo key (Debian/Ubuntu)
      apt_key:
        url: 'https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/xUbuntu_22.04/Release.key'
        state: present
      when: ansible_os_family == 'Debian'

    - name: Add Podman upstream repository (Debian/Ubuntu)
      apt_repository:
        repo: 'deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/xUbuntu_22.04/ /'
        state: present
      when: ansible_os_family == 'Debian'

    - name: Upgrade Podman to latest upstream version (Debian/Ubuntu)
      apt:
        name: podman
        state: latest
        update_cache: yes
      when: ansible_os_family == 'Debian'

    - name: Enable Podman metrics endpoint
      ansible.builtin.lineinfile:
        path: /etc/containers/containers.conf
        regexp: '^#?metrics_port ='
        line: 'metrics_port = 9882'
        state: present
        create: yes
      # No handler needed; explicit restart task follows
      tags: metrics

    - name: Ensure Podman service is restarted to apply metrics config
      ansible.builtin.systemd:
        name: podman
        state: restarted
        enabled: yes
      when: ansible_service_mgr == 'systemd'
      tags: metrics

    - name: Ensure /etc/promtail directory exists
      ansible.builtin.file:
        path: /etc/promtail
        state: directory
        owner: root
        group: root
        mode: '0755'
      tags: logs

    - name: Create systemd unit for Podman metrics service
      ansible.builtin.copy:
        dest: /etc/systemd/system/podman-metrics.service
        content: |
          [Unit]
          Description=Podman Metrics Service
          After=network.target

          [Service]
          ExecStart=/usr/bin/podman system service --time=0 tcp:0.0.0.0:9882
          Restart=always
          User=root

          [Install]
          WantedBy=multi-user.target
        mode: '0644'
      tags: metrics

    - name: Reload systemd and enable/start podman-metrics
      ansible.builtin.systemd:
        name: podman-metrics.service
        state: started
        enabled: yes
        daemon_reload: yes
      tags: metrics

    - name: Ensure monitoring data base exists on hosts
      ansible.builtin.file:
        path: /srv/monitoring_data
        state: directory
        owner: root
        group: root
        mode: '0755'
      tags: monitoring_storage

    - name: Ensure promtail data directory exists on hosts
      ansible.builtin.file:
        path: /srv/monitoring_data/promtail
        state: directory
        owner: root
        group: root
        mode: '0755'
        recurse: yes
      tags: monitoring_storage

    - name: Ensure prometheus data directory exists on monitoring nodes
      ansible.builtin.file:
        path: /srv/monitoring_data/prometheus
        state: directory
        owner: 65534
        group: 65534
        mode: '0755'
        recurse: yes
      when: inventory_hostname in groups['monitoring_nodes']
      tags: monitoring_storage

    - name: Deploy promtail container
      containers.podman.podman_container:
        name: promtail
        image: docker.io/grafana/promtail:latest
        state: started
        volumes:
          - /var/log:/var/log:ro
          - /etc/promtail:/etc/promtail:ro
          - /srv/monitoring_data/promtail:/var/promtail:rw
        restart_policy: always
        command: -config.file=/etc/promtail/promtail.yaml -positions.file=/var/promtail/positions.yaml
      tags: logs

    - name: Check if port 9100 is in use
      ansible.builtin.shell: ss -ltnp | grep ':9100' || true
      register: port_9100_check
      changed_when: false
      tags: node_exporter

    - name: Set fact if 9100 is in use
      ansible.builtin.set_fact:
        port_9100_in_use: "{{ port_9100_check.stdout != '' }}"
      tags: node_exporter

    - name: Get PID owning 9100 (if any)
      ansible.builtin.shell: |
        ss -ltnp | grep ':9100' | sed -n 's/.*pid=\([0-9]*\),.*/\1/p' | head -n1 || true
      register: port_9100_pid
      changed_when: false
      when: port_9100_in_use
      tags: node_exporter

    - name: Stop systemd node_exporter service if present
      ansible.builtin.systemd:
        name: node_exporter
        state: stopped
        enabled: no
      failed_when: false
      changed_when: true
      when: port_9100_in_use
      tags: node_exporter

    - name: Stop and remove any existing podman container named node-exporter
      containers.podman.podman_container:
        name: node-exporter
        state: absent
        remove: true
      failed_when: false
      changed_when: true
      when: port_9100_in_use
      tags: node_exporter

    - name: Kill leftover PID owning 9100 if still present
      ansible.builtin.shell: "kill -TERM {{ port_9100_pid.stdout }} || true"
      when:
        - port_9100_in_use
        - port_9100_pid.stdout is defined
        - port_9100_pid.stdout | length > 0
      failed_when: false
      changed_when: true
      tags: node_exporter

    - name: Wait for port 9100 to become free
      ansible.builtin.wait_for:
        host: 127.0.0.1
        port: 9100
        state: stopped
        timeout: 15
      register: wait_9100_free
      failed_when: false
      changed_when: false
      tags: node_exporter

    - name: Debug port free result
      ansible.builtin.debug:
        msg: "port_9100_in_use={{ port_9100_in_use }} port_pid='{{ port_9100_pid.stdout | default('') }}' wait_result={{ wait_9100_free }}"
      tags: node_exporter

    - name: Pull node_exporter image from Docker Hub
      ansible.builtin.command: podman pull docker.io/prom/node-exporter:latest
      register: node_exporter_pull
      failed_when: false
      changed_when: node_exporter_pull.rc == 0
      tags: node_exporter

    - name: Run node_exporter as a Podman container
      containers.podman.podman_container:
        name: node-exporter
        image: docker.io/prom/node-exporter:latest
        state: started
        restart_policy: always
        ports:
          - "9100:9100"
        volumes:
          - /proc:/host/proc:ro
          - /sys:/host/sys:ro
          - /:/rootfs:ro
        command: --path.procfs=/host/proc --path.sysfs=/host/sys --path.rootfs=/rootfs
      when: node_exporter_pull.rc == 0
      tags: node_exporter

    - name: Warn if node_exporter image pull failed
      ansible.builtin.debug:
        msg: "node_exporter image pull failed (docker.io/prom/node-exporter:latest). Falling back to system package or local binary setup."
      when: node_exporter_pull.rc != 0
      tags: node_exporter

    - name: Pull podman_exporter image from Docker Hub (public)
      image: docker.io/prometheus_podman_exporter:latest
      state: started      register: podman_exporter_pull
      failed_when: false
      changed_when: podman_exporter_pull.rc == 0
      tags: podman_exporter

    - name: Deploy podman_exporter container on hosts (exposes Prometheus metrics on 9300)
      containers.podman.podman_container:
        name: podman-exporter
        image: docker.io/veemero/podman_exporter:latest
        state: started
        restart_policy: always
        ports:
          - "9300:9300"
        command: --web.listen-address=0.0.0.0:9300
      when: podman_exporter_pull.rc == 0
      tags: podman_exporter

    - name: Warn if podman_exporter image pull failed
      ansible.builtin.debug:
        msg: "podman_exporter image pull failed (docker.io/veemero/podman_exporter:latest). Set up alternate exporter or login to registry."
      when: podman_exporter_pull.rc != 0
      tags: podman_exporter

    - name: Wait for podman_exporter to listen on 9300 (non-fatal)
      ansible.builtin.wait_for:
        host: 127.0.0.1
        port: 9300
        timeout: 30
      register: podman_exporter_wait
      failed_when: false
      changed_when: false
      tags: podman_exporter

    - name: Validate podman_exporter /metrics endpoint (sample)
      ansible.builtin.uri:
        url: http://127.0.0.1:9300/metrics
        method: GET
        return_content: false
        status_code: 200
      register: podman_exporter_probe
      failed_when: false
      changed_when: false
      tags: podman_exporter


    - name: Ensure /etc/prometheus directory exists on monitoring_node
      ansible.builtin.file:
        path: /etc/prometheus
        state: directory
        owner: root
        group: root
        mode: '0755'
      when: inventory_hostname in groups['monitoring_nodes']
      tags: prometheus

    - name: Template prometheus.yml to monitoring_node from inventory
      ansible.builtin.template:
        src: ../templates/prometheus.yml.j2
        dest: /etc/prometheus/prometheus.yml
        owner: root
        group: root
        mode: '0644'
      notify: Restart Prometheus Container
      when: inventory_hostname in groups['monitoring_nodes']
      tags: prometheus

    - name: Ensure Prometheus image is pulled on monitoring nodes
      ansible.builtin.command: podman pull docker.io/prom/prometheus:latest
      when: inventory_hostname in groups['monitoring_nodes']
      tags: prometheus

    - name: Run Prometheus as a Podman container on monitoring nodes
      containers.podman.podman_container:
        name: prometheus
        image: docker.io/prom/prometheus:latest
        state: started
        restart_policy: always
        ports:
          - "9090:9090"
        volumes:
          - /etc/prometheus:/etc/prometheus:Z
          - /srv/monitoring_data/prometheus:/prometheus:Z
        command: --config.file=/etc/prometheus/prometheus.yml --storage.tsdb.path=/prometheus
      when: inventory_hostname in groups['monitoring_nodes']
      tags: prometheus

    - name: Wait for Prometheus to listen on 9090 (non-fatal)
      ansible.builtin.wait_for:
        host: 127.0.0.1
        port: 9090
        timeout: 60
      register: prometheus_wait
      failed_when: false
      when: inventory_hostname in groups['monitoring_nodes']
      tags: prometheus

    - name: Gather podman containers state for Prometheus
      ansible.builtin.command: podman ps -a --format json
      register: podman_ps
      failed_when: false
      changed_when: false
      when: inventory_hostname in groups['monitoring_nodes']
      tags: prometheus

    - name: Collect Prometheus container logs (last 200 lines)
      ansible.builtin.command: podman logs --tail 200 prometheus
      register: prometheus_logs
      failed_when: false
      changed_when: false
      when: inventory_hostname in groups['monitoring_nodes']
      tags: prometheus

    - name: Debug Prometheus startup status
      ansible.builtin.debug:
        msg: |
          Prometheus wait result: rc={{ (prometheus_wait | default({})).get('rc', 'n/a') }} elapsed={{ (prometheus_wait | default({})).get('elapsed', 'n/a') }}
          podman ps (sample): {{ (podman_ps.stdout | default('')) | truncate(1000) }}
          prometheus logs (sample): {{ (prometheus_logs.stdout | default('')) | truncate(2000) }}
      when: inventory_hostname in groups['monitoring_nodes']
      tags: prometheus

    - name: Stat for local prometheus binary
      ansible.builtin.stat:
        path: /usr/local/bin/prometheus
      register: prometheus_stat
      when: inventory_hostname in groups['monitoring_nodes']
      tags: prometheus

    - name: Create a systemd unit for local Prometheus (if binary exists)
      ansible.builtin.copy:
        dest: /etc/systemd/system/prometheus.service
        content: |
          [Unit]
          Description=Prometheus Server
          Wants=network-online.target
          After=network-online.target

          [Service]
          Type=simple
          ExecStart=/usr/local/bin/prometheus --config.file=/etc/prometheus/prometheus.yml --storage.tsdb.path=/srv/monitoring_data/prometheus
          Restart=on-failure

          [Install]
          WantedBy=multi-user.target
        mode: '0644'
      when: inventory_hostname in groups['monitoring_nodes'] and prometheus_stat.stat.exists
      tags: prometheus

    - name: Copy promtail config to all nodes
      ansible.builtin.copy:
        src: files/promtail-config.yaml
        dest: /etc/promtail/promtail.yaml
        owner: root
        group: root
        mode: '0644'
      tags: promtail

    - name: Ensure firewall allows Prometheus/Loki/node_exporter scraping
      ansible.builtin.ufw:
        rule: allow
        port: "{{ item }}"
        proto: tcp
      loop:
        - 9882
        - 3100
        - 9100
      when: ansible_os_family == 'Debian'
      tags: firewall

  handlers:
    - name: Restart Prometheus Container
      ansible.builtin.command: podman restart prometheus || true
      become: true
      listen: Restart Prometheus Container
