---
# VMStation Simplified Deployment Playbook
# Replaces the complex site.yaml with essential functionality only

- name: "VMStation Simplified Deployment"
  hosts: localhost
  gather_facts: false
  become: false
  tasks:
    - name: "Display deployment overview"
      debug:
        msg: |
          === VMStation Simplified Deployment ===
          
          This playbook deploys:
          1. Kubernetes cluster (if not exists)
          2. Essential monitoring stack (Prometheus, Grafana, Loki)
          3. Jellyfin media server
          4. Additional applications (Dashboard, MongoDB, etc.)
          
          Target Infrastructure:
          - Control plane: {{ groups['monitoring_nodes'][0] }} (monitoring_nodes)
          - Storage node: {{ groups['storage_nodes'][0] }} (storage_nodes)  
          - Compute node: {{ groups['compute_nodes'][0] }} (compute_nodes)

# Step 1: Setup Kubernetes cluster
- import_playbook: plays/setup-cluster.yaml

# Step 1.5: Validate cluster readiness before application deployment
- name: "Cluster Readiness Validation"
  hosts: monitoring_nodes
  gather_facts: false
  become: false
  tasks:
    - name: "Check cluster node status"
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Node
      register: cluster_nodes

    - name: "Check flannel pod status"
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Pod
        namespace: kube-flannel
        label_selectors:
          - app=flannel
      register: flannel_pods
      failed_when: false

    - name: "Display cluster status"
      debug:
        msg: |
          === Cluster Status Check ===
          Total nodes: {{ cluster_nodes.resources | length }}
          {% for node in cluster_nodes.resources %}
          - {{ node.metadata.name }}: {{ node.status.conditions | selectattr('type', 'equalto', 'Ready') | map(attribute='status') | first | default('Unknown') }}
          {% endfor %}
          
          Flannel pods: {{ flannel_pods.resources | length if flannel_pods.resources else 0 }}
          {% for pod in flannel_pods.resources | default([]) %}
          - {{ pod.metadata.name }} on {{ pod.spec.nodeName }}: {{ pod.status.phase }}
          {% endfor %}

    - name: "Wait for flannel to be ready on all nodes"
      block:
        - name: "Check for CNI bridge conflicts before flannel wait"
          shell: |
            # Check for CNI bridge IP conflicts that prevent flannel/coredns from starting
            cni_conflicts=$(kubectl get events --all-namespaces --field-selector reason=FailedCreatePodSandBox 2>/dev/null | grep "failed to set bridge addr.*already has an IP address different" | wc -l || echo "0")
            
            # Also check for ContainerCreating pods stuck due to CNI issues
            stuck_pods=$(kubectl get pods --all-namespaces --field-selector status.phase=Pending 2>/dev/null | grep ContainerCreating | wc -l || echo "0")
            
            # Check for CoreDNS pods specifically stuck due to CNI issues
            coredns_stuck=$(kubectl get pods -n kube-system -l k8s-app=kube-dns --field-selector status.phase=Pending 2>/dev/null | wc -l || echo "0")
            
            if [ "$cni_conflicts" -gt 0 ] || [ "$stuck_pods" -gt 3 ] || [ "$coredns_stuck" -gt 0 ]; then
              echo "CNI_BRIDGE_CONFLICTS_DETECTED=true"
              echo "Found indicators of CNI issues:"
              echo "- CNI bridge conflict events: $cni_conflicts"
              echo "- Pods stuck in ContainerCreating: $stuck_pods"  
              echo "- CoreDNS pods stuck: $coredns_stuck"
              exit 1
            else
              echo "No CNI bridge conflicts detected"
              echo "CNI status looks healthy for flannel wait"
              exit 0
            fi
          environment:
            KUBECONFIG: /etc/kubernetes/admin.conf
          register: cni_conflict_check
          failed_when: false
          
        - name: "Wait for flannel DaemonSet with timeout protection"
          kubernetes.core.k8s_info:
            api_version: v1
            kind: DaemonSet
            namespace: kube-flannel
            name: kube-flannel-ds
            wait: true
            wait_condition:
              type: Ready
            wait_timeout: 120
          register: flannel_wait_result
          failed_when: false
          when: '"CNI_BRIDGE_CONFLICTS_DETECTED=true" not in cni_conflict_check.stdout'
          
        - name: "Handle CNI conflicts detected during flannel wait"
          debug:
            msg: |
              === CNI Bridge Conflicts Detected ===
              Flannel cannot be ready due to CNI bridge IP conflicts.
              Setting flag for post-deployment fixes.
              Deployment will continue and apply CNI bridge fix automatically.
          when: '"CNI_BRIDGE_CONFLICTS_DETECTED=true" in cni_conflict_check.stdout'
          
        - name: "Set CNI conflict flag for post-deployment handling"
          shell: echo "CNI_CONFLICT_DETECTED=true" > /tmp/cni_conflict_detected
          when: '"CNI_BRIDGE_CONFLICTS_DETECTED=true" in cni_conflict_check.stdout'
          
        - name: "Handle flannel wait timeout"
          debug:
            msg: |
              === Flannel Wait Timeout ===
              Flannel DaemonSet did not become ready within 120 seconds.
              This may indicate CNI issues that will be handled by post-deployment fixes.
              Continuing deployment to allow fixes to run.
          when: 
            - '"CNI_BRIDGE_CONFLICTS_DETECTED=true" not in cni_conflict_check.stdout'
            - flannel_wait_result.failed | default(false)
            
        - name: "Display flannel readiness status"
          debug:
            msg: |
              Flannel Readiness Check Complete:
              - CNI conflicts detected: {{ "Yes" if "CNI_BRIDGE_CONFLICTS_DETECTED=true" in cni_conflict_check.stdout else "No" }}
              - Flannel wait completed: {{ "Yes" if not (flannel_wait_result.failed | default(false)) else "No (timeout)" }}
              - Post-deployment fixes required: {{ "Yes" if "CNI_BRIDGE_CONFLICTS_DETECTED=true" in cni_conflict_check.stdout or (flannel_wait_result.failed | default(false)) else "No" }}
      ignore_errors: yes

    - name: "Check if any critical pods are failing"
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Pod
        namespace: kube-system
      register: system_pods

    - name: "Display system pod issues"
      debug:
        msg: |
          === System Pod Status ===
          {% for pod in system_pods.resources %}
          {% if pod.status.phase != 'Running' and pod.status.phase != 'Succeeded' %}
          - {{ pod.metadata.name }}: {{ pod.status.phase }}
          {% if pod.status.containerStatuses is defined %}
          {% for container in pod.status.containerStatuses %}
          {% if container.state.waiting is defined %}
            Container {{ container.name }}: {{ container.state.waiting.reason | default('Unknown') }}
          {% endif %}
          {% endfor %}
          {% endif %}
          {% endif %}
          {% endfor %}

# Step 2: Deploy core monitoring stack
- import_playbook: plays/deploy-apps.yaml

# Step 3: Deploy Jellyfin if enabled
- import_playbook: plays/jellyfin.yml
  when: jellyfin_enabled | default(true)

# Step 4: Final validation
- name: "VMStation Deployment Validation"
  hosts: monitoring_nodes
  gather_facts: false
  become: false
  tasks:
    - name: "Verify Kubernetes cluster"
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Node
      register: cluster_nodes
      
    - name: "Check essential namespaces"
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Namespace
        name: "{{ item }}"
      loop:
        - monitoring
        - jellyfin
        - kube-system
      register: namespace_check
      failed_when: false

    - name: "Verify monitoring pods"
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Pod
        namespace: monitoring
        label_selectors:
          - app.kubernetes.io/name=prometheus
      register: prometheus_pods
      failed_when: false

    - name: "Display deployment summary"
      debug:
        msg: |
          === Deployment Summary ===
          
          Cluster Nodes: {{ cluster_nodes.resources | length }}
          {% for node in cluster_nodes.resources %}
          - {{ node.metadata.name }}: {{ node.status.addresses[0].address }} ({{ node.status.conditions | selectattr('type', 'equalto', 'Ready') | map(attribute='status') | first | default('Unknown') }})
          {% endfor %}
          
          Namespaces: 
          {% for ns in namespace_check.results %}
          - {{ ns.item }}: {{ 'OK' if ns.resources else 'Missing' }}
          {% endfor %}
          
          Monitoring: {{ 'Running' if prometheus_pods.resources else 'Not Ready' }}
          {% if prometheus_pods.resources %}
          {% for pod in prometheus_pods.resources %}
          - {{ pod.metadata.name }}: {{ pod.status.phase | default('Unknown') }}
          {% endfor %}
          {% endif %}
          
          {% if jellyfin_enabled | default(true) %}
          Jellyfin: Enabled
          {% endif %}
          
          Access URLs:
          - Grafana: http://{{ groups['monitoring_nodes'][0] }}:30300  
          - Prometheus: http://{{ groups['monitoring_nodes'][0] }}:30090
          - Jellyfin: http://{{ groups['storage_nodes'][0] }}:30096
          
          {% if prometheus_pods.resources | length == 0 %}
          
          ⚠️  WARNING: Some applications may not be ready yet.
          Check status with: kubectl get pods --all-namespaces
          For troubleshooting: kubectl describe pod -n <namespace> <pod-name>
          {% endif %}